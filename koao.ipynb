{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import audio\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import face_detection\n",
    "from models import Wav2Lip\n",
    "\n",
    "mel_step_size = 16\n",
    "def _load(checkpoint_path):\n",
    "    \"\"\"加载模型权重（支持CPU/GPU）\"\"\"\n",
    "    if device == 'cuda':\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
    "    return checkpoint\n",
    "\n",
    "def load_model(path):\n",
    "    \"\"\"初始化并加载Wav2Lip模型\"\"\"\n",
    "    model = Wav2Lip()\n",
    "    print(f\"从 {path} 加载模型\")\n",
    "    checkpoint = _load(path)\n",
    "    new_s = {}\n",
    "    for k, v in checkpoint[\"state_dict\"].items():\n",
    "        new_s[k.replace('module.', '')] = v\n",
    "    model.load_state_dict(new_s)\n",
    "    model = model.to(device)\n",
    "    return model.eval()\n",
    "def get_smoothened_boxes(boxes, T):\n",
    "    for i in range(len(boxes)):\n",
    "        if i + T > len(boxes):\n",
    "            window = boxes[len(boxes) - T:]\n",
    "        else:\n",
    "            window = boxes[i : i + T]\n",
    "        boxes[i] = np.mean(window, axis=0)\n",
    "    return boxes\n",
    "\n",
    "def face_detect(images, pads, device, batch_size, nosmooth):\n",
    "    detector = face_detection.FaceAlignment(face_detection.LandmarksType._2D, flip_input=False, device=device)\n",
    "    predictions = []\n",
    "    while True:\n",
    "        try:\n",
    "            for i in tqdm(range(0, len(images), batch_size), desc=\"人脸检测\"):\n",
    "                predictions.extend(detector.get_detections_for_batch(np.array(images[i:i + batch_size])))\n",
    "            break\n",
    "        except RuntimeError:\n",
    "            if batch_size == 1:\n",
    "                raise RuntimeError('图像过大，需降低分辨率')\n",
    "            batch_size //= 2\n",
    "            print(f'调整人脸检测批次大小为 {batch_size}')\n",
    "    results = []\n",
    "    pady1, pady2, padx1, padx2 = pads\n",
    "    for rect, image in zip(predictions, images):\n",
    "        if rect is None:\n",
    "            cv2.imwrite('temp/faulty_frame.jpg', image)\n",
    "            raise ValueError('未检测到人脸！请确保视频含有人脸')\n",
    "        y1 = max(0, rect[1] - pady1)\n",
    "        y2 = min(image.shape[0], rect[3] + pady2)\n",
    "        x1 = max(0, rect[0] - padx1)\n",
    "        x2 = min(image.shape[1], rect[2] + padx2)\n",
    "        results.append([x1, y1, x2, y2])\n",
    "    boxes = np.array(results)\n",
    "    if not nosmooth:\n",
    "        boxes = get_smoothened_boxes(boxes, T=5)\n",
    "    results = [[image[y1: y2, x1:x2], (y1, y2, x1, x2)] for image, (x1, y1, x2, y2) in zip(images, boxes)]\n",
    "    del detector\n",
    "    return results\n",
    "\n",
    "def datagen(frames, mels, box, static, face_det_batch_size, pads, nosmooth, img_size, device):\n",
    "    img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "    if box[0] == -1:\n",
    "        if not static:\n",
    "            face_det_results = face_detect(frames, pads, device, face_det_batch_size, nosmooth)\n",
    "        else:\n",
    "            face_det_results = face_detect([frames[0]], pads, device, face_det_batch_size, nosmooth)\n",
    "    else:\n",
    "        print('使用手动指定人脸框')\n",
    "        y1, y2, x1, x2 = box\n",
    "        face_det_results = [[f[y1: y2, x1:x2], (y1, y2, x1, x2)] for f in frames]\n",
    "    for i, m in enumerate(mels):\n",
    "        idx = 0 if static else i % len(frames)\n",
    "        frame_to_save = frames[idx].copy()\n",
    "        face, coords = face_det_results[idx].copy()\n",
    "        face = cv2.resize(face, (img_size, img_size))\n",
    "        img_batch.append(face)\n",
    "        mel_batch.append(m)\n",
    "        frame_batch.append(frame_to_save)\n",
    "        coords_batch.append(coords)\n",
    "        if len(img_batch) >= 128:  # 默认批次128，实际可传参\n",
    "            img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "            img_masked = img_batch.copy()\n",
    "            img_masked[:, img_size // 2:] = 0\n",
    "            img_input = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "            mel_input = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "            yield img_input, mel_input, frame_batch, coords_batch\n",
    "            img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "    if len(img_batch) > 0:\n",
    "        img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "        img_masked = img_batch.copy()\n",
    "        img_masked[:, img_size // 2:] = 0\n",
    "        img_input = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "        mel_input = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "        yield img_input, mel_input, frame_batch, coords_batch\n",
    "\n",
    "def prepare_wav2lip_data(audio_path, face_path,\n",
    "                         pads=[0,10,0,0], box=[-1,-1,-1,-1], crop=[0,-1,0,-1],\n",
    "                         static=False, fps=25, face_det_batch_size=16, wav2lip_batch_size=128,\n",
    "                         resize_factor=1, rotate=False, nosmooth=False, img_size=96, device='cuda'):\n",
    "    # 1. 读帧\n",
    "    if not os.path.isfile(face_path):\n",
    "        raise ValueError('人脸文件路径错误')\n",
    "    if face_path.split('.')[-1].lower() in ['jpg', 'png', 'jpeg']:\n",
    "        full_frames = [cv2.imread(face_path)]\n",
    "        if full_frames[0] is None:\n",
    "            raise ValueError(f\"无法读取图片: {face_path}\")\n",
    "        static = True\n",
    "    else:\n",
    "        video_stream = cv2.VideoCapture(face_path)\n",
    "        fps = video_stream.get(cv2.CAP_PROP_FPS)\n",
    "        full_frames = []\n",
    "        while True:\n",
    "            still_reading, frame = video_stream.read()\n",
    "            if not still_reading:\n",
    "                video_stream.release()\n",
    "                break\n",
    "            if resize_factor > 1:\n",
    "                frame = cv2.resize(frame, (frame.shape[1] // resize_factor, frame.shape[0] // resize_factor))\n",
    "            if rotate:\n",
    "                frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "            y1, y2, x1, x2 = crop\n",
    "            if x2 == -1: x2 = frame.shape[1]\n",
    "            if y2 == -1: y2 = frame.shape[0]\n",
    "            frame = frame[y1:y2, x1:x2]\n",
    "            full_frames.append(frame)\n",
    "    # 2. 读音频\n",
    "    if not audio_path.endswith('.wav'):\n",
    "        print('提取音频...')\n",
    "        command = f'ffmpeg -y -i \"{audio_path}\" -strict -2 temp/temp.wav'\n",
    "        subprocess.call(command, shell=True)\n",
    "        audio_path = 'temp/temp.wav'\n",
    "    wav = audio.load_wav(audio_path, 16000)\n",
    "    mel = audio.melspectrogram(wav)\n",
    "    if np.isnan(mel.reshape(-1)).sum() > 0:\n",
    "        raise ValueError('梅尔频谱包含NaN值，请检查音频质量')\n",
    "    # 3. 分帧\n",
    "    mel_idx_multiplier = 80. / fps\n",
    "    mel_chunks = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        start_idx = int(i * mel_idx_multiplier)\n",
    "        if start_idx + mel_step_size > len(mel[0]):\n",
    "            mel_chunks.append(mel[:, len(mel[0]) - mel_step_size:])\n",
    "            break\n",
    "        mel_chunks.append(mel[:, start_idx: start_idx + mel_step_size])\n",
    "        i += 1\n",
    "    full_frames = full_frames[:len(mel_chunks)]\n",
    "    # 4. 返回数据生成器和帧等\n",
    "    gen = datagen(full_frames.copy(), mel_chunks, box, static, face_det_batch_size, pads, nosmooth, img_size, device)\n",
    "    return gen, full_frames, fps\n",
    "\n",
    "# 用法示例\n",
    "if __name__ == '__main__':\n",
    "    # 参数示例\n",
    "    audio_path = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\input\\1.wav\"\n",
    "    face_path = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\input\\1.png\"\n",
    "    check_path=r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\checkpoints\\wav2lip_gan.pth\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model=load_model(check_path)\n",
    "    # 通过该函数获取可用于模型推理的数据生成器\n",
    "    gen, full_frames, fps = prepare_wav2lip_data(\n",
    "        audio_path, face_path,\n",
    "        pads=[0, 10, 0, 0],\n",
    "        box=[-1, -1, -1, -1],\n",
    "        crop=[0, -1, 0, -1],\n",
    "        static=False,\n",
    "        fps=25,\n",
    "        face_det_batch_size=16,\n",
    "        wav2lip_batch_size=128,\n",
    "        resize_factor=1,\n",
    "        rotate=False,\n",
    "        nosmooth=False,\n",
    "        img_size=96,\n",
    "        device=device\n",
    "    )\n",
    "    # 直接可用于模型推理\n",
    "    for i, (img_batch, mel_batch, frames, coords) in enumerate(\n",
    "        tqdm(gen, total=int(np.ceil(len(full_frames) / 128)), desc=\"处理进度\")):\n",
    "        img_batch = torch.FloatTensor(np.transpose(img_batch, (0, 3, 1, 2))).to(device)\n",
    "        mel_batch = torch.FloatTensor(np.transpose(mel_batch, (0, 3, 1, 2))).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(mel_batch, img_batch)\n",
    "\n",
    "        pred = pred.cpu().numpy().transpose(0, 2, 3, 1) * 255.\n",
    "        pred = pred.astype(np.uint8)\n",
    "\n",
    "        for p, f, c in zip(pred, frames, coords):\n",
    "            y1, y2, x1, x2 = c\n",
    "            p = cv2.resize(p, (x2 - x1, y2 - y1))\n",
    "            f[y1:y2, x1:x2] = p\n",
    "            f = imag = cv2.resize(f, (224, 336))\n",
    "            cv2.imshow('image', f)\n",
    "            cv2.waitKey(1)\n"
   ],
   "id": "8a7518a2a3b22377",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 导入必要的库\n",
    "from os import listdir, path\n",
    "import numpy as np  # 数值计算库\n",
    "import scipy, cv2, os, sys, audio  # 科学计算、OpenCV、系统操作、音频处理\n",
    "import json, subprocess, random, string  # JSON处理、子进程调用、随机数生成\n",
    "from tqdm import tqdm  # 进度条库\n",
    "from glob import glob  # 文件路径匹配\n",
    "import torch, face_detection  # PyTorch框架、人脸检测库\n",
    "from models import Wav2Lip  # 导入自定义的Wav2Lip模型\n",
    "import platform  # 系统平台信息获取\n",
    "imag=r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\input\\1.png\"\n",
    "imag=cv2.imread(imag)\n",
    "imag=cv2.resize(imag,(224,336))\n",
    "cv2.namedWindow('image')\n",
    "cv2.resizeWindow('image', 300, 500)\n",
    "cv2.imshow('image', imag)\n",
    "cv2.waitKey(2000)\n",
    "# ------------------ 参数设置区（无需命令行，直接修改这里即可） ------------------\n",
    "class Args:\n",
    "    # 必需参数\n",
    "    checkpoint_path = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\checkpoints/wav2lip.pth\"  # 模型权重文件路径\n",
    "    face = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\input\\1.png\"                     # 输入人脸视频/图像路径\n",
    "    audio = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\input\\1.wav\"                   # 输入音频/视频文件路径\n",
    "    outfile = 'results/woowowo.mp4'          # 输出视频路径\n",
    "\n",
    "    # 可选参数\n",
    "    static = False                 # 是否为静态图像输入\n",
    "    fps = 25.0                     # 静态图像帧率\n",
    "    pads = [0, 10, 0, 0]           # 人脸检测 padding\n",
    "    face_det_batch_size = 16       # 人脸检测批次大小\n",
    "    wav2lip_batch_size = 128       # Wav2Lip模型批次大小\n",
    "    resize_factor = 1              # 分辨率缩放因子\n",
    "    crop = [0, -1, 0, -1]          # 视频裁剪区域\n",
    "    box = [-1, -1, -1, -1]         # 手动人脸框坐标\n",
    "    rotate = False                 # 是否旋转视频\n",
    "    nosmooth = False               # 禁用人脸检测平滑\n",
    "    img_size = 96                  # 设置模型输入图像尺寸为96x96\n",
    "\n",
    "args = Args\n",
    "\n",
    "# 判断输入是否为静态图像\n",
    "if os.path.isfile(args.face) and args.face.split('.')[-1].lower() in ['jpg', 'png', 'jpeg']:\n",
    "    args.static = True\n",
    "\n",
    "# -------------------------- 人脸检测相关函数 --------------------------\n",
    "def get_smoothened_boxes(boxes, T):\n",
    "    \"\"\"平滑人脸检测框，减少相邻帧抖动\"\"\"\n",
    "    for i in range(len(boxes)):\n",
    "        # 取滑动窗口内的检测框求平均\n",
    "        if i + T > len(boxes):\n",
    "            window = boxes[len(boxes) - T:]\n",
    "        else:\n",
    "            window = boxes[i: i + T]\n",
    "        boxes[i] = np.mean(window, axis=0)\n",
    "    return boxes\n",
    "\n",
    "def face_detect(images):\n",
    "    \"\"\"人脸检测函数，返回检测到的人脸区域\"\"\"\n",
    "    detector = face_detection.FaceAlignment(face_detection.LandmarksType._2D, flip_input=False, device=device)\n",
    "    batch_size = args.face_det_batch_size\n",
    "    predictions = []\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            for i in tqdm(range(0, len(images), batch_size), desc=\"人脸检测\"):\n",
    "                predictions.extend(detector.get_detections_for_batch(np.array(images[i:i + batch_size])))\n",
    "            break\n",
    "        except RuntimeError:\n",
    "            if batch_size == 1:\n",
    "                raise RuntimeError('图像过大，需降低分辨率')\n",
    "            batch_size //= 2\n",
    "            print(f'调整人脸检测批次大小为 {batch_size}')\n",
    "\n",
    "    results = []\n",
    "    pady1, pady2, padx1, padx2 = args.pads\n",
    "    for rect, image in zip(predictions, images):\n",
    "        if rect is None:\n",
    "            cv2.imwrite('temp/faulty_frame.jpg', image)\n",
    "            raise ValueError('未检测到人脸！请确保视频含有人脸')\n",
    "\n",
    "        y1 = max(0, rect[1] - pady1)\n",
    "        y2 = min(image.shape[0], rect[3] + pady2)\n",
    "        x1 = max(0, rect[0] - padx1)\n",
    "        x2 = min(image.shape[1], rect[2] + padx2)\n",
    "        results.append([x1, y1, x2, y2])\n",
    "\n",
    "    boxes = np.array(results)\n",
    "    if not args.nosmooth:\n",
    "        boxes = get_smoothened_boxes(boxes, T=5)\n",
    "\n",
    "    results = [[image[y1: y2, x1:x2], (y1, y2, x1, x2)] for image, (x1, y1, x2, y2) in zip(images, boxes)]\n",
    "    del detector\n",
    "    return results\n",
    "\n",
    "# -------------------------- 数据生成器函数 --------------------------\n",
    "def datagen(frames, mels):\n",
    "    \"\"\"生成模型输入数据批次\"\"\"\n",
    "    img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "\n",
    "    if args.box[0] == -1:\n",
    "        if not args.static:\n",
    "            face_det_results = face_detect(frames)\n",
    "        else:\n",
    "            face_det_results = face_detect([frames[0]])\n",
    "    else:\n",
    "        print('使用手动指定人脸框')\n",
    "        y1, y2, x1, x2 = args.box\n",
    "        face_det_results = [[f[y1: y2, x1:x2], (y1, y2, x1, x2)] for f in frames]\n",
    "\n",
    "    for i, m in enumerate(mels):\n",
    "        idx = 0 if args.static else i % len(frames)\n",
    "        frame_to_save = frames[idx].copy()\n",
    "        face, coords = face_det_results[idx].copy()\n",
    "        face = cv2.resize(face, (args.img_size, args.img_size))\n",
    "\n",
    "        img_batch.append(face)\n",
    "        mel_batch.append(m)\n",
    "        frame_batch.append(frame_to_save)\n",
    "        coords_batch.append(coords)\n",
    "\n",
    "        if len(img_batch) >= args.wav2lip_batch_size:\n",
    "            img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "            img_masked = img_batch.copy()\n",
    "            img_masked[:, args.img_size // 2:] = 0\n",
    "            img_input = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "            mel_input = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "\n",
    "            yield img_input, mel_input, frame_batch, coords_batch\n",
    "            img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "\n",
    "    if len(img_batch) > 0:\n",
    "        img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "        img_masked = img_batch.copy()\n",
    "        img_masked[:, args.img_size // 2:] = 0\n",
    "        img_input = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "        mel_input = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "        yield img_input, mel_input, frame_batch, coords_batch\n",
    "\n",
    "# -------------------------- 模型加载相关 --------------------------\n",
    "mel_step_size = 16\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'使用 {device} 进行推理')\n",
    "\n",
    "def _load(checkpoint_path):\n",
    "    \"\"\"加载模型权重（支持CPU/GPU）\"\"\"\n",
    "    if device == 'cuda':\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
    "    return checkpoint\n",
    "\n",
    "def load_model(path):\n",
    "    \"\"\"初始化并加载Wav2Lip模型\"\"\"\n",
    "    model = Wav2Lip()\n",
    "    print(f\"从 {path} 加载模型\")\n",
    "    checkpoint = _load(path)\n",
    "    new_s = {}\n",
    "    for k, v in checkpoint[\"state_dict\"].items():\n",
    "        new_s[k.replace('module.', '')] = v\n",
    "    model.load_state_dict(new_s)\n",
    "    model = model.to(device)\n",
    "    return model.eval()\n",
    "\n",
    "# -------------------------- 主函数 --------------------------\n",
    "def main():\n",
    "    if not os.path.isfile(args.face):\n",
    "        raise ValueError('人脸文件路径错误')\n",
    "    #载入模型\n",
    "    model = load_model(args.checkpoint_path)\n",
    "\n",
    "    if args.face.split('.')[-1].lower() in ['jpg', 'png', 'jpeg']:\n",
    "        full_frames = [cv2.imread(args.face)]\n",
    "        fps = args.fps\n",
    "    else:\n",
    "        video_stream = cv2.VideoCapture(args.face)\n",
    "        fps = video_stream.get(cv2.CAP_PROP_FPS)\n",
    "        print('读取视频帧...')\n",
    "        full_frames = []\n",
    "        while True:\n",
    "            still_reading, frame = video_stream.read()\n",
    "            if not still_reading:\n",
    "                video_stream.release()\n",
    "                break\n",
    "            if args.resize_factor > 1:\n",
    "                frame = cv2.resize(frame, (frame.shape[1] // args.resize_factor, frame.shape[0] // args.resize_factor))\n",
    "            if args.rotate:\n",
    "                frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "            y1, y2, x1, x2 = args.crop\n",
    "            if x2 == -1: x2 = frame.shape[1]\n",
    "            if y2 == -1: y2 = frame.shape[0]\n",
    "            frame = frame[y1:y2, x1:x2]\n",
    "            full_frames.append(frame)\n",
    "\n",
    "    print(f\"可用推理帧数: {len(full_frames)}\")\n",
    "\n",
    "    if not args.audio.endswith('.wav'):\n",
    "        print('提取音频...')\n",
    "        command = f'ffmpeg -y -i {args.audio} -strict -2 temp/temp.wav'\n",
    "        subprocess.call(command, shell=True)\n",
    "        args.audio = 'temp/temp.wav'\n",
    "\n",
    "    wav = audio.load_wav(args.audio, 16000)\n",
    "    mel = audio.melspectrogram(wav)\n",
    "    print(f\"梅尔频谱形状: {mel.shape}\")\n",
    "\n",
    "    if np.isnan(mel.reshape(-1)).sum() > 0:\n",
    "        raise ValueError('梅尔频谱包含NaN值，请检查音频质量')\n",
    "\n",
    "    mel_idx_multiplier = 80. / fps\n",
    "    mel_chunks = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        start_idx = int(i * mel_idx_multiplier)\n",
    "        if start_idx + mel_step_size > len(mel[0]):\n",
    "            mel_chunks.append(mel[:, len(mel[0]) - mel_step_size:])\n",
    "            break\n",
    "        mel_chunks.append(mel[:, start_idx: start_idx + mel_step_size])\n",
    "        i += 1\n",
    "    print(f\"梅尔块数量: {len(mel_chunks)}\")\n",
    "\n",
    "    full_frames = full_frames[:len(mel_chunks)]\n",
    "    batch_size = args.wav2lip_batch_size\n",
    "    gen = datagen(full_frames.copy(), mel_chunks)\n",
    "\n",
    "    \"\"\"out = None\n",
    "    frame_h, frame_w = full_frames[0].shape[:-1]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    out = cv2.VideoWriter('temp/result.avi', fourcc, fps, (frame_w, frame_h))\"\"\"\n",
    "    for i, (img_batch, mel_batch, frames, coords) in enumerate(tqdm(gen, total=int(np.ceil(len(mel_chunks) / batch_size)), desc=\"处理进度\")):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        img_batch = torch.FloatTensor(np.transpose(img_batch, (0, 3, 1, 2))).to(device)\n",
    "        mel_batch = torch.FloatTensor(np.transpose(mel_batch, (0, 3, 1, 2))).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(mel_batch, img_batch)\n",
    "\n",
    "        pred = pred.cpu().numpy().transpose(0, 2, 3, 1) * 255.\n",
    "        pred = pred.astype(np.uint8)\n",
    "\n",
    "        for p, f, c in zip(pred, frames, coords):\n",
    "            y1, y2, x1, x2 = c\n",
    "            p = cv2.resize(p, (x2 - x1, y2 - y1))\n",
    "            f[y1:y2, x1:x2] = p\n",
    "            f=imag=cv2.resize(f,(224,336))\n",
    "            cv2.imshow('image', f)\n",
    "            cv2.waitKey(1)\n",
    "\n",
    "            #out.write(f)\n",
    "\n",
    "    \"\"\"if out is not None:\n",
    "        out.release()\n",
    "\n",
    "    print('合并音视频...')\n",
    "    command = f'ffmpeg -y -i {args.audio} -i temp/result.avi -strict -2 -q:v 1 {args.outfile}'\n",
    "    subprocess.call(command, shell=platform.system() != 'Windows')\"\"\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    main()\n",
    "    print(f\"总耗时: {time.time() - start_time:.2f} 秒\")"
   ],
   "id": "95df99b8b0f67977",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "27dcc5e3e62b9b30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:34:02.074721Z",
     "start_time": "2025-05-25T08:34:02.040642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import audio\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import face_detection\n",
    "from models import Wav2Lip\n",
    "\n",
    "mel_step_size = 16\n",
    "\n",
    "def _load(checkpoint_path):\n",
    "    \"\"\"加载模型权重（支持CPU/GPU）\"\"\"\n",
    "    if device == 'cuda':\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
    "    return checkpoint\n",
    "\n",
    "def load_model(path):\n",
    "    \"\"\"初始化并加载Wav2Lip模型\"\"\"\n",
    "    model = Wav2Lip()\n",
    "    print(f\"从 {path} 加载模型\")\n",
    "    checkpoint = _load(path)\n",
    "    new_s = {}\n",
    "    for k, v in checkpoint[\"state_dict\"].items():\n",
    "        new_s[k.replace('module.', '')] = v\n",
    "    model.load_state_dict(new_s)\n",
    "    model = model.to(device)\n",
    "    return model.eval()\n",
    "\n",
    "def preprocess_image(\n",
    "    image_path,\n",
    "    pads=[0,10,0,0],\n",
    "    box=[-1,-1,-1,-1],\n",
    "    img_size=96,\n",
    "    face_det_batch_size=16,\n",
    "    nosmooth=False,\n",
    "    device='cuda'\n",
    "):\n",
    "    # 加载图片\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"无法读取图片: {image_path}\")\n",
    "    # 人脸检测\n",
    "    if box[0] == -1:\n",
    "        detector = face_detection.FaceAlignment(face_detection.LandmarksType._2D, flip_input=False, device=device)\n",
    "        predictions = detector.get_detections_for_batch(np.array([image]))\n",
    "        rect = predictions[0]\n",
    "        if rect is None:\n",
    "            raise RuntimeError(\"未检测到人脸\")\n",
    "        pady1, pady2, padx1, padx2 = pads\n",
    "        y1 = max(0, rect[1] - pady1)\n",
    "        y2 = min(image.shape[0], rect[3] + pady2)\n",
    "        x1 = max(0, rect[0] - padx1)\n",
    "        x2 = min(image.shape[1], rect[2] + padx2)\n",
    "    else:\n",
    "        y1, y2, x1, x2 = box\n",
    "    face = image[y1:y2, x1:x2]\n",
    "    face = cv2.resize(face, (img_size, img_size))\n",
    "    coords = (0, img_size, 0, img_size)  # 对静态图直接用(0,96,0,96)\n",
    "    return face, coords\n",
    "\n",
    "def prepare_audio_batches(\n",
    "    audio_path,\n",
    "    face_img,\n",
    "    face_coords,\n",
    "    static=True,\n",
    "    fps=25,\n",
    "    mel_step_size=16,\n",
    "    wav2lip_batch_size=128,\n",
    "    img_size=96\n",
    "):\n",
    "    # 1. 读音频\n",
    "    if not audio_path.endswith('.wav'):\n",
    "        print('提取音频...')\n",
    "        command = f'ffmpeg -y -i \"{audio_path}\" -strict -2 temp/temp.wav'\n",
    "        subprocess.call(command, shell=True)\n",
    "        audio_path = 'temp/temp.wav'\n",
    "    wav = audio.load_wav(audio_path, 16000)\n",
    "    mel = audio.melspectrogram(wav)\n",
    "    if np.isnan(mel.reshape(-1)).sum() > 0:\n",
    "        raise ValueError('梅尔频谱包含NaN值，请检查音频质量')\n",
    "    # 2. mel切块\n",
    "    mel_idx_multiplier = 80. / fps\n",
    "    mel_chunks = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        start_idx = int(i * mel_idx_multiplier)\n",
    "        if start_idx + mel_step_size > len(mel[0]):\n",
    "            mel_chunks.append(mel[:, len(mel[0]) - mel_step_size:])\n",
    "            break\n",
    "        mel_chunks.append(mel[:, start_idx: start_idx + mel_step_size])\n",
    "        i += 1\n",
    "    # 3. 生成batch\n",
    "    img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "    for i, m in enumerate(mel_chunks):\n",
    "        frame_to_save = face_img.copy()\n",
    "        face = face_img.copy()\n",
    "        coords = face_coords  # (0, img_size, 0, img_size)\n",
    "        img_batch.append(face)\n",
    "        mel_batch.append(m)\n",
    "        frame_batch.append(frame_to_save)\n",
    "        coords_batch.append(coords)\n",
    "        if len(img_batch) >= wav2lip_batch_size:\n",
    "            img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "            img_masked = img_batch.copy()\n",
    "            img_masked[:, img_size // 2:] = 0\n",
    "            img_input = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "            mel_input = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "            yield img_input, mel_input, frame_batch, coords_batch\n",
    "            img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "    if len(img_batch) > 0:\n",
    "        img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "        img_masked = img_batch.copy()\n",
    "        img_masked[:, img_size // 2:] = 0\n",
    "        img_input = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "        mel_input = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "        yield img_input, mel_input, frame_batch, coords_batch\n",
    "\n",
    "def wav2lip_infer(\n",
    "    model,\n",
    "    gen,\n",
    "    device,\n",
    "    batch_size=128,\n",
    "    window_size=(224, 336),\n",
    "    show_window=True,\n",
    "    window_name=\"Wav2Lip Result\"\n",
    "):\n",
    "    global a\n",
    "    \"\"\"\n",
    "    执行Wav2Lip模型推理，遍历gen生成的数据batch并实时展示或处理结果（静态图片流程）。\n",
    "    \"\"\"\n",
    "    for i, (img_batch, mel_batch, frames, coords) in enumerate(\n",
    "        tqdm(gen, desc=\"处理进度\")\n",
    "    ):\n",
    "        img_batch = torch.FloatTensor(np.transpose(img_batch, (0, 3, 1, 2))).to(device)\n",
    "        mel_batch = torch.FloatTensor(np.transpose(mel_batch, (0, 3, 1, 2))).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(mel_batch, img_batch)\n",
    "\n",
    "        pred = pred.cpu().numpy().transpose(0, 2, 3, 1) * 255.\n",
    "        pred = pred.astype(np.uint8)\n",
    "\n",
    "        for p, f, c in zip(pred, frames, coords):\n",
    "            y1, y2, x1, x2 = c\n",
    "            # 这里coords=(0,96,0,96)，就是整张96x96小图\n",
    "            p = cv2.resize(p, (x2 - x1, y2 - y1))\n",
    "            f[y1:y2, x1:x2] = p\n",
    "            f_disp = cv2.resize(f, window_size)\n",
    "            if show_window:\n",
    "                cv2.imshow(window_name, f_disp)\n",
    "                #print(time.time()-a,\"------\")\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    cv2.destroyAllWindows()\n",
    "                    return\n",
    "    if show_window:\n",
    "        cv2.destroyAllWindows()"
   ],
   "id": "a31b9505d667ded6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:33:11.801041Z",
     "start_time": "2025-05-25T08:33:09.440969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    check_path = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\checkpoints\\wav2lip_gan.pth\"\n",
    "    img_path = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\input\\1.png\"\n",
    "    audio_path = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\input\\1.wav\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    a=time.time()\n",
    "    model = load_model(check_path)\n",
    "    print(time.time() - a)\n",
    "    a=time.time()\n",
    "\n",
    "\n",
    "\n",
    "    face_img, face_coords = preprocess_image(img_path, device=device)\n",
    "    print(time.time() - a)"
   ],
   "id": "64674b36b301ab1a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 D:\\coding\\projects\\Python\\human\\Wav2Lip\\checkpoints\\wav2lip_gan.pth 加载模型\n",
      "1.32600998878479\n",
      "1.024045467376709\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:34:20.325536Z",
     "start_time": "2025-05-25T08:34:05.840268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    a=time.time()\n",
    "    gen = prepare_audio_batches(audio_path, face_img, face_coords)\n",
    "    print(time.time() - a)\n",
    "    a=time.time()\n",
    "\n",
    "    wav2lip_infer(model, gen, device)\n",
    "    print(time.time() - a)"
   ],
   "id": "527e1eb7ee7ba6d0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 12it [00:14,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.467391967773438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dd2def6c0443a989",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:35:54.233168Z",
     "start_time": "2025-05-25T08:35:54.202271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import audio\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import face_detection\n",
    "from models import Wav2Lip\n",
    "\n",
    "mel_step_size = 16\n",
    "\n",
    "def _load(checkpoint_path):\n",
    "    \"\"\"加载模型权重（支持CPU/GPU）\"\"\"\n",
    "    if device == 'cuda':\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
    "    return checkpoint\n",
    "\n",
    "def load_model(path):\n",
    "    \"\"\"初始化并加载Wav2Lip模型\"\"\"\n",
    "    model = Wav2Lip()\n",
    "    print(f\"从 {path} 加载模型\")\n",
    "    checkpoint = _load(path)\n",
    "    new_s = {}\n",
    "    for k, v in checkpoint[\"state_dict\"].items():\n",
    "        new_s[k.replace('module.', '')] = v\n",
    "    model.load_state_dict(new_s)\n",
    "    model = model.to(device)\n",
    "    return model.eval()\n",
    "\n",
    "def preprocess_image(\n",
    "    image_path,\n",
    "    pads=[0,10,0,0],\n",
    "    box=[-1,-1,-1,-1],\n",
    "    img_size=96,\n",
    "    face_det_batch_size=16,\n",
    "    nosmooth=False,\n",
    "    device='cuda'\n",
    "):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"无法读取图片: {image_path}\")\n",
    "    if box[0] == -1:\n",
    "        detector = face_detection.FaceAlignment(face_detection.LandmarksType._2D, flip_input=False, device=device)\n",
    "        predictions = detector.get_detections_for_batch(np.array([image]))\n",
    "        rect = predictions[0]\n",
    "        if rect is None:\n",
    "            raise RuntimeError(\"未检测到人脸\")\n",
    "        pady1, pady2, padx1, padx2 = pads\n",
    "        y1 = max(0, rect[1] - pady1)\n",
    "        y2 = min(image.shape[0], rect[3] + pady2)\n",
    "        x1 = max(0, rect[0] - padx1)\n",
    "        x2 = min(image.shape[1], rect[2] + padx2)\n",
    "    else:\n",
    "        y1, y2, x1, x2 = box\n",
    "    face = image[y1:y2, x1:x2]\n",
    "    face = cv2.resize(face, (img_size, img_size))\n",
    "    coords = (y1, y2, x1, x2)\n",
    "    return face, coords, image\n",
    "\n",
    "def prepare_audio_batches(\n",
    "    audio_path,\n",
    "    face_img,\n",
    "    face_coords,\n",
    "    static=True,\n",
    "    fps=25,\n",
    "    mel_step_size=16,\n",
    "    wav2lip_batch_size=128,\n",
    "    img_size=96\n",
    "):\n",
    "    if not audio_path.endswith('.wav'):\n",
    "        print('提取音频...')\n",
    "        command = f'ffmpeg -y -i \"{audio_path}\" -strict -2 temp/temp.wav'\n",
    "        subprocess.call(command, shell=True)\n",
    "        audio_path = 'temp/temp.wav'\n",
    "    wav = audio.load_wav(audio_path, 16000)\n",
    "    mel = audio.melspectrogram(wav)\n",
    "    if np.isnan(mel.reshape(-1)).sum() > 0:\n",
    "        raise ValueError('梅尔频谱包含NaN值，请检查音频质量')\n",
    "    mel_idx_multiplier = 80. / fps\n",
    "    mel_chunks = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        start_idx = int(i * mel_idx_multiplier)\n",
    "        if start_idx + mel_step_size > len(mel[0]):\n",
    "            mel_chunks.append(mel[:, len(mel[0]) - mel_step_size:])\n",
    "            break\n",
    "        mel_chunks.append(mel[:, start_idx: start_idx + mel_step_size])\n",
    "        i += 1\n",
    "    img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "    for i, m in enumerate(mel_chunks):\n",
    "        frame_to_save = face_img.copy()\n",
    "        face = face_img.copy()\n",
    "        coords = face_coords  # (y1, y2, x1, x2) for the original image\n",
    "        img_batch.append(face)\n",
    "        mel_batch.append(m)\n",
    "        frame_batch.append(frame_to_save)\n",
    "        coords_batch.append(coords)\n",
    "        if len(img_batch) >= wav2lip_batch_size:\n",
    "            img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "            img_masked = img_batch.copy()\n",
    "            img_masked[:, img_size // 2:] = 0\n",
    "            img_input = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "            mel_input = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "            yield img_input, mel_input, frame_batch, coords_batch\n",
    "            img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "    if len(img_batch) > 0:\n",
    "        img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "        img_masked = img_batch.copy()\n",
    "        img_masked[:, img_size // 2:] = 0\n",
    "        img_input = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "        mel_input = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "        yield img_input, mel_input, frame_batch, coords_batch\n",
    "\n",
    "def wav2lip_infer(\n",
    "    model,\n",
    "    gen,\n",
    "    device,\n",
    "    orig_image,\n",
    "    coords,\n",
    "    batch_size=128,\n",
    "    window_size=(224, 336),\n",
    "    show_window=True,\n",
    "    window_name=\"Wav2Lip Result\"\n",
    "):\n",
    "    global b\n",
    "    for i, (img_batch, mel_batch, frames, coords_batch) in enumerate(\n",
    "        tqdm(gen, desc=\"处理进度\")\n",
    "    ):\n",
    "        img_batch = torch.FloatTensor(np.transpose(img_batch, (0, 3, 1, 2))).to(device)\n",
    "        mel_batch = torch.FloatTensor(np.transpose(mel_batch, (0, 3, 1, 2))).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(mel_batch, img_batch)\n",
    "        pred = pred.cpu().numpy().transpose(0, 2, 3, 1) * 255.\n",
    "        pred = pred.astype(np.uint8)\n",
    "\n",
    "        for p in pred:\n",
    "            y1, y2, x1, x2 = coords\n",
    "            h, w = y2 - y1, x2 - x1\n",
    "            if h <= 0 or w <= 0:\n",
    "                print(\"Invalid coords:\", coords)\n",
    "                continue\n",
    "            p_resized = cv2.resize(p, (w, h))\n",
    "            show_img = orig_image.copy()\n",
    "            # 用掩膜粘贴（此处直接贴回人脸区域）\n",
    "            show_img[y1:y2, x1:x2] = p_resized\n",
    "            show_img_disp = cv2.resize(show_img, window_size)\n",
    "            if show_window:\n",
    "                cv2.imshow(window_name, show_img_disp)\n",
    "                print(time.time()-b,\"----\")\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    cv2.destroyAllWindows()\n",
    "                    return\n",
    "    if show_window:\n",
    "        cv2.destroyAllWindows()"
   ],
   "id": "a3b7610deba689e6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:34:49.913231Z",
     "start_time": "2025-05-25T08:34:47.994635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    check_path = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\checkpoints\\wav2lip_gan.pth\"\n",
    "    img_path = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\input\\1.png\"\n",
    "    audio_path = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\input\\1.wav\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    a=time.time()\n",
    "\n",
    "    model = load_model(check_path)\n",
    "    print(time.time() - a)\n",
    "    a=time.time()\n",
    "    face_img, face_coords, orig_image = preprocess_image(img_path, device=device)\n",
    "    print(time.time() - a)"
   ],
   "id": "c52ad9fc7ce3ef26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 D:\\coding\\projects\\Python\\human\\Wav2Lip\\checkpoints\\wav2lip_gan.pth 加载模型\n",
      "1.032834768295288\n",
      "0.8675639629364014\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:36:14.305250Z",
     "start_time": "2025-05-25T08:35:56.086331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    a=time.time()\n",
    "    gen = prepare_audio_batches(audio_path, face_img, face_coords)\n",
    "    print(time.time() - a)\n",
    "    a=time.time()\n",
    "    b=time.time()\n",
    "    wav2lip_infer(model, gen, device, orig_image=orig_image, coords=face_coords)\n",
    "    print(time.time() - a)"
   ],
   "id": "c607bc77a7a059c8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.7216842174530029 ----\n",
      "0.7306890487670898 ----\n",
      "0.7537441253662109 ----\n",
      "0.7637538909912109 ----\n",
      "0.7741804122924805 ----\n",
      "0.7741804122924805 ----\n",
      "0.7964823246002197 ----\n",
      "0.8066043853759766 ----\n",
      "0.8169867992401123 ----\n",
      "0.8274562358856201 ----\n",
      "0.8380670547485352 ----\n",
      "0.8501057624816895 ----\n",
      "0.8609046936035156 ----\n",
      "0.8720381259918213 ----\n",
      "0.8800251483917236 ----\n",
      "0.8906211853027344 ----\n",
      "0.900759220123291 ----\n",
      "0.9115715026855469 ----\n",
      "0.9208118915557861 ----\n",
      "0.935631275177002 ----\n",
      "0.9473636150360107 ----\n",
      "0.9574370384216309 ----\n",
      "0.9675302505493164 ----\n",
      "0.973548173904419 ----\n",
      "0.9840149879455566 ----\n",
      "0.9940829277038574 ----\n",
      "1.004086971282959 ----\n",
      "1.0140957832336426 ----\n",
      "1.024106502532959 ----\n",
      "1.0341150760650635 ----\n",
      "1.0481393337249756 ----\n",
      "1.0541324615478516 ----\n",
      "1.0642547607421875 ----\n",
      "1.0742661952972412 ----\n",
      "1.0862843990325928 ----\n",
      "1.0947074890136719 ----\n",
      "1.1049871444702148 ----\n",
      "1.1151738166809082 ----\n",
      "1.1251804828643799 ----\n",
      "1.1394896507263184 ----\n",
      "1.1494879722595215 ----\n",
      "1.159334421157837 ----\n",
      "1.1676571369171143 ----\n",
      "1.1751713752746582 ----\n",
      "1.185267686843872 ----\n",
      "1.195410966873169 ----\n",
      "1.2054758071899414 ----\n",
      "1.2159271240234375 ----\n",
      "1.2271709442138672 ----\n",
      "1.2377336025238037 ----\n",
      "1.2480285167694092 ----\n",
      "1.2582521438598633 ----\n",
      "1.2684321403503418 ----\n",
      "1.2784430980682373 ----\n",
      "1.2927656173706055 ----\n",
      "1.3027873039245605 ----\n",
      "1.3128085136413574 ----\n",
      "1.3208272457122803 ----\n",
      "1.333022117614746 ----\n",
      "1.3432531356811523 ----\n",
      "1.3481292724609375 ----\n",
      "1.3535804748535156 ----\n",
      "1.3673186302185059 ----\n",
      "1.3769781589508057 ----\n",
      "1.3869986534118652 ----\n",
      "1.3970224857330322 ----\n",
      "1.4070439338684082 ----\n",
      "1.4150619506835938 ----\n",
      "1.4230594635009766 ----\n",
      "1.4333057403564453 ----\n",
      "1.443315029144287 ----\n",
      "1.4533441066741943 ----\n",
      "1.4634077548980713 ----\n",
      "1.4772984981536865 ----\n",
      "1.4834976196289062 ----\n",
      "1.493666410446167 ----\n",
      "1.5040957927703857 ----\n",
      "1.5143020153045654 ----\n",
      "1.5243256092071533 ----\n",
      "1.5343396663665771 ----\n",
      "1.5445008277893066 ----\n",
      "1.558716058731079 ----\n",
      "1.5653095245361328 ----\n",
      "1.5777866840362549 ----\n",
      "1.5877909660339355 ----\n",
      "1.598210096359253 ----\n",
      "1.6082184314727783 ----\n",
      "1.6182224750518799 ----\n",
      "1.628706693649292 ----\n",
      "1.6387197971343994 ----\n",
      "1.6507391929626465 ----\n",
      "1.658747911453247 ----\n",
      "1.6687636375427246 ----\n",
      "1.6787803173065186 ----\n",
      "1.6888318061828613 ----\n",
      "1.6988458633422852 ----\n",
      "1.7088665962219238 ----\n",
      "1.7193663120269775 ----\n",
      "1.7296955585479736 ----\n",
      "1.739722728729248 ----\n",
      "1.7497272491455078 ----\n",
      "1.7617504596710205 ----\n",
      "1.7697577476501465 ----\n",
      "1.780266523361206 ----\n",
      "1.790271520614624 ----\n",
      "1.8023064136505127 ----\n",
      "1.8129518032073975 ----\n",
      "1.822972297668457 ----\n",
      "1.8329837322235107 ----\n",
      "1.8432388305664062 ----\n",
      "1.853280782699585 ----\n",
      "1.8653075695037842 ----\n",
      "1.8744192123413086 ----\n",
      "1.888880729675293 ----\n",
      "1.8948750495910645 ----\n",
      "1.9048848152160645 ----\n",
      "1.915025234222412 ----\n",
      "1.9270429611206055 ----\n",
      "1.9350523948669434 ----\n",
      "1.9450693130493164 ----\n",
      "1.9550838470458984 ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 1it [00:02,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9653503894805908 ----\n",
      "1.9753570556640625 ----\n",
      "1.9893746376037598 ----\n",
      "1.9953858852386475 ----\n",
      "2.0054023265838623 ----\n",
      "2.0154306888580322 ----\n",
      "2.025454044342041 ----\n",
      "2.2490127086639404 ----\n",
      "2.2593436241149902 ----\n",
      "2.2693519592285156 ----\n",
      "2.281252861022949 ----\n",
      "2.2955474853515625 ----\n",
      "2.3015544414520264 ----\n",
      "2.311558485031128 ----\n",
      "2.3215692043304443 ----\n",
      "2.3315906524658203 ----\n",
      "2.3419535160064697 ----\n",
      "2.351966619491577 ----\n",
      "2.36403226852417 ----\n",
      "2.372039794921875 ----\n",
      "2.3822128772735596 ----\n",
      "2.3942313194274902 ----\n",
      "2.402228355407715 ----\n",
      "2.412245273590088 ----\n",
      "2.4222524166107178 ----\n",
      "2.434581995010376 ----\n",
      "2.4442808628082275 ----\n",
      "2.456587076187134 ----\n",
      "2.462681531906128 ----\n",
      "2.4726991653442383 ----\n",
      "2.48272442817688 ----\n",
      "2.4964027404785156 ----\n",
      "2.5034291744232178 ----\n",
      "2.5136194229125977 ----\n",
      "2.5237624645233154 ----\n",
      "2.5350182056427 ----\n",
      "2.545856237411499 ----\n",
      "2.559525728225708 ----\n",
      "2.5655245780944824 ----\n",
      "2.5775630474090576 ----\n",
      "2.586320638656616 ----\n",
      "2.5963408946990967 ----\n",
      "2.606358289718628 ----\n",
      "2.618387460708618 ----\n",
      "2.626389265060425 ----\n",
      "2.6385550498962402 ----\n",
      "2.6466305255889893 ----\n",
      "2.662681818008423 ----\n",
      "2.6670546531677246 ----\n",
      "2.679123878479004 ----\n",
      "2.687133550643921 ----\n",
      "2.6971418857574463 ----\n",
      "2.7091522216796875 ----\n",
      "2.71752667427063 ----\n",
      "2.727181911468506 ----\n",
      "2.7392494678497314 ----\n",
      "2.747267961502075 ----\n",
      "2.759380578994751 ----\n",
      "2.7674343585968018 ----\n",
      "2.777540683746338 ----\n",
      "2.7875607013702393 ----\n",
      "2.7978873252868652 ----\n",
      "2.807791233062744 ----\n",
      "2.817821502685547 ----\n",
      "2.8299338817596436 ----\n",
      "2.837951421737671 ----\n",
      "2.847989559173584 ----\n",
      "2.8580148220062256 ----\n",
      "2.8683547973632812 ----\n",
      "2.8807992935180664 ----\n",
      "2.888801097869873 ----\n",
      "2.898810625076294 ----\n",
      "2.9088196754455566 ----\n",
      "2.9188239574432373 ----\n",
      "2.930103063583374 ----\n",
      "2.9403421878814697 ----\n",
      "2.9523541927337646 ----\n",
      "2.964402675628662 ----\n",
      "2.970402717590332 ----\n",
      "2.9824182987213135 ----\n",
      "2.9904346466064453 ----\n",
      "3.0004570484161377 ----\n",
      "3.010751247406006 ----\n",
      "3.0207715034484863 ----\n",
      "3.0327963829040527 ----\n",
      "3.0428311824798584 ----\n",
      "3.0512990951538086 ----\n",
      "3.0613105297088623 ----\n",
      "3.0753777027130127 ----\n",
      "3.081369400024414 ----\n",
      "3.0933876037597656 ----\n",
      "3.1013920307159424 ----\n",
      "3.11340594291687 ----\n",
      "3.1274337768554688 ----\n",
      "3.1354429721832275 ----\n",
      "3.145467758178711 ----\n",
      "3.1575310230255127 ----\n",
      "3.1656243801116943 ----\n",
      "3.1776442527770996 ----\n",
      "3.1856460571289062 ----\n",
      "3.195695400238037 ----\n",
      "3.205709218978882 ----\n",
      "3.215777635574341 ----\n",
      "3.227804660797119 ----\n",
      "3.2378218173980713 ----\n",
      "3.247992992401123 ----\n",
      "3.2564809322357178 ----\n",
      "3.2664954662323 ----\n",
      "3.2798919677734375 ----\n",
      "3.2908661365509033 ----\n",
      "3.2963600158691406 ----\n",
      "3.306363821029663 ----\n",
      "3.3163723945617676 ----\n",
      "3.328249454498291 ----\n",
      "3.3363869190216064 ----\n",
      "3.3466286659240723 ----\n",
      "3.358675003051758 ----\n",
      "3.3710782527923584 ----\n",
      "3.3770651817321777 ----\n",
      "3.3890931606292725 ----\n",
      "3.3971004486083984 ----\n",
      "3.4100892543792725 ----\n",
      "3.4177446365356445 ----\n",
      "3.427769422531128 ----\n",
      "3.4500582218170166 ----\n",
      "3.4582366943359375 ----\n",
      "3.468254566192627 ----\n",
      "3.4782726764678955 ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 2it [00:03,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.495086193084717 ----\n",
      "3.5011074542999268 ----\n",
      "3.5111353397369385 ----\n",
      "3.5221776962280273 ----\n",
      "3.5321900844573975 ----\n",
      "3.5422117710113525 ----\n",
      "3.555056095123291 ----\n",
      "3.78037428855896 ----\n",
      "3.790832281112671 ----\n",
      "3.8008694648742676 ----\n",
      "3.8108811378479004 ----\n",
      "3.820887565612793 ----\n",
      "3.831238269805908 ----\n",
      "3.841662883758545 ----\n",
      "3.8533098697662354 ----\n",
      "3.861325740814209 ----\n",
      "3.8753249645233154 ----\n",
      "3.8833694458007812 ----\n",
      "3.8913722038269043 ----\n",
      "3.9013798236846924 ----\n",
      "3.914522647857666 ----\n",
      "3.92339825630188 ----\n",
      "3.9334099292755127 ----\n",
      "3.9459848403930664 ----\n",
      "3.956009864807129 ----\n",
      "3.96802020072937 ----\n",
      "3.976036787033081 ----\n",
      "3.9860665798187256 ----\n",
      "3.9961936473846436 ----\n",
      "4.006199598312378 ----\n",
      "4.016249179840088 ----\n",
      "4.026258230209351 ----\n",
      "4.039780378341675 ----\n",
      "4.0459253787994385 ----\n",
      "4.0512855052948 ----\n",
      "4.065926551818848 ----\n",
      "4.075937509536743 ----\n",
      "4.086032390594482 ----\n",
      "4.096258163452148 ----\n",
      "4.106276512145996 ----\n",
      "4.116290807723999 ----\n",
      "4.126318693161011 ----\n",
      "4.13633918762207 ----\n",
      "4.146409034729004 ----\n",
      "4.158841848373413 ----\n",
      "4.1709818840026855 ----\n",
      "4.181007385253906 ----\n",
      "4.193185091018677 ----\n",
      "4.201392412185669 ----\n",
      "4.211403846740723 ----\n",
      "4.221423387527466 ----\n",
      "4.231444358825684 ----\n",
      "4.24183464050293 ----\n",
      "4.251857280731201 ----\n",
      "4.261887550354004 ----\n",
      "4.271939992904663 ----\n",
      "4.283786296844482 ----\n",
      "4.293794870376587 ----\n",
      "4.303800821304321 ----\n",
      "4.313919305801392 ----\n",
      "4.323937654495239 ----\n",
      "4.333966493606567 ----\n",
      "4.343978404998779 ----\n",
      "4.35405969619751 ----\n",
      "4.364077091217041 ----\n",
      "4.37408971786499 ----\n",
      "4.384111404418945 ----\n",
      "4.398819923400879 ----\n",
      "4.409015655517578 ----\n",
      "4.419523477554321 ----\n",
      "4.42498779296875 ----\n",
      "4.435008764266968 ----\n",
      "4.445088148117065 ----\n",
      "4.455095529556274 ----\n",
      "4.4691386222839355 ----\n",
      "4.475142240524292 ----\n",
      "4.48719334602356 ----\n",
      "4.497670888900757 ----\n",
      "4.50577187538147 ----\n",
      "4.519803524017334 ----\n",
      "4.525813817977905 ----\n",
      "4.536054611206055 ----\n",
      "4.546058893203735 ----\n",
      "4.556065559387207 ----\n",
      "4.566075801849365 ----\n",
      "4.576093435287476 ----\n",
      "4.5862274169921875 ----\n",
      "4.59623122215271 ----\n",
      "4.606315851211548 ----\n",
      "4.6167378425598145 ----\n",
      "4.627202987670898 ----\n",
      "4.637280702590942 ----\n",
      "4.647290468215942 ----\n",
      "4.65730094909668 ----\n",
      "4.677756071090698 ----\n",
      "4.685386896133423 ----\n",
      "4.6954264640808105 ----\n",
      "4.707438945770264 ----\n",
      "4.715447664260864 ----\n",
      "4.725736618041992 ----\n",
      "4.737763166427612 ----\n",
      "4.745990514755249 ----\n",
      "4.756007194519043 ----\n",
      "4.7660417556762695 ----\n",
      "4.77643084526062 ----\n",
      "4.786461591720581 ----\n",
      "4.7964818477630615 ----\n",
      "4.808511734008789 ----\n",
      "4.819254159927368 ----\n",
      "4.82686972618103 ----\n",
      "4.837022304534912 ----\n",
      "4.84904146194458 ----\n",
      "4.857043981552124 ----\n",
      "4.867055892944336 ----\n",
      "4.87708854675293 ----\n",
      "4.887319564819336 ----\n",
      "4.901051998138428 ----\n",
      "4.907353401184082 ----\n",
      "4.917385816574097 ----\n",
      "4.9312217235565186 ----\n",
      "4.943361759185791 ----\n",
      "4.955739974975586 ----\n",
      "4.965759754180908 ----\n",
      "4.979903697967529 ----\n",
      "4.9858996868133545 ----\n",
      "4.998258590698242 ----\n",
      "5.009521961212158 ----\n",
      "5.016458034515381 ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 3it [00:05,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.026949644088745 ----\n",
      "5.0369789600372314 ----\n",
      "5.049004793167114 ----\n",
      "5.0570151805877686 ----\n",
      "5.067426443099976 ----\n",
      "5.077442169189453 ----\n",
      "5.0876305103302 ----\n",
      "5.312392234802246 ----\n",
      "5.322707414627075 ----\n",
      "5.334729433059692 ----\n",
      "5.342980861663818 ----\n",
      "5.352993011474609 ----\n",
      "5.363447904586792 ----\n",
      "5.373119354248047 ----\n",
      "5.383134841918945 ----\n",
      "5.393147706985474 ----\n",
      "5.403159856796265 ----\n",
      "5.413175344467163 ----\n",
      "5.423192024230957 ----\n",
      "5.437305927276611 ----\n",
      "5.443463563919067 ----\n",
      "5.453469514846802 ----\n",
      "5.463474988937378 ----\n",
      "5.473923444747925 ----\n",
      "5.483933925628662 ----\n",
      "5.494425535202026 ----\n",
      "5.5039637088775635 ----\n",
      "5.516392946243286 ----\n",
      "5.524017572402954 ----\n",
      "5.534030437469482 ----\n",
      "5.544190168380737 ----\n",
      "5.558276414871216 ----\n",
      "5.564276695251465 ----\n",
      "5.574563503265381 ----\n",
      "5.586867094039917 ----\n",
      "5.594867706298828 ----\n",
      "5.60497784614563 ----\n",
      "5.617141008377075 ----\n",
      "5.626981258392334 ----\n",
      "5.6318583488464355 ----\n",
      "5.649573087692261 ----\n",
      "5.659590005874634 ----\n",
      "5.6696202754974365 ----\n",
      "5.680053949356079 ----\n",
      "5.692461967468262 ----\n",
      "5.7004663944244385 ----\n",
      "5.711542129516602 ----\n",
      "5.7215576171875 ----\n",
      "5.731565475463867 ----\n",
      "5.74157452583313 ----\n",
      "5.7520434856414795 ----\n",
      "5.762047529220581 ----\n",
      "5.772264003753662 ----\n",
      "5.7822887897491455 ----\n",
      "5.792431592941284 ----\n",
      "5.802446603775024 ----\n",
      "5.81245493888855 ----\n",
      "5.822481393814087 ----\n",
      "5.8324902057647705 ----\n",
      "5.842865467071533 ----\n",
      "5.852922677993774 ----\n",
      "5.862927675247192 ----\n",
      "5.872952222824097 ----\n",
      "5.882978916168213 ----\n",
      "5.894995212554932 ----\n",
      "5.907074451446533 ----\n",
      "5.917093992233276 ----\n",
      "5.9307215213775635 ----\n",
      "5.9375526905059814 ----\n",
      "5.951578617095947 ----\n",
      "5.957583904266357 ----\n",
      "5.967604637145996 ----\n",
      "5.977637767791748 ----\n",
      "5.989107131958008 ----\n",
      "6.001124620437622 ----\n",
      "6.009135484695435 ----\n",
      "6.019637584686279 ----\n",
      "6.029310941696167 ----\n",
      "6.039709568023682 ----\n",
      "6.052452087402344 ----\n",
      "6.05973482131958 ----\n",
      "6.069780111312866 ----\n",
      "6.080435037612915 ----\n",
      "6.090491533279419 ----\n",
      "6.100981950759888 ----\n",
      "6.113006114959717 ----\n",
      "6.121025800704956 ----\n",
      "6.135116338729858 ----\n",
      "6.141134977340698 ----\n",
      "6.151147365570068 ----\n",
      "6.16316556930542 ----\n",
      "6.171387672424316 ----\n",
      "6.183448553085327 ----\n",
      "6.193544626235962 ----\n",
      "6.20154595375061 ----\n",
      "6.211750507354736 ----\n",
      "6.221776008605957 ----\n",
      "6.231796979904175 ----\n",
      "6.24213719367981 ----\n",
      "6.252228260040283 ----\n",
      "6.2625367641448975 ----\n",
      "6.274558782577515 ----\n",
      "6.2825682163238525 ----\n",
      "6.292576551437378 ----\n",
      "6.302582502365112 ----\n",
      "6.312822341918945 ----\n",
      "6.324876308441162 ----\n",
      "6.334889650344849 ----\n",
      "6.347253322601318 ----\n",
      "6.353052377700806 ----\n",
      "6.363072156906128 ----\n",
      "6.373081207275391 ----\n",
      "6.383179187774658 ----\n",
      "6.396769046783447 ----\n",
      "6.41128945350647 ----\n",
      "6.426061630249023 ----\n",
      "6.436846733093262 ----\n",
      "6.44748067855835 ----\n",
      "6.457256078720093 ----\n",
      "6.472306728363037 ----\n",
      "6.4905006885528564 ----\n",
      "6.502516746520996 ----\n",
      "6.510521411895752 ----\n",
      "6.52118992805481 ----\n",
      "6.533767938613892 ----\n",
      "6.540984630584717 ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 4it [00:06,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.554898500442505 ----\n",
      "6.5610339641571045 ----\n",
      "6.571041822433472 ----\n",
      "6.581058025360107 ----\n",
      "6.591082334518433 ----\n",
      "6.601525068283081 ----\n",
      "6.616572380065918 ----\n",
      "6.621728420257568 ----\n",
      "6.631732702255249 ----\n",
      "6.861947774887085 ----\n",
      "6.874914646148682 ----\n",
      "6.885297060012817 ----\n",
      "6.897595405578613 ----\n",
      "6.917247295379639 ----\n",
      "6.931677579879761 ----\n",
      "6.947032690048218 ----\n",
      "6.9566969871521 ----\n",
      "6.966705799102783 ----\n",
      "6.976722955703735 ----\n",
      "6.986741542816162 ----\n",
      "6.997115135192871 ----\n",
      "7.009826898574829 ----\n",
      "7.017364740371704 ----\n",
      "7.027378559112549 ----\n",
      "7.037399530410767 ----\n",
      "7.047406911849976 ----\n",
      "7.059431076049805 ----\n",
      "7.067440032958984 ----\n",
      "7.081916093826294 ----\n",
      "7.087922811508179 ----\n",
      "7.1023924350738525 ----\n",
      "7.110394716262817 ----\n",
      "7.120535612106323 ----\n",
      "7.129572868347168 ----\n",
      "7.141598463058472 ----\n",
      "7.149637699127197 ----\n",
      "7.16002893447876 ----\n",
      "7.17004132270813 ----\n",
      "7.182065963745117 ----\n",
      "7.190079212188721 ----\n",
      "7.200093507766724 ----\n",
      "7.2101216316223145 ----\n",
      "7.22012996673584 ----\n",
      "7.230178117752075 ----\n",
      "7.240495920181274 ----\n",
      "7.250502109527588 ----\n",
      "7.260518312454224 ----\n",
      "7.274362325668335 ----\n",
      "7.284616231918335 ----\n",
      "7.294634103775024 ----\n",
      "7.304647207260132 ----\n",
      "7.314661741256714 ----\n",
      "7.324679851531982 ----\n",
      "7.334708213806152 ----\n",
      "7.344726324081421 ----\n",
      "7.354748964309692 ----\n",
      "7.366763114929199 ----\n",
      "7.374773025512695 ----\n",
      "7.385030269622803 ----\n",
      "7.39503812789917 ----\n",
      "7.405103921890259 ----\n",
      "7.4151153564453125 ----\n",
      "7.427356004714966 ----\n",
      "7.446148157119751 ----\n",
      "7.456667184829712 ----\n",
      "7.466233968734741 ----\n",
      "7.480467796325684 ----\n",
      "7.486483573913574 ----\n",
      "7.496487379074097 ----\n",
      "7.506906509399414 ----\n",
      "7.5169219970703125 ----\n",
      "7.527231931686401 ----\n",
      "7.539644241333008 ----\n",
      "7.549655914306641 ----\n",
      "7.557660818099976 ----\n",
      "7.568066596984863 ----\n",
      "7.578197240829468 ----\n",
      "7.588236093521118 ----\n",
      "7.598407030105591 ----\n",
      "7.608413934707642 ----\n",
      "7.618832349777222 ----\n",
      "7.628856420516968 ----\n",
      "7.638864994049072 ----\n",
      "7.65088677406311 ----\n",
      "7.66257905960083 ----\n",
      "7.669294357299805 ----\n",
      "7.67930006980896 ----\n",
      "7.689598560333252 ----\n",
      "7.699705123901367 ----\n",
      "7.709794998168945 ----\n",
      "7.719811916351318 ----\n",
      "7.730062246322632 ----\n",
      "7.743484973907471 ----\n",
      "7.750108242034912 ----\n",
      "7.760119438171387 ----\n",
      "7.770296812057495 ----\n",
      "7.792899131774902 ----\n",
      "7.805154323577881 ----\n",
      "7.815183401107788 ----\n",
      "7.823182821273804 ----\n",
      "7.831188440322876 ----\n",
      "7.843277454376221 ----\n",
      "7.855327367782593 ----\n",
      "7.861373424530029 ----\n",
      "7.875401735305786 ----\n",
      "7.881403207778931 ----\n",
      "7.895421504974365 ----\n",
      "7.901467323303223 ----\n",
      "7.911803245544434 ----\n",
      "7.921817302703857 ----\n",
      "7.9342124462127686 ----\n",
      "7.944460868835449 ----\n",
      "7.9544947147369385 ----\n",
      "7.968369483947754 ----\n",
      "7.983790397644043 ----\n",
      "7.997438907623291 ----\n",
      "8.007466077804565 ----\n",
      "8.017486333847046 ----\n",
      "8.02750849723816 ----\n",
      "8.033721923828125 ----\n",
      "8.044060468673706 ----\n",
      "8.056557416915894 ----\n",
      "8.065049171447754 ----\n",
      "8.075357437133789 ----\n",
      "8.087416887283325 ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 5it [00:08,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.102350950241089 ----\n",
      "8.105459690093994 ----\n",
      "8.115497350692749 ----\n",
      "8.125515699386597 ----\n",
      "8.13596796989441 ----\n",
      "8.14614462852478 ----\n",
      "8.156489372253418 ----\n",
      "8.176856279373169 ----\n",
      "8.18691110610962 ----\n",
      "8.196928262710571 ----\n",
      "8.208954095840454 ----\n",
      "8.218875408172607 ----\n",
      "8.441121101379395 ----\n",
      "8.453948259353638 ----\n",
      "8.470726251602173 ----\n",
      "8.489731311798096 ----\n",
      "8.50364875793457 ----\n",
      "8.50974726676941 ----\n",
      "8.520033836364746 ----\n",
      "8.53004765510559 ----\n",
      "8.54006314277649 ----\n",
      "8.550081968307495 ----\n",
      "8.560084819793701 ----\n",
      "8.570107221603394 ----\n",
      "8.580123901367188 ----\n",
      "8.590158939361572 ----\n",
      "8.600176811218262 ----\n",
      "8.610187768936157 ----\n",
      "8.622318744659424 ----\n",
      "8.632338285446167 ----\n",
      "8.64053750038147 ----\n",
      "8.651031970977783 ----\n",
      "8.661165237426758 ----\n",
      "8.67118525505066 ----\n",
      "8.681193828582764 ----\n",
      "8.691622972488403 ----\n",
      "8.70138692855835 ----\n",
      "8.711400032043457 ----\n",
      "8.721420764923096 ----\n",
      "8.731435537338257 ----\n",
      "8.741477489471436 ----\n",
      "8.751511096954346 ----\n",
      "8.763551712036133 ----\n",
      "8.781689643859863 ----\n",
      "8.79234004020691 ----\n",
      "8.802142858505249 ----\n",
      "8.812403678894043 ----\n",
      "8.822569370269775 ----\n",
      "8.832926273345947 ----\n",
      "8.846591472625732 ----\n",
      "8.856667518615723 ----\n",
      "8.86268949508667 ----\n",
      "8.872713327407837 ----\n",
      "8.882736206054688 ----\n",
      "8.89507508277893 ----\n",
      "8.902748346328735 ----\n",
      "8.912901639938354 ----\n",
      "8.922940969467163 ----\n",
      "8.93301272392273 ----\n",
      "8.947168111801147 ----\n",
      "8.956738233566284 ----\n",
      "8.97115707397461 ----\n",
      "8.986818790435791 ----\n",
      "9.001831293106079 ----\n",
      "9.011994123458862 ----\n",
      "9.024007081985474 ----\n",
      "9.032011985778809 ----\n",
      "9.042015314102173 ----\n",
      "9.052117109298706 ----\n",
      "9.062448740005493 ----\n",
      "9.072510242462158 ----\n",
      "9.086645364761353 ----\n",
      "9.09468960762024 ----\n",
      "9.102711200714111 ----\n",
      "9.112751960754395 ----\n",
      "9.126038312911987 ----\n",
      "9.132824897766113 ----\n",
      "9.144836187362671 ----\n",
      "9.153340578079224 ----\n",
      "9.162865161895752 ----\n",
      "9.174993515014648 ----\n",
      "9.183141708374023 ----\n",
      "9.1931471824646 ----\n",
      "9.203418493270874 ----\n",
      "9.216224908828735 ----\n",
      "9.223727703094482 ----\n",
      "9.233747482299805 ----\n",
      "9.243752002716064 ----\n",
      "9.254141807556152 ----\n",
      "9.267812013626099 ----\n",
      "9.273832321166992 ----\n",
      "9.283848762512207 ----\n",
      "9.293936491012573 ----\n",
      "9.303964138031006 ----\n",
      "9.313979387283325 ----\n",
      "9.3280189037323 ----\n",
      "9.336027145385742 ----\n",
      "9.344038009643555 ----\n",
      "9.354068040847778 ----\n",
      "9.366078853607178 ----\n",
      "9.374202728271484 ----\n",
      "9.387873649597168 ----\n",
      "9.396227836608887 ----\n",
      "9.40444278717041 ----\n",
      "9.414780139923096 ----\n",
      "9.426795244216919 ----\n",
      "9.434800386428833 ----\n",
      "9.444963455200195 ----\n",
      "9.457862377166748 ----\n",
      "9.471522092819214 ----\n",
      "9.480908632278442 ----\n",
      "9.496984958648682 ----\n",
      "9.513993740081787 ----\n",
      "9.5239999294281 ----\n",
      "9.534010171890259 ----\n",
      "9.546032905578613 ----\n",
      "9.554055452346802 ----\n",
      "9.566066026687622 ----\n",
      "9.576081037521362 ----\n",
      "9.584084749221802 ----\n",
      "9.59438681602478 ----\n",
      "9.606402397155762 ----\n",
      "9.614409685134888 ----\n",
      "9.624419927597046 ----\n",
      "9.634463548660278 ----\n",
      "9.644480228424072 ----\n",
      "9.654776334762573 ----\n",
      "9.666885614395142 ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 6it [00:09,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.679163694381714 ----\n",
      "9.68541932106018 ----\n",
      "9.695437908172607 ----\n",
      "9.705455780029297 ----\n",
      "9.715871572494507 ----\n",
      "9.726048231124878 ----\n",
      "9.738256216049194 ----\n",
      "9.746248960494995 ----\n",
      "9.758266925811768 ----\n",
      "9.77629017829895 ----\n",
      "9.787088394165039 ----\n",
      "9.797143459320068 ----\n",
      "10.02816128730774 ----\n",
      "10.038169860839844 ----\n",
      "10.048282146453857 ----\n",
      "10.060306549072266 ----\n",
      "10.068320989608765 ----\n",
      "10.080460548400879 ----\n",
      "10.08852744102478 ----\n",
      "10.098538875579834 ----\n",
      "10.108551979064941 ----\n",
      "10.118557929992676 ----\n",
      "10.139065742492676 ----\n",
      "10.153203964233398 ----\n",
      "10.159204721450806 ----\n",
      "10.16920804977417 ----\n",
      "10.179218053817749 ----\n",
      "10.193256616592407 ----\n",
      "10.19938850402832 ----\n",
      "10.20942234992981 ----\n",
      "10.219735860824585 ----\n",
      "10.23311185836792 ----\n",
      "10.240138292312622 ----\n",
      "10.250144004821777 ----\n",
      "10.260154962539673 ----\n",
      "10.270159244537354 ----\n",
      "10.280167818069458 ----\n",
      "10.29018521308899 ----\n",
      "10.300202369689941 ----\n",
      "10.310217142105103 ----\n",
      "10.320364952087402 ----\n",
      "10.330370664596558 ----\n",
      "10.34037971496582 ----\n",
      "10.35039496421814 ----\n",
      "10.36040449142456 ----\n",
      "10.370414733886719 ----\n",
      "10.380426406860352 ----\n",
      "10.390434741973877 ----\n",
      "10.40044116973877 ----\n",
      "10.412324905395508 ----\n",
      "10.420868396759033 ----\n",
      "10.431905031204224 ----\n",
      "10.442365169525146 ----\n",
      "10.453943252563477 ----\n",
      "10.465592861175537 ----\n",
      "10.472079992294312 ----\n",
      "10.482085466384888 ----\n",
      "10.495100021362305 ----\n",
      "10.510401964187622 ----\n",
      "10.521424770355225 ----\n",
      "10.530928611755371 ----\n",
      "10.540944814682007 ----\n",
      "10.551138877868652 ----\n",
      "10.56116271018982 ----\n",
      "10.571170806884766 ----\n",
      "10.581196308135986 ----\n",
      "10.59168291091919 ----\n",
      "10.601701974868774 ----\n",
      "10.611709117889404 ----\n",
      "10.621765613555908 ----\n",
      "10.63203239440918 ----\n",
      "10.646487951278687 ----\n",
      "10.654600381851196 ----\n",
      "10.662512302398682 ----\n",
      "10.672519445419312 ----\n",
      "10.686661005020142 ----\n",
      "10.694681406021118 ----\n",
      "10.706706762313843 ----\n",
      "10.712870836257935 ----\n",
      "10.72288703918457 ----\n",
      "10.732912302017212 ----\n",
      "10.747173309326172 ----\n",
      "10.753557205200195 ----\n",
      "10.767878293991089 ----\n",
      "10.778791904449463 ----\n",
      "10.801780223846436 ----\n",
      "10.811857223510742 ----\n",
      "10.828913927078247 ----\n",
      "10.842094898223877 ----\n",
      "10.848117351531982 ----\n",
      "10.852132320404053 ----\n",
      "10.866746187210083 ----\n",
      "10.88075304031372 ----\n",
      "10.891719341278076 ----\n",
      "10.903802633285522 ----\n",
      "10.9138343334198 ----\n",
      "10.925868034362793 ----\n",
      "10.933897256851196 ----\n",
      "10.943936109542847 ----\n",
      "10.951924800872803 ----\n",
      "10.962035894393921 ----\n",
      "10.973450422286987 ----\n",
      "10.983308553695679 ----\n",
      "10.997506380081177 ----\n",
      "11.013291597366333 ----\n",
      "11.029511451721191 ----\n",
      "11.037338972091675 ----\n",
      "11.049618005752563 ----\n",
      "11.058663129806519 ----\n",
      "11.068669080734253 ----\n",
      "11.07938003540039 ----\n",
      "11.08906888961792 ----\n",
      "11.099073648452759 ----\n",
      "11.109363794326782 ----\n",
      "11.119385719299316 ----\n",
      "11.12938928604126 ----\n",
      "11.139394044876099 ----\n",
      "11.151736974716187 ----\n",
      "11.159737348556519 ----\n",
      "11.16975736618042 ----\n",
      "11.183796405792236 ----\n",
      "11.191798686981201 ----\n",
      "11.206185340881348 ----\n",
      "11.214191675186157 ----\n",
      "11.224212408065796 ----\n",
      "11.234306335449219 ----\n",
      "11.244311809539795 ----\n",
      "11.256686449050903 ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 7it [00:11,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.269317865371704 ----\n",
      "11.279030323028564 ----\n",
      "11.28948450088501 ----\n",
      "11.299506664276123 ----\n",
      "11.309850692749023 ----\n",
      "11.319967269897461 ----\n",
      "11.329972267150879 ----\n",
      "11.342030763626099 ----\n",
      "11.350027799606323 ----\n",
      "11.36040472984314 ----\n",
      "11.37051248550415 ----\n",
      "11.38121247291565 ----\n",
      "11.60758638381958 ----\n",
      "11.619598388671875 ----\n",
      "11.627609491348267 ----\n",
      "11.637622594833374 ----\n",
      "11.64764142036438 ----\n",
      "11.657845735549927 ----\n",
      "11.667861938476562 ----\n",
      "11.678088665008545 ----\n",
      "11.690487146377563 ----\n",
      "11.700738430023193 ----\n",
      "11.70841360092163 ----\n",
      "11.718823909759521 ----\n",
      "11.72885799407959 ----\n",
      "11.73888111114502 ----\n",
      "11.748898983001709 ----\n",
      "11.758914470672607 ----\n",
      "11.769226312637329 ----\n",
      "11.779554605484009 ----\n",
      "11.789997100830078 ----\n",
      "11.800437927246094 ----\n",
      "11.810450553894043 ----\n",
      "11.820550441741943 ----\n",
      "11.832584381103516 ----\n",
      "11.840084791183472 ----\n",
      "11.850100994110107 ----\n",
      "11.86056900024414 ----\n",
      "11.87261176109314 ----\n",
      "11.884415626525879 ----\n",
      "11.890382289886475 ----\n",
      "11.902419567108154 ----\n",
      "11.912474632263184 ----\n",
      "11.922479391098022 ----\n",
      "11.93269157409668 ----\n",
      "11.946649074554443 ----\n",
      "11.952956438064575 ----\n",
      "11.962979078292847 ----\n",
      "11.973125696182251 ----\n",
      "11.98539662361145 ----\n",
      "11.995509147644043 ----\n",
      "12.011002779006958 ----\n",
      "12.025882244110107 ----\n",
      "12.041229009628296 ----\n",
      "12.051250457763672 ----\n",
      "12.061744689941406 ----\n",
      "12.071758508682251 ----\n",
      "12.08188247680664 ----\n",
      "12.092135667800903 ----\n",
      "12.102156639099121 ----\n",
      "12.112461805343628 ----\n",
      "12.122514963150024 ----\n",
      "12.132532835006714 ----\n",
      "12.142966270446777 ----\n",
      "12.155007123947144 ----\n",
      "12.163022994995117 ----\n",
      "12.175071716308594 ----\n",
      "12.182679414749146 ----\n",
      "12.192694902420044 ----\n",
      "12.205130100250244 ----\n",
      "12.21315312385559 ----\n",
      "12.225181102752686 ----\n",
      "12.233590364456177 ----\n",
      "12.249855756759644 ----\n",
      "12.264209747314453 ----\n",
      "12.272176742553711 ----\n",
      "12.280198812484741 ----\n",
      "12.292230129241943 ----\n",
      "12.300240993499756 ----\n",
      "12.310508728027344 ----\n",
      "12.320523262023926 ----\n",
      "12.33254361152649 ----\n",
      "12.343649625778198 ----\n",
      "12.350578546524048 ----\n",
      "12.360584020614624 ----\n",
      "12.370937824249268 ----\n",
      "12.380967855453491 ----\n",
      "12.391297101974487 ----\n",
      "12.401623010635376 ----\n",
      "12.41171908378601 ----\n",
      "12.421933889389038 ----\n",
      "12.431945085525513 ----\n",
      "12.441974639892578 ----\n",
      "12.451989889144897 ----\n",
      "12.461995363235474 ----\n",
      "12.47227954864502 ----\n",
      "12.482300996780396 ----\n",
      "12.496141910552979 ----\n",
      "12.505813360214233 ----\n",
      "12.51997184753418 ----\n",
      "12.536977291107178 ----\n",
      "12.54764175415039 ----\n",
      "12.555235862731934 ----\n",
      "12.563063383102417 ----\n",
      "12.573177099227905 ----\n",
      "12.58319878578186 ----\n",
      "12.593709945678711 ----\n",
      "12.603729963302612 ----\n",
      "12.613738059997559 ----\n",
      "12.623923301696777 ----\n",
      "12.637775897979736 ----\n",
      "12.644180059432983 ----\n",
      "12.65421199798584 ----\n",
      "12.664580345153809 ----\n",
      "12.680085182189941 ----\n",
      "12.689162731170654 ----\n",
      "12.695178270339966 ----\n",
      "12.705432891845703 ----\n",
      "12.715632438659668 ----\n",
      "12.725874423980713 ----\n",
      "12.736051321029663 ----\n",
      "12.746099472045898 ----\n",
      "12.756529331207275 ----\n",
      "12.76682996749878 ----\n",
      "12.777201414108276 ----\n",
      "12.78722357749939 ----\n",
      "12.797241449356079 ----\n",
      "12.807364702224731 ----\n",
      "12.817373991012573 ----\n",
      "12.827634334564209 ----\n",
      "12.837867259979248 ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 8it [00:12,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.84788179397583 ----\n",
      "12.858232736587524 ----\n",
      "12.868499517440796 ----\n",
      "12.881017684936523 ----\n",
      "12.889501571655273 ----\n",
      "12.911750555038452 ----\n",
      "12.919515132904053 ----\n",
      "12.929736852645874 ----\n",
      "12.939748764038086 ----\n",
      "13.189582586288452 ----\n",
      "13.199586868286133 ----\n",
      "13.209752798080444 ----\n",
      "13.219771146774292 ----\n",
      "13.229872226715088 ----\n",
      "13.239903211593628 ----\n",
      "13.260460615158081 ----\n",
      "13.27281904220581 ----\n",
      "13.280831813812256 ----\n",
      "13.29121470451355 ----\n",
      "13.300922155380249 ----\n",
      "13.314786672592163 ----\n",
      "13.32297682762146 ----\n",
      "13.331016302108765 ----\n",
      "13.341142654418945 ----\n",
      "13.353586196899414 ----\n",
      "13.361613988876343 ----\n",
      "13.371623754501343 ----\n",
      "13.384751081466675 ----\n",
      "13.401554822921753 ----\n",
      "13.417024850845337 ----\n",
      "13.42312741279602 ----\n",
      "13.433692693710327 ----\n",
      "13.45397400856018 ----\n",
      "13.464471817016602 ----\n",
      "13.474496364593506 ----\n",
      "13.484906911849976 ----\n",
      "13.494930028915405 ----\n",
      "13.507215738296509 ----\n",
      "13.53094744682312 ----\n",
      "13.545873403549194 ----\n",
      "13.56189775466919 ----\n",
      "13.571909427642822 ----\n",
      "13.586000680923462 ----\n",
      "13.594228506088257 ----\n",
      "13.604595422744751 ----\n",
      "13.614601135253906 ----\n",
      "13.622618198394775 ----\n",
      "13.634679794311523 ----\n",
      "13.642934799194336 ----\n",
      "13.653112888336182 ----\n",
      "13.66311764717102 ----\n",
      "13.676172018051147 ----\n",
      "13.69113826751709 ----\n",
      "13.698281049728394 ----\n",
      "13.710546016693115 ----\n",
      "13.7205810546875 ----\n",
      "13.726596355438232 ----\n",
      "13.736736059188843 ----\n",
      "13.746315002441406 ----\n",
      "13.756322860717773 ----\n",
      "13.766334295272827 ----\n",
      "13.780230522155762 ----\n",
      "13.78520154953003 ----\n",
      "13.800617218017578 ----\n",
      "13.815992593765259 ----\n",
      "13.821360111236572 ----\n",
      "13.831269264221191 ----\n",
      "13.841371774673462 ----\n",
      "13.85139012336731 ----\n",
      "13.863409996032715 ----\n",
      "13.871397256851196 ----\n",
      "13.881779670715332 ----\n",
      "13.891798973083496 ----\n",
      "13.905680656433105 ----\n",
      "13.913861989974976 ----\n",
      "13.92188549041748 ----\n",
      "13.935724020004272 ----\n",
      "13.942389726638794 ----\n",
      "13.952472686767578 ----\n",
      "13.964502573013306 ----\n",
      "13.972586870193481 ----\n",
      "13.984663009643555 ----\n",
      "13.995105266571045 ----\n",
      "14.003502368927002 ----\n",
      "14.017426013946533 ----\n",
      "14.024520874023438 ----\n",
      "14.038205623626709 ----\n",
      "14.054942846298218 ----\n",
      "14.069973945617676 ----\n",
      "14.076076984405518 ----\n",
      "14.088214635848999 ----\n",
      "14.096734762191772 ----\n",
      "14.110395669937134 ----\n",
      "14.116842269897461 ----\n",
      "14.126868724822998 ----\n",
      "14.137354612350464 ----\n",
      "14.147368669509888 ----\n",
      "14.159591913223267 ----\n",
      "14.16767930984497 ----\n",
      "14.17969036102295 ----\n",
      "14.189710140228271 ----\n",
      "14.197861671447754 ----\n",
      "14.219791412353516 ----\n",
      "14.244304656982422 ----\n",
      "14.254328966140747 ----\n",
      "14.266387462615967 ----\n",
      "14.274547338485718 ----\n",
      "14.28446340560913 ----\n",
      "14.294477701187134 ----\n",
      "14.304495334625244 ----\n",
      "14.314515590667725 ----\n",
      "14.324518918991089 ----\n",
      "14.334598302841187 ----\n",
      "14.34708309173584 ----\n",
      "14.355083703994751 ----\n",
      "14.367100715637207 ----\n",
      "14.375415563583374 ----\n",
      "14.385431289672852 ----\n",
      "14.395449876785278 ----\n",
      "14.403951168060303 ----\n",
      "14.413963556289673 ----\n",
      "14.424351453781128 ----\n",
      "14.434430837631226 ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 9it [00:14,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.4447340965271 ----\n",
      "14.455212354660034 ----\n",
      "14.46723198890686 ----\n",
      "14.475545883178711 ----\n",
      "14.485567808151245 ----\n",
      "14.497865915298462 ----\n",
      "14.509652137756348 ----\n",
      "14.521694898605347 ----\n",
      "14.533662796020508 ----\n",
      "14.542586326599121 ----\n",
      "14.5584397315979 ----\n",
      "14.570865154266357 ----\n",
      "14.587706804275513 ----\n",
      "14.601625680923462 ----\n",
      "14.824790239334106 ----\n",
      "14.832798480987549 ----\n",
      "14.842810869216919 ----\n",
      "14.853212118148804 ----\n",
      "14.863216400146484 ----\n",
      "14.87339186668396 ----\n",
      "14.883416414260864 ----\n",
      "14.89366626739502 ----\n",
      "14.903682947158813 ----\n",
      "14.91580605506897 ----\n",
      "14.924017429351807 ----\n",
      "14.93448781967163 ----\n",
      "14.944652557373047 ----\n",
      "14.954672574996948 ----\n",
      "14.96869158744812 ----\n",
      "14.981126070022583 ----\n",
      "14.996874570846558 ----\n",
      "15.005215644836426 ----\n",
      "15.019260168075562 ----\n",
      "15.028979301452637 ----\n",
      "15.03564453125 ----\n",
      "15.05754566192627 ----\n",
      "15.071215391159058 ----\n",
      "15.081130266189575 ----\n",
      "15.091156244277954 ----\n",
      "15.101181507110596 ----\n",
      "15.107194423675537 ----\n",
      "15.132265329360962 ----\n",
      "15.149165153503418 ----\n",
      "15.161190509796143 ----\n",
      "15.169206619262695 ----\n",
      "15.175217151641846 ----\n",
      "15.185235977172852 ----\n",
      "15.20038366317749 ----\n",
      "15.209402322769165 ----\n",
      "15.219423532485962 ----\n",
      "15.229441404342651 ----\n",
      "15.239458799362183 ----\n",
      "15.249642848968506 ----\n",
      "15.261698007583618 ----\n",
      "15.269721508026123 ----\n",
      "15.279751062393188 ----\n",
      "15.289777517318726 ----\n",
      "15.299802303314209 ----\n",
      "15.305816411972046 ----\n",
      "15.31849217414856 ----\n",
      "15.328895807266235 ----\n",
      "15.339427471160889 ----\n",
      "15.349474906921387 ----\n",
      "15.369581937789917 ----\n",
      "15.37982964515686 ----\n",
      "15.390042066574097 ----\n",
      "15.399929523468018 ----\n",
      "15.410866022109985 ----\n",
      "15.421164989471436 ----\n",
      "15.431204319000244 ----\n",
      "15.441223859786987 ----\n",
      "15.45570158958435 ----\n",
      "15.465471982955933 ----\n",
      "15.471855401992798 ----\n",
      "15.481859683990479 ----\n",
      "15.491873264312744 ----\n",
      "15.50391149520874 ----\n",
      "15.51285982131958 ----\n",
      "15.52286958694458 ----\n",
      "15.532947778701782 ----\n",
      "15.545081853866577 ----\n",
      "15.556936502456665 ----\n",
      "15.563565969467163 ----\n",
      "15.575679302215576 ----\n",
      "15.585684537887573 ----\n",
      "15.59414029121399 ----\n",
      "15.621952772140503 ----\n",
      "15.63414478302002 ----\n",
      "15.649293661117554 ----\n",
      "15.68378496170044 ----\n",
      "15.69904613494873 ----\n",
      "15.714739084243774 ----\n",
      "15.71923565864563 ----\n",
      "15.74644136428833 ----\n",
      "15.751629114151001 ----\n",
      "15.76163363456726 ----\n",
      "15.773561954498291 ----\n",
      "15.781696557998657 ----\n",
      "15.791808605194092 ----\n",
      "15.803843975067139 ----\n",
      "15.809985637664795 ----\n",
      "15.822287797927856 ----\n",
      "15.830311298370361 ----\n",
      "15.840331077575684 ----\n",
      "15.852595806121826 ----\n",
      "15.860621213912964 ----\n",
      "15.872801780700684 ----\n",
      "15.880804777145386 ----\n",
      "15.890824317932129 ----\n",
      "15.904886484146118 ----\n",
      "15.910704851150513 ----\n",
      "15.920718908309937 ----\n",
      "15.930748224258423 ----\n",
      "15.942795276641846 ----\n",
      "15.951476573944092 ----\n",
      "15.961499452590942 ----\n",
      "15.971567392349243 ----\n",
      "15.981585264205933 ----\n",
      "15.991654396057129 ----\n",
      "16.002137422561646 ----\n",
      "16.01248574256897 ----\n",
      "16.022942781448364 ----\n",
      "16.033414125442505 ----\n",
      "16.052809238433838 ----\n",
      "16.056155681610107 ----\n",
      "16.075013875961304 ----\n",
      "16.085185050964355 ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 10it [00:16,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.09319567680359 ----\n",
      "16.103493452072144 ----\n",
      "16.116807460784912 ----\n",
      "16.127755403518677 ----\n",
      "16.13545846939087 ----\n",
      "16.15235733985901 ----\n",
      "16.16732120513916 ----\n",
      "16.176859378814697 ----\n",
      "16.188177824020386 ----\n",
      "16.19336700439453 ----\n",
      "16.203380346298218 ----\n",
      "16.21736741065979 ----\n",
      "16.22365713119507 ----\n",
      "16.235753059387207 ----\n",
      "16.24577260017395 ----\n",
      "16.50809597969055 ----\n",
      "16.520601511001587 ----\n",
      "16.528500080108643 ----\n",
      "16.53873348236084 ----\n",
      "16.54875636100769 ----\n",
      "16.56079912185669 ----\n",
      "16.569385528564453 ----\n",
      "16.5794038772583 ----\n",
      "16.58944344520569 ----\n",
      "16.60147190093994 ----\n",
      "16.6200008392334 ----\n",
      "16.63289475440979 ----\n",
      "16.650169134140015 ----\n",
      "16.67665433883667 ----\n",
      "16.69641375541687 ----\n",
      "16.71222686767578 ----\n",
      "16.716642379760742 ----\n",
      "16.72698187828064 ----\n",
      "16.737086534500122 ----\n",
      "16.74739933013916 ----\n",
      "16.75749921798706 ----\n",
      "16.767587184906006 ----\n",
      "16.777795553207397 ----\n",
      "16.78752064704895 ----\n",
      "16.799578428268433 ----\n",
      "16.811472415924072 ----\n",
      "16.817832708358765 ----\n",
      "16.829880237579346 ----\n",
      "16.83998441696167 ----\n",
      "16.84799575805664 ----\n",
      "16.858017683029175 ----\n",
      "16.868374586105347 ----\n",
      "16.890419721603394 ----\n",
      "16.905652046203613 ----\n",
      "16.915663480758667 ----\n",
      "16.93585181236267 ----\n",
      "16.96624732017517 ----\n",
      "16.976565837860107 ----\n",
      "16.996838808059692 ----\n",
      "17.0068576335907 ----\n",
      "17.01687479019165 ----\n",
      "17.026878833770752 ----\n",
      "17.037107706069946 ----\n",
      "17.047178745269775 ----\n",
      "17.05719566345215 ----\n",
      "17.0692400932312 ----\n",
      "17.077570915222168 ----\n",
      "17.08964967727661 ----\n",
      "17.098009824752808 ----\n",
      "17.10802435874939 ----\n",
      "17.118394136428833 ----\n",
      "17.12840986251831 ----\n",
      "17.144359827041626 ----\n",
      "17.159359216690063 ----\n",
      "17.177664279937744 ----\n",
      "17.18776249885559 ----\n",
      "17.201993942260742 ----\n",
      "17.207837104797363 ----\n",
      "17.218398571014404 ----\n",
      "17.22873020172119 ----\n",
      "17.239099502563477 ----\n",
      "17.24960732460022 ----\n",
      "17.26005721092224 ----\n",
      "17.27032470703125 ----\n",
      "17.280858755111694 ----\n",
      "17.2910578250885 ----\n",
      "17.301258087158203 ----\n",
      "17.313148021697998 ----\n",
      "17.326045036315918 ----\n",
      "17.332095861434937 ----\n",
      "17.34210991859436 ----\n",
      "17.352280855178833 ----\n",
      "17.364310264587402 ----\n",
      "17.372315645217896 ----\n",
      "17.38235855102539 ----\n",
      "17.39449644088745 ----\n",
      "17.402889013290405 ----\n",
      "17.412930727005005 ----\n",
      "17.423253774642944 ----\n",
      "17.433300018310547 ----\n",
      "17.443329334259033 ----\n",
      "17.453521251678467 ----\n",
      "17.47329807281494 ----\n",
      "17.4902241230011 ----\n",
      "17.501630306243896 ----\n",
      "17.50653648376465 ----\n",
      "17.51657485961914 ----\n",
      "17.526585817337036 ----\n",
      "17.540821313858032 ----\n",
      "17.5469491481781 ----\n",
      "17.561514139175415 ----\n",
      "17.577015161514282 ----\n",
      "17.581461668014526 ----\n",
      "17.596705675125122 ----\n",
      "17.606776237487793 ----\n",
      "17.617024183273315 ----\n",
      "17.627042055130005 ----\n",
      "17.639076948165894 ----\n",
      "17.6510968208313 ----\n",
      "17.661290645599365 ----\n",
      "17.671388626098633 ----\n",
      "17.681408166885376 ----\n",
      "17.69160294532776 ----\n",
      "17.70185112953186 ----\n",
      "17.71185803413391 ----\n",
      "17.72214412689209 ----\n",
      "17.73215365409851 ----\n",
      "17.744603157043457 ----\n",
      "17.762736082077026 ----\n",
      "17.77664065361023 ----\n",
      "17.78278636932373 ----\n",
      "17.792818546295166 ----\n",
      "17.80284309387207 ----\n",
      "17.812865495681763 ----\n",
      "17.82288384437561 ----\n",
      "17.834864377975464 ----\n",
      "17.84489607810974 ----\n",
      "17.855157613754272 ----\n",
      "17.865262269973755 ----\n",
      "17.875282526016235 ----\n",
      "17.885308742523193 ----\n",
      "17.897431135177612 ----\n",
      "17.908251762390137 ----\n",
      "17.92027449607849 ----\n",
      "17.930691480636597 ----\n",
      "17.940696239471436 ----\n",
      "17.948742151260376 ----\n",
      "17.961153745651245 ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 12it [00:18,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.009217023849487 ----\n",
      "18.02262282371521 ----\n",
      "18.028911352157593 ----\n",
      "18.038928508758545 ----\n",
      "18.04893398284912 ----\n",
      "18.05896830558777 ----\n",
      "18.071008443832397 ----\n",
      "18.08152198791504 ----\n",
      "18.093534469604492 ----\n",
      "18.101686000823975 ----\n",
      "18.11176037788391 ----\n",
      "18.121366024017334 ----\n",
      "18.131374835968018 ----\n",
      "18.14139747619629 ----\n",
      "18.153422355651855 ----\n",
      "18.16356086730957 ----\n",
      "18.17356824874878 ----\n",
      "18.183578729629517 ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理进度: 12it [00:18,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.200161933898926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "831ccdc6a67af6b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:41:22.257848Z",
     "start_time": "2025-05-25T08:41:22.247699Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f88c1018d97b9203",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:41:22.412029Z",
     "start_time": "2025-05-25T08:41:22.401724Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "97246724ac7e9fcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:41:22.539245Z",
     "start_time": "2025-05-25T08:41:22.528826Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fdd40ef51c3264b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:41:22.720384Z",
     "start_time": "2025-05-25T08:41:22.710199Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a3cf97f636c3a805",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:41:32.346894Z",
     "start_time": "2025-05-25T08:41:32.334603Z"
    }
   },
   "cell_type": "code",
   "source": "print(2)",
   "id": "32d85598fb455b52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:51:27.699867Z",
     "start_time": "2025-05-25T08:51:24.339330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "import threading\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import audio\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import face_detection\n",
    "from models import Wav2Lip\n",
    "\n",
    "mel_step_size = 16\n",
    "\n",
    "def _load(checkpoint_path):\n",
    "    if device == 'cuda':\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
    "    return checkpoint\n",
    "\n",
    "def load_model(path):\n",
    "    model = Wav2Lip()\n",
    "    print(f\"从 {path} 加载模型\")\n",
    "    checkpoint = _load(path)\n",
    "    new_s = {}\n",
    "    for k, v in checkpoint[\"state_dict\"].items():\n",
    "        new_s[k.replace('module.', '')] = v\n",
    "    model.load_state_dict(new_s)\n",
    "    model = model.to(device)\n",
    "    return model.eval()\n",
    "\n",
    "def preprocess_image(\n",
    "    image_path,\n",
    "    pads=[0,10,0,0],\n",
    "    box=[-1,-1,-1,-1],\n",
    "    img_size=96,\n",
    "    face_det_batch_size=16,\n",
    "    nosmooth=False,\n",
    "    device='cuda'\n",
    "):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"无法读取图片: {image_path}\")\n",
    "    if box[0] == -1:\n",
    "        detector = face_detection.FaceAlignment(face_detection.LandmarksType._2D, flip_input=False, device=device)\n",
    "        predictions = detector.get_detections_for_batch(np.array([image]))\n",
    "        rect = predictions[0]\n",
    "        if rect is None:\n",
    "            raise RuntimeError(\"未检测到人脸\")\n",
    "        pady1, pady2, padx1, padx2 = pads\n",
    "        y1 = max(0, rect[1] - pady1)\n",
    "        y2 = min(image.shape[0], rect[3] + pady2)\n",
    "        x1 = max(0, rect[0] - padx1)\n",
    "        x2 = min(image.shape[1], rect[2] + padx2)\n",
    "    else:\n",
    "        y1, y2, x1, x2 = box\n",
    "    face = image[y1:y2, x1:x2]\n",
    "    face = cv2.resize(face, (img_size, img_size))\n",
    "    coords = (y1, y2, x1, x2)\n",
    "    return face, coords, image\n",
    "\n",
    "def prepare_audio_batches(\n",
    "    audio_path,\n",
    "    face_img,\n",
    "    face_coords,\n",
    "    static=True,\n",
    "    fps=25,\n",
    "    mel_step_size=16,\n",
    "    wav2lip_batch_size=128,\n",
    "    img_size=96\n",
    "):\n",
    "    if not audio_path.endswith('.wav'):\n",
    "        print('提取音频...')\n",
    "        command = f'ffmpeg -y -i \"{audio_path}\" -strict -2 temp/temp.wav'\n",
    "        subprocess.call(command, shell=True)\n",
    "        audio_path = 'temp/temp.wav'\n",
    "    wav = audio.load_wav(audio_path, 16000)\n",
    "    mel = audio.melspectrogram(wav)\n",
    "    if np.isnan(mel.reshape(-1)).sum() > 0:\n",
    "        raise ValueError('梅尔频谱包含NaN值，请检查音频质量')\n",
    "    mel_idx_multiplier = 80. / fps\n",
    "    mel_chunks = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        start_idx = int(i * mel_idx_multiplier)\n",
    "        if start_idx + mel_step_size > len(mel[0]):\n",
    "            mel_chunks.append(mel[:, len(mel[0]) - mel_step_size:])\n",
    "            break\n",
    "        mel_chunks.append(mel[:, start_idx: start_idx + mel_step_size])\n",
    "        i += 1\n",
    "    img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "    for i, m in enumerate(mel_chunks):\n",
    "        frame_to_save = face_img.copy()\n",
    "        face = face_img.copy()\n",
    "        coords = face_coords\n",
    "        img_batch.append(face)\n",
    "        mel_batch.append(m)\n",
    "        frame_batch.append(frame_to_save)\n",
    "        coords_batch.append(coords)\n",
    "        if len(img_batch) >= wav2lip_batch_size:\n",
    "            img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "            img_masked = img_batch.copy()\n",
    "            img_masked[:, img_size // 2:] = 0\n",
    "            img_input = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "            mel_input = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "            yield img_input, mel_input, frame_batch, coords_batch\n",
    "            img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "    if len(img_batch) > 0:\n",
    "        img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "        img_masked = img_batch.copy()\n",
    "        img_masked[:, img_size // 2:] = 0\n",
    "        img_input = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "        mel_input = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "        yield img_input, mel_input, frame_batch, coords_batch\n",
    "\n",
    "def play_audio_stream(audio_path, start_event, stop_event):\n",
    "    data, samplerate = sf.read(audio_path)\n",
    "    if len(data.shape) == 1:\n",
    "        data = data[:, None]\n",
    "    def callback(outdata, frames, time_, status):\n",
    "        start_event.wait()\n",
    "        if stop_event.is_set():\n",
    "            raise sd.CallbackAbort\n",
    "        chunk = data[callback.idx:callback.idx+frames]\n",
    "        if len(chunk) < frames:\n",
    "            outdata[:len(chunk)] = chunk\n",
    "            outdata[len(chunk):] = 0\n",
    "            stop_event.set()\n",
    "            raise sd.CallbackStop\n",
    "        else:\n",
    "            outdata[:] = chunk\n",
    "        callback.idx += frames\n",
    "    callback.idx = 0\n",
    "    with sd.OutputStream(channels=data.shape[1], samplerate=samplerate, callback=callback):\n",
    "        start_event.wait()\n",
    "        while not stop_event.is_set() and callback.idx < len(data):\n",
    "            sd.sleep(100)\n",
    "\n",
    "def wav2lip_sync_play(\n",
    "    model,\n",
    "    gen,\n",
    "    device,\n",
    "    orig_image,\n",
    "    coords,\n",
    "    audio_path,\n",
    "    fps=25,\n",
    "    window_size=(224, 336),\n",
    "    show_window=True,\n",
    "    window_name=\"Wav2Lip Result\"\n",
    "):\n",
    "    global a\n",
    "    start_event = threading.Event()\n",
    "    stop_event = threading.Event()\n",
    "    audio_thread = threading.Thread(target=play_audio_stream, args=(audio_path, start_event, stop_event))\n",
    "    audio_thread.start()\n",
    "\n",
    "    frame_interval = 1.0 / fps\n",
    "    frame_count = 0\n",
    "    start_time = time.time()\n",
    "    start_event.set()\n",
    "\n",
    "    for i, (img_batch, mel_batch, frames, coords_batch) in enumerate(gen):\n",
    "        img_batch = torch.FloatTensor(np.transpose(img_batch, (0, 3, 1, 2))).to(device)\n",
    "        mel_batch = torch.FloatTensor(np.transpose(mel_batch, (0, 3, 1, 2))).to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(mel_batch, img_batch)\n",
    "        pred = pred.cpu().numpy().transpose(0, 2, 3, 1) * 255.\n",
    "        pred = pred.astype(np.uint8)\n",
    "        for p in pred:\n",
    "            y1, y2, x1, x2 = coords\n",
    "            h, w = y2 - y1, x2 - x1\n",
    "            if h <= 0 or w <= 0:\n",
    "                continue\n",
    "            p_resized = cv2.resize(p, (w, h))\n",
    "            show_img = orig_image.copy()\n",
    "            show_img[y1:y2, x1:x2] = p_resized\n",
    "            show_img_disp = cv2.resize(show_img, window_size)\n",
    "            # 音视频时间对齐\n",
    "            target_time = start_time + frame_count * frame_interval\n",
    "            now = time.time()\n",
    "            if now < target_time:\n",
    "                time.sleep(target_time - now)\n",
    "            #print(time.time() - a,\"-------\")\n",
    "            cv2.imshow(window_name, show_img_disp)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                stop_event.set()\n",
    "                cv2.destroyAllWindows()\n",
    "                audio_thread.join()\n",
    "                return\n",
    "            frame_count += 1\n",
    "    stop_event.set()\n",
    "    audio_thread.join()\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "b0228a56a461b1f6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:51:33.561683Z",
     "start_time": "2025-05-25T08:51:27.954876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    check_path = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\checkpoints\\wav2lip_gan.pth\"\n",
    "    img_path = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\input\\1.png\"\n",
    "    audio_path = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\input\\1.wav\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    model = load_model(check_path)\n",
    "    face_img, face_coords, orig_image = preprocess_image(img_path, device=device)"
   ],
   "id": "15870c220ce570db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 D:\\coding\\projects\\Python\\human\\Wav2Lip\\checkpoints\\wav2lip_gan.pth 加载模型\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:51:54.728083Z",
     "start_time": "2025-05-25T08:51:41.973824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    a=time.time()\n",
    "    gen = prepare_audio_batches(audio_path, face_img, face_coords)\n",
    "    print(time.time() - a)\n",
    "    a = time.time()\n",
    "    wav2lip_sync_play(model, gen, device, orig_image=orig_image, coords=face_coords, audio_path=audio_path)"
   ],
   "id": "502654c22f4896d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m a)\n\u001B[0;32m      4\u001B[0m a \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m----> 5\u001B[0m \u001B[43mwav2lip_sync_play\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morig_image\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morig_image\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoords\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mface_coords\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maudio_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[1], line 186\u001B[0m, in \u001B[0;36mwav2lip_sync_play\u001B[1;34m(model, gen, device, orig_image, coords, audio_path, fps, window_size, show_window, window_name)\u001B[0m\n\u001B[0;32m    184\u001B[0m now \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m now \u001B[38;5;241m<\u001B[39m target_time:\n\u001B[1;32m--> 186\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget_time\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnow\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;66;03m#print(time.time() - a,\"-------\")\u001B[39;00m\n\u001B[0;32m    188\u001B[0m cv2\u001B[38;5;241m.\u001B[39mimshow(window_name, show_img_disp)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "\n",
   "id": "b066e5f76dddba36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e911a5f547603159"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T09:15:59.066331Z",
     "start_time": "2025-05-25T09:15:55.266270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "import threading\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import Wav2Lip.audio as audio\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import Wav2Lip.face_detection as face_detection\n",
    "from Wav2Lip.models import Wav2Lip\n",
    "\n",
    "mel_step_size = 16\n",
    "\n",
    "def _load(checkpoint_path):\n",
    "    if device == 'cuda':\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
    "    return checkpoint\n",
    "\n",
    "def load_model(path):\n",
    "    model = Wav2Lip()\n",
    "    print(f\"从 {path} 加载模型\")\n",
    "    checkpoint = _load(path)\n",
    "    new_s = {}\n",
    "    for k, v in checkpoint[\"state_dict\"].items():\n",
    "        new_s[k.replace('module.', '')] = v\n",
    "    model.load_state_dict(new_s)\n",
    "    model = model.to(device)\n",
    "    return model.eval()\n",
    "\n",
    "def preprocess_image(\n",
    "    image_path,\n",
    "    pads=[0,10,0,0],\n",
    "    box=[-1,-1,-1,-1],\n",
    "    img_size=96,\n",
    "    face_det_batch_size=16,\n",
    "    nosmooth=False,\n",
    "    device='cuda'\n",
    "):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"无法读取图片: {image_path}\")\n",
    "    if box[0] == -1:\n",
    "        detector = face_detection.FaceAlignment(face_detection.LandmarksType._2D, flip_input=False, device=device)\n",
    "        predictions = detector.get_detections_for_batch(np.array([image]))\n",
    "        rect = predictions[0]\n",
    "        if rect is None:\n",
    "            raise RuntimeError(\"未检测到人脸\")\n",
    "        pady1, pady2, padx1, padx2 = pads\n",
    "        y1 = max(0, rect[1] - pady1)\n",
    "        y2 = min(image.shape[0], rect[3] + pady2)\n",
    "        x1 = max(0, rect[0] - padx1)\n",
    "        x2 = min(image.shape[1], rect[2] + padx2)\n",
    "    else:\n",
    "        y1, y2, x1, x2 = box\n",
    "    face = image[y1:y2, x1:x2]\n",
    "    face = cv2.resize(face, (img_size, img_size))\n",
    "    coords = (y1, y2, x1, x2)\n",
    "    return face, coords, image\n",
    "\n",
    "def prepare_audio_batches(\n",
    "    audio_path,\n",
    "    face_img,\n",
    "    face_coords,\n",
    "    static=True,\n",
    "    fps=25,\n",
    "    mel_step_size=16,\n",
    "    wav2lip_batch_size=128,\n",
    "    img_size=96\n",
    "):\n",
    "    if not audio_path.endswith('.wav'):\n",
    "        print('提取音频...')\n",
    "        command = f'ffmpeg -y -i \"{audio_path}\" -strict -2 temp/temp.wav'.format(audio_path)\n",
    "        subprocess.call(command, shell=True)\n",
    "        audio_path = 'temp/temp.wav'\n",
    "    wav = audio.load_wav(audio_path, 16000)\n",
    "    mel = audio.melspectrogram(wav)\n",
    "    if np.isnan(mel.reshape(-1)).sum() > 0:\n",
    "        raise ValueError('梅尔频谱包含NaN值，请检查音频质量')\n",
    "    mel_idx_multiplier = 80. / fps\n",
    "    mel_chunks = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        start_idx = int(i * mel_idx_multiplier)\n",
    "        if start_idx + mel_step_size > len(mel[0]):\n",
    "            mel_chunks.append(mel[:, len(mel[0]) - mel_step_size:])\n",
    "            break\n",
    "        mel_chunks.append(mel[:, start_idx: start_idx + mel_step_size])\n",
    "        i += 1\n",
    "    img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "    for i, m in enumerate(mel_chunks):\n",
    "        frame_to_save = face_img.copy()\n",
    "        face = face_img.copy()\n",
    "        coords = face_coords\n",
    "        img_batch.append(face)\n",
    "        mel_batch.append(m)\n",
    "        frame_batch.append(frame_to_save)\n",
    "        coords_batch.append(coords)\n",
    "        if len(img_batch) >= wav2lip_batch_size:\n",
    "            img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "            img_masked = img_batch.copy()\n",
    "            img_masked[:, img_size // 2:] = 0\n",
    "            img_input = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "            mel_input = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "            yield img_input, mel_input, frame_batch, coords_batch\n",
    "            img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "    if len(img_batch) > 0:\n",
    "        img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "        img_masked = img_batch.copy()\n",
    "        img_masked[:, img_size // 2:] = 0\n",
    "        img_input = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "        mel_input = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "        yield img_input, mel_input, frame_batch, coords_batch\n",
    "\n",
    "def play_audio_stream(audio_path, start_event, stop_event):\n",
    "    data, samplerate = sf.read(audio_path)\n",
    "    if len(data.shape) == 1:\n",
    "        data = data[:, None]\n",
    "    def callback(outdata, frames, time_, status):\n",
    "        start_event.wait()\n",
    "        if stop_event.is_set():\n",
    "            raise sd.CallbackAbort\n",
    "        chunk = data[callback.idx:callback.idx+frames]\n",
    "        if len(chunk) < frames:\n",
    "            outdata[:len(chunk)] = chunk\n",
    "            outdata[len(chunk):] = 0\n",
    "            stop_event.set()\n",
    "            raise sd.CallbackStop\n",
    "        else:\n",
    "            outdata[:] = chunk\n",
    "        callback.idx += frames\n",
    "    callback.idx = 0\n",
    "    with sd.OutputStream(channels=data.shape[1], samplerate=samplerate, callback=callback):\n",
    "        start_event.wait()\n",
    "        while not stop_event.is_set() and callback.idx < len(data):\n",
    "            sd.sleep(100)\n",
    "\n",
    "def wav2lip_sync_play(\n",
    "    model,\n",
    "    gen,\n",
    "    device,\n",
    "    orig_image,\n",
    "    coords,\n",
    "    audio_path,\n",
    "    fps=25,\n",
    "    window_size=(224, 336),\n",
    "    show_window=True,\n",
    "    window_name=\"Wav2Lip Result\"\n",
    "):\n",
    "    start_event = threading.Event()\n",
    "    stop_event = threading.Event()\n",
    "    audio_thread = threading.Thread(target=play_audio_stream, args=(audio_path, start_event, stop_event))\n",
    "    audio_thread.start()\n",
    "\n",
    "    frame_interval = 1.0 / fps\n",
    "    frame_count = 0\n",
    "    start_time = time.time()\n",
    "    start_event.set()\n",
    "\n",
    "    for i, (img_batch, mel_batch, frames, coords_batch) in enumerate(gen):\n",
    "        img_batch = torch.FloatTensor(np.transpose(img_batch, (0, 3, 1, 2))).to(device)\n",
    "        mel_batch = torch.FloatTensor(np.transpose(mel_batch, (0, 3, 1, 2))).to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(mel_batch, img_batch)\n",
    "        pred = pred.cpu().numpy().transpose(0, 2, 3, 1) * 255.\n",
    "        pred = pred.astype(np.uint8)\n",
    "        for p in pred:\n",
    "            y1, y2, x1, x2 = coords\n",
    "            h, w = y2 - y1, x2 - x1\n",
    "            if h <= 0 or w <= 0:\n",
    "                continue\n",
    "            p_resized = cv2.resize(p, (w, h))\n",
    "            show_img = orig_image.copy()\n",
    "            show_img[y1:y2, x1:x2] = p_resized\n",
    "            show_img_disp = cv2.resize(show_img, window_size)\n",
    "            # 音视频时间对齐\n",
    "            target_time = start_time + frame_count * frame_interval\n",
    "            now = time.time()\n",
    "            if now < target_time:\n",
    "                time.sleep(target_time - now)\n",
    "            cv2.imshow(window_name, show_img_disp)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                stop_event.set()\n",
    "                cv2.destroyAllWindows()\n",
    "                audio_thread.join()\n",
    "                return\n",
    "            frame_count += 1\n",
    "    stop_event.set()\n",
    "    audio_thread.join()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def idle_display(orig_image, window_size=(224, 336), window_name=\"Wav2Lip Result\"):\n",
    "    show_img_disp = cv2.resize(orig_image, window_size)\n",
    "    cv2.imshow(window_name, show_img_disp)\n",
    "    while True:\n",
    "        key = cv2.waitKey(100)\n",
    "        if key == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            return False  # quit\n",
    "        elif key != -1:\n",
    "            break\n",
    "    return True  # got some input"
   ],
   "id": "e95d62d71d0d3727",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T09:16:35.893845Z",
     "start_time": "2025-05-25T09:16:01.939038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    check_path = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\checkpoints\\wav2lip_gan.pth\"\n",
    "    img_path = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\input\\1.png\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    model = load_model(check_path)\n",
    "    face_img, face_coords, orig_image = preprocess_image(img_path, device=device)\n",
    "\n",
    "    print(\"==== Wav2Lip 音频驱动图像同步播放 ====\")\n",
    "    print(\"按 'q' 退出；其余任意键输入音频路径并播放合成结果。\")\n",
    "\n",
    "    while True:\n",
    "        # 空闲时持续展示图片\n",
    "        if not idle_display(orig_image):\n",
    "            break\n",
    "\n",
    "        audio_path = input(\"请输入要驱动的音频文件路径（或按回车跳过，输入 q 退出）：\").strip()\n",
    "        if audio_path == \"\" or not os.path.exists(audio_path):\n",
    "            print(\"未输入音频或音频文件不存在，继续等待输入...\")\n",
    "            continue\n",
    "        if audio_path.lower() == \"q\":\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            gen = prepare_audio_batches(audio_path, face_img, face_coords)\n",
    "            wav2lip_sync_play(model, gen, device, orig_image=orig_image, coords=face_coords, audio_path=audio_path)\n",
    "        except Exception as e:\n",
    "            print(f\"音频处理或合成异常: {e}\")\n",
    "\n",
    "    print(\"程序已退出。\")"
   ],
   "id": "d5dd0bc6024ae1a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 D:\\coding\\projects\\Python\\human\\Wav2Lip\\checkpoints\\wav2lip_gan.pth 加载模型\n",
      "==== Wav2Lip 音频驱动图像同步播放 ====\n",
      "按 'q' 退出；其余任意键输入音频路径并播放合成结果。\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 14\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m按 \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mq\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m 退出；其余任意键输入音频路径并播放合成结果。\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;66;03m# 空闲时持续展示图片\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43midle_display\u001B[49m\u001B[43m(\u001B[49m\u001B[43morig_image\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m     15\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m     17\u001B[0m     audio_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m请输入要驱动的音频文件路径（或按回车跳过，输入 q 退出）：\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mstrip()\n",
      "Cell \u001B[1;32mIn[1], line 201\u001B[0m, in \u001B[0;36midle_display\u001B[1;34m(orig_image, window_size, window_name)\u001B[0m\n\u001B[0;32m    199\u001B[0m cv2\u001B[38;5;241m.\u001B[39mimshow(window_name, show_img_disp)\n\u001B[0;32m    200\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 201\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwaitKey\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    202\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mord\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mq\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    203\u001B[0m         cv2\u001B[38;5;241m.\u001B[39mdestroyAllWindows()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T09:27:59.793017Z",
     "start_time": "2025-05-25T09:27:59.756364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "import threading\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import Wav2Lip.audio as audio\n",
    "import subprocess\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import Wav2Lip.face_detection as face_detection\n",
    "from Wav2Lip.models import Wav2Lip\n",
    "\n",
    "mel_step_size = 16\n",
    "\n",
    "def _load(checkpoint_path):\n",
    "    if device == 'cuda':\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
    "    return checkpoint\n",
    "\n",
    "def load_model(path):\n",
    "    model = Wav2Lip()\n",
    "    print(f\"从 {path} 加载模型\")\n",
    "    checkpoint = _load(path)\n",
    "    new_s = {}\n",
    "    for k, v in checkpoint[\"state_dict\"].items():\n",
    "        new_s[k.replace('module.', '')] = v\n",
    "    model.load_state_dict(new_s)\n",
    "    model = model.to(device)\n",
    "    return model.eval()\n",
    "\n",
    "def preprocess_image(\n",
    "    image_path,\n",
    "    pads=[0,10,0,0],\n",
    "    box=[-1,-1,-1,-1],\n",
    "    img_size=96,\n",
    "    face_det_batch_size=16,\n",
    "    nosmooth=False,\n",
    "    device='cuda'\n",
    "):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"无法读取图片: {image_path}\")\n",
    "    if box[0] == -1:\n",
    "        detector = face_detection.FaceAlignment(face_detection.LandmarksType._2D, flip_input=False, device=device)\n",
    "        predictions = detector.get_detections_for_batch(np.array([image]))\n",
    "        rect = predictions[0]\n",
    "        if rect is None:\n",
    "            raise RuntimeError(\"未检测到人脸\")\n",
    "        pady1, pady2, padx1, padx2 = pads\n",
    "        y1 = max(0, rect[1] - pady1)\n",
    "        y2 = min(image.shape[0], rect[3] + pady2)\n",
    "        x1 = max(0, rect[0] - padx1)\n",
    "        x2 = min(image.shape[1], rect[2] + padx2)\n",
    "    else:\n",
    "        y1, y2, x1, x2 = box\n",
    "    face = image[y1:y2, x1:x2]\n",
    "    face = cv2.resize(face, (img_size, img_size))\n",
    "    coords = (y1, y2, x1, x2)\n",
    "    return face, coords, image\n",
    "\n",
    "def prepare_audio_batches(\n",
    "    audio_path,\n",
    "    face_img,\n",
    "    face_coords,\n",
    "    static=True,\n",
    "    fps=25,\n",
    "    mel_step_size=16,\n",
    "    wav2lip_batch_size=128,\n",
    "    img_size=96\n",
    "):\n",
    "    if not audio_path.endswith('.wav'):\n",
    "        print('提取音频...')\n",
    "        command = f'ffmpeg -y -i \"{audio_path}\" -strict -2 temp/temp.wav'\n",
    "        subprocess.call(command, shell=True)\n",
    "        audio_path = 'temp/temp.wav'\n",
    "    wav = audio.load_wav(audio_path, 16000)\n",
    "    mel = audio.melspectrogram(wav)\n",
    "    if np.isnan(mel.reshape(-1)).sum() > 0:\n",
    "        raise ValueError('梅尔频谱包含NaN值，请检查音频质量')\n",
    "    mel_idx_multiplier = 80. / fps\n",
    "    mel_chunks = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        start_idx = int(i * mel_idx_multiplier)\n",
    "        if start_idx + mel_step_size > len(mel[0]):\n",
    "            mel_chunks.append(mel[:, len(mel[0]) - mel_step_size:])\n",
    "            break\n",
    "        mel_chunks.append(mel[:, start_idx: start_idx + mel_step_size])\n",
    "        i += 1\n",
    "    img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "    for i, m in enumerate(mel_chunks):\n",
    "        frame_to_save = face_img.copy()\n",
    "        face = face_img.copy()\n",
    "        coords = face_coords\n",
    "        img_batch.append(face)\n",
    "        mel_batch.append(m)\n",
    "        frame_batch.append(frame_to_save)\n",
    "        coords_batch.append(coords)\n",
    "        if len(img_batch) >= wav2lip_batch_size:\n",
    "            img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "            img_masked = img_batch.copy()\n",
    "            img_masked[:, img_size // 2:] = 0\n",
    "            img_input = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "            mel_input = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "            yield img_input, mel_input, frame_batch, coords_batch\n",
    "            img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "    if len(img_batch) > 0:\n",
    "        img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "        img_masked = img_batch.copy()\n",
    "        img_masked[:, img_size // 2:] = 0\n",
    "        img_input = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "        mel_input = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "        yield img_input, mel_input, frame_batch, coords_batch\n",
    "\n",
    "def play_audio_stream(audio_path, start_event, stop_event):\n",
    "    data, samplerate = sf.read(audio_path)\n",
    "    if len(data.shape) == 1:\n",
    "        data = data[:, None]\n",
    "    def callback(outdata, frames, time_, status):\n",
    "        start_event.wait()\n",
    "        if stop_event.is_set():\n",
    "            raise sd.CallbackAbort\n",
    "        chunk = data[callback.idx:callback.idx+frames]\n",
    "        if len(chunk) < frames:\n",
    "            outdata[:len(chunk)] = chunk\n",
    "            outdata[len(chunk):] = 0\n",
    "            stop_event.set()\n",
    "            raise sd.CallbackStop\n",
    "        else:\n",
    "            outdata[:] = chunk\n",
    "        callback.idx += frames\n",
    "    callback.idx = 0\n",
    "    with sd.OutputStream(channels=data.shape[1], samplerate=samplerate, callback=callback):\n",
    "        start_event.wait()\n",
    "        while not stop_event.is_set() and callback.idx < len(data):\n",
    "            sd.sleep(100)\n",
    "\n",
    "def wav2lip_sync_play(\n",
    "    model,\n",
    "    gen,\n",
    "    device,\n",
    "    orig_image,\n",
    "    coords,\n",
    "    audio_path,\n",
    "    fps=25,\n",
    "    window_size=(224, 336),\n",
    "    show_window=True,\n",
    "    window_name=\"Wav2Lip Result\"\n",
    "):\n",
    "    start_event = threading.Event()\n",
    "    stop_event = threading.Event()\n",
    "    audio_thread = threading.Thread(target=play_audio_stream, args=(audio_path, start_event, stop_event))\n",
    "    audio_thread.start()\n",
    "\n",
    "    frame_interval = 1.0 / fps\n",
    "    frame_count = 0\n",
    "    start_time = time.time()\n",
    "    start_event.set()\n",
    "\n",
    "    for i, (img_batch, mel_batch, frames, coords_batch) in enumerate(gen):\n",
    "        img_batch = torch.FloatTensor(np.transpose(img_batch, (0, 3, 1, 2))).to(device)\n",
    "        mel_batch = torch.FloatTensor(np.transpose(mel_batch, (0, 3, 1, 2))).to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(mel_batch, img_batch)\n",
    "        pred = pred.cpu().numpy().transpose(0, 2, 3, 1) * 255.\n",
    "        pred = pred.astype(np.uint8)\n",
    "        for p in pred:\n",
    "            y1, y2, x1, x2 = coords\n",
    "            h, w = y2 - y1, x2 - x1\n",
    "            if h <= 0 or w <= 0:\n",
    "                continue\n",
    "            p_resized = cv2.resize(p, (w, h))\n",
    "            show_img = orig_image.copy()\n",
    "            show_img[y1:y2, x1:x2] = p_resized\n",
    "            show_img_disp = cv2.resize(show_img, window_size)\n",
    "            # 音视频时间对齐\n",
    "            target_time = start_time + frame_count * frame_interval\n",
    "            now = time.time()\n",
    "            if now < target_time:\n",
    "                time.sleep(target_time - now)\n",
    "            cv2.imshow(window_name, show_img_disp)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                stop_event.set()\n",
    "                cv2.destroyAllWindows()\n",
    "                audio_thread.join()\n",
    "                return\n",
    "            frame_count += 1\n",
    "    stop_event.set()\n",
    "    audio_thread.join()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def show_image_idle(orig_image, window_size=(224, 336), window_name=\"Wav2Lip\"):\n",
    "    img = cv2.resize(orig_image, window_size)\n",
    "    cv2.imshow(window_name, img)\n",
    "    # 只刷新，不阻塞主线程，需外部循环配合\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "def wait_for_audio_path():\n",
    "    audio_path = input(\"请输入要讲解的音频文件路径（或输入 q 退出）：\").strip()\n",
    "    if audio_path.lower() == \"q\":\n",
    "        return None\n",
    "    if not os.path.exists(audio_path):\n",
    "        print(\"音频文件不存在，请重新输入。\")\n",
    "        return \"\"\n",
    "    return audio_path"
   ],
   "id": "2befb5cd02b24824",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T09:28:20.618195Z",
     "start_time": "2025-05-25T09:28:18.415799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    check_path = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\checkpoints\\wav2lip_gan.pth\"\n",
    "    img_path = r\"D:\\coding\\projects\\Python\\human\\Wav2Lip\\input\\1.png\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    model = load_model(check_path)\n",
    "    face_img, face_coords, orig_image = preprocess_image(img_path, device=device)\n"
   ],
   "id": "eb58b94f34877a5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 D:\\coding\\projects\\Python\\human\\Wav2Lip\\checkpoints\\wav2lip_gan.pth 加载模型\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T09:28:43.881632Z",
     "start_time": "2025-05-25T09:28:24.022063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    window_name = \"Wav2Lip 自助讲解\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    print(\"==== 自助讲解员系统 ====\")\n",
    "    print(\"系统空闲时自动展示图片，收到音频地址后自动讲解并口型同步。按 'q' 退出。\")\n",
    "\n",
    "    while True:\n",
    "        # 持续展示图片，直到有音频输入\n",
    "        print(\"空闲展示中，等待输入讲解音频路径 ...\")\n",
    "        while True:\n",
    "            show_image_idle(orig_image, window_name=window_name)\n",
    "            # 检查窗口是否被关闭/按下q\n",
    "            key = cv2.waitKey(100)\n",
    "            if key == ord('q'):\n",
    "                print(\"用户退出。\")\n",
    "                cv2.destroyAllWindows()\n",
    "                exit(0)\n",
    "            # 检查命令行输入是否就绪（非阻塞方式，提示用户切到命令行输入）\n",
    "            # 推荐只在命令行输入后进入下一步\n",
    "            break\n",
    "\n",
    "        # 等待用户输入音频路径\n",
    "        audio_path = wait_for_audio_path()\n",
    "        if audio_path is None:\n",
    "            break\n",
    "        if not audio_path:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            gen = prepare_audio_batches(audio_path, face_img, face_coords)\n",
    "            wav2lip_sync_play(\n",
    "                model, gen, device,\n",
    "                orig_image=orig_image, coords=face_coords,\n",
    "                audio_path=audio_path,\n",
    "                window_name=window_name\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"音频处理或合成异常: {e}\")\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"讲解系统已关闭。\")"
   ],
   "id": "4c468cf2af3dc591",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== 自助讲解员系统 ====\n",
      "系统空闲时自动展示图片，收到音频地址后自动讲解并口型同步。按 'q' 退出。\n",
      "空闲展示中，等待输入讲解音频路径 ...\n",
      "空闲展示中，等待输入讲解音频路径 ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 23\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# 等待用户输入音频路径\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m audio_path \u001B[38;5;241m=\u001B[39m \u001B[43mwait_for_audio_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m audio_path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[4], line 203\u001B[0m, in \u001B[0;36mwait_for_audio_path\u001B[1;34m()\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mwait_for_audio_path\u001B[39m():\n\u001B[1;32m--> 203\u001B[0m     audio_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m请输入要讲解的音频文件路径（或输入 q 退出）：\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[0;32m    204\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m audio_path\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mq\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    205\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mD:\\coding\\Anaconda\\envs\\w\\lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001B[0m, in \u001B[0;36mKernel.raw_input\u001B[1;34m(self, prompt)\u001B[0m\n\u001B[0;32m   1280\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1281\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[1;32m-> 1282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1283\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1284\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1285\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mshell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1286\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1287\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\coding\\Anaconda\\envs\\w\\lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001B[0m, in \u001B[0;36mKernel._input_request\u001B[1;34m(self, prompt, ident, parent, password)\u001B[0m\n\u001B[0;32m   1322\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m   1323\u001B[0m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[0;32m   1324\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInterrupted by user\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1325\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1327\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Message:\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#face\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import threading\n",
    "import time\n",
    "import Wav2Lip.audio as audio\n",
    "import subprocess\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import Wav2Lip.face_detection as face_detection\n",
    "from Wav2Lip.models import Wav2Lip\n",
    "\n",
    "mel_step_size = 16\n",
    "\n",
    "def _load(checkpoint_path, device):\n",
    "    if device == 'cuda':\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
    "    return checkpoint\n",
    "\n",
    "def load_model(path, device):\n",
    "    model = Wav2Lip()\n",
    "    print(f\"从 {path} 加载模型\")\n",
    "    checkpoint = _load(path, device)\n",
    "    new_s = {}\n",
    "    for k, v in checkpoint[\"state_dict\"].items():\n",
    "        new_s[k.replace('module.', '')] = v\n",
    "    model.load_state_dict(new_s)\n",
    "    model = model.to(device)\n",
    "    return model.eval()\n",
    "\n",
    "def preprocess_image(\n",
    "    image_path,\n",
    "    pads=[0,10,0,0],\n",
    "    box=[-1,-1,-1,-1],\n",
    "    img_size=96,\n",
    "    face_det_batch_size=16,\n",
    "    nosmooth=False,\n",
    "    device='cuda'\n",
    "):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"无法读取图片: {image_path}\")\n",
    "    if box[0] == -1:\n",
    "        detector = face_detection.FaceAlignment(face_detection.LandmarksType._2D, flip_input=False, device=device)\n",
    "        predictions = detector.get_detections_for_batch(np.array([image]))\n",
    "        rect = predictions[0]\n",
    "        if rect is None:\n",
    "            raise RuntimeError(\"未检测到人脸\")\n",
    "        pady1, pady2, padx1, padx2 = pads\n",
    "        y1 = max(0, rect[1] - pady1)\n",
    "        y2 = min(image.shape[0], rect[3] + pady2)\n",
    "        x1 = max(0, rect[0] - padx1)\n",
    "        x2 = min(image.shape[1], rect[2] + padx2)\n",
    "    else:\n",
    "        y1, y2, x1, x2 = box\n",
    "    face = image[y1:y2, x1:x2]\n",
    "    face = cv2.resize(face, (img_size, img_size))\n",
    "    coords = (y1, y2, x1, x2)\n",
    "    return face, coords, image\n",
    "\n",
    "def prepare_audio_batches(\n",
    "    audio_path,\n",
    "    face_img,\n",
    "    face_coords,\n",
    "    static=True,\n",
    "    fps=25,\n",
    "    mel_step_size=16,\n",
    "    wav2lip_batch_size=128,\n",
    "    img_size=96\n",
    "):\n",
    "    if not audio_path.endswith('.wav'):\n",
    "        command = f'ffmpeg -y -i \"{audio_path}\" -strict -2 temp/temp.wav'\n",
    "        subprocess.call(command, shell=True)\n",
    "        audio_path = 'temp/temp.wav'\n",
    "    wav = audio.load_wav(audio_path, 16000)\n",
    "    mel = audio.melspectrogram(wav)\n",
    "    if np.isnan(mel.reshape(-1)).sum() > 0:\n",
    "        raise ValueError('梅尔频谱包含NaN值，请检查音频质量')\n",
    "    mel_idx_multiplier = 80. / fps\n",
    "    mel_chunks = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        start_idx = int(i * mel_idx_multiplier)\n",
    "        if start_idx + mel_step_size > len(mel[0]):\n",
    "            mel_chunks.append(mel[:, len(mel[0]) - mel_step_size:])\n",
    "            break\n",
    "        mel_chunks.append(mel[:, start_idx: start_idx + mel_step_size])\n",
    "        i += 1\n",
    "    # 补帧：确保嘴型帧不会太短\n",
    "    min_frames = int((len(mel[0]) / 80) * fps / (16000 / 80))\n",
    "    if len(mel_chunks) < min_frames and len(mel_chunks) > 0:\n",
    "        repeat = int(np.ceil(min_frames / len(mel_chunks)))\n",
    "        mel_chunks = (mel_chunks * repeat)[:min_frames]\n",
    "\n",
    "    img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "    for i, m in enumerate(mel_chunks):\n",
    "        frame_to_save = face_img.copy()\n",
    "        face = face_img.copy()\n",
    "        coords = face_coords\n",
    "        img_batch.append(face)\n",
    "        mel_batch.append(m)\n",
    "        frame_batch.append(frame_to_save)\n",
    "        coords_batch.append(coords)\n",
    "        if len(img_batch) >= wav2lip_batch_size:\n",
    "            img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "            img_masked = img_batch.copy()\n",
    "            img_masked[:, img_size // 2:] = 0\n",
    "            img_input = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "            mel_input = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "            yield img_input, mel_input, frame_batch, coords_batch\n",
    "            img_batch, mel_batch, frame_batch, coords_batch = [], [], [], []\n",
    "    if len(img_batch) > 0:\n",
    "        img_batch, mel_batch = np.asarray(img_batch), np.asarray(mel_batch)\n",
    "        img_masked = img_batch.copy()\n",
    "        img_masked[:, img_size // 2:] = 0\n",
    "        img_input = np.concatenate((img_masked, img_batch), axis=3) / 255.\n",
    "        mel_input = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])\n",
    "        yield img_input, mel_input, frame_batch, coords_batch\n",
    "\n",
    "class LipSyncPlayer:\n",
    "    def __init__(self, model, device, orig_image, face_coords, fps=25):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.orig_image = orig_image\n",
    "        self.face_coords = face_coords\n",
    "        self.fps = fps\n",
    "\n",
    "    def infer_frames(self, batch_gen):\n",
    "        \"\"\"\n",
    "        只做推理，返回(耗时, all_frames)\n",
    "        \"\"\"\n",
    "        t_infer_start = time.perf_counter()\n",
    "        all_frames = []\n",
    "        gen_iter = iter(batch_gen)\n",
    "        for img_batch, mel_batch, frames, coords_batch in gen_iter:\n",
    "            img_batch = torch.FloatTensor(np.transpose(img_batch, (0, 3, 1, 2))).to(self.device)\n",
    "            mel_batch = torch.FloatTensor(np.transpose(mel_batch, (0, 3, 1, 2))).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                pred = self.model(mel_batch, img_batch)\n",
    "            pred = pred.cpu().numpy().transpose(0, 2, 3, 1) * 255.\n",
    "            pred = pred.astype(np.uint8)\n",
    "            for p in pred:\n",
    "                y1, y2, x1, x2 = self.face_coords\n",
    "                h, w = y2 - y1, x2 - x1\n",
    "                if h <= 0 or w <= 0:\n",
    "                    continue\n",
    "                p_resized = cv2.resize(p, (w, h))\n",
    "                show_img = self.orig_image.copy()\n",
    "                show_img[y1:y2, x1:x2] = p_resized\n",
    "                all_frames.append(show_img.copy())\n",
    "        t_infer_end = time.perf_counter()\n",
    "        infer_time = t_infer_end - t_infer_start\n",
    "        return infer_time, all_frames\n",
    "\n",
    "    def play_frames(self, audio_path, all_frames, frame_callback):\n",
    "        \"\"\"\n",
    "        只做播放，返回耗时\n",
    "        \"\"\"\n",
    "        # 加载音频数据\n",
    "        data, samplerate = sf.read(audio_path)\n",
    "        duration = len(data) / samplerate\n",
    "        n_frames = len(all_frames)\n",
    "        frame_interval = 1.0 / self.fps\n",
    "        total_frames_by_audio = int(duration * self.fps)\n",
    "\n",
    "        stop_event = threading.Event()\n",
    "        def audio_thread_func():\n",
    "            sd.play(data, samplerate)\n",
    "            sd.wait()\n",
    "            stop_event.set()\n",
    "        audio_thread = threading.Thread(target=audio_thread_func)\n",
    "        audio_thread.start()\n",
    "\n",
    "        t_play_start = time.perf_counter()\n",
    "        t_start = time.time()\n",
    "        frame_idx = 0\n",
    "        last_frame = None\n",
    "        while not stop_event.is_set():\n",
    "            now = time.time()\n",
    "            expected_frame = int((now - t_start) * self.fps)\n",
    "            if expected_frame >= total_frames_by_audio:\n",
    "                break\n",
    "            if frame_idx < n_frames:\n",
    "                frame_callback(all_frames[frame_idx])\n",
    "                last_frame = all_frames[frame_idx]\n",
    "            else:\n",
    "                if last_frame is not None:\n",
    "                    frame_callback(last_frame)\n",
    "            frame_idx += 1\n",
    "            next_time = t_start + frame_idx * frame_interval\n",
    "            time.sleep(max(0, next_time - time.time()))\n",
    "        audio_thread.join()\n",
    "        t_play_end = time.perf_counter()\n",
    "        play_time = t_play_end - t_play_start\n",
    "        return play_time"
   ],
   "id": "d8167556a2187e48"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "cf",
   "id": "19a22477f450ffda"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T13:40:50.913131Z",
     "start_time": "2025-05-25T13:40:50.823138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#app:\n",
    "import sys\n",
    "import threading\n",
    "import asyncio\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PyQt5 import QtWidgets, QtCore, QtGui\n",
    "from config import API_KEY, BASE_URL, WAV2LIP_MODEL_PATH, IDLE_IMAGE_PATH, FACE_IMAGE_PATH, DEVICE\n",
    "from llm import ChatBot\n",
    "from tts import generate_speech\n",
    "from face import load_model, preprocess_image, prepare_audio_batches, LipSyncPlayer\n",
    "\n",
    "class DigitalHumanUI(QtWidgets.QWidget):\n",
    "    append_history_signal = QtCore.pyqtSignal(str, str)\n",
    "    show_frame_signal = QtCore.pyqtSignal(np.ndarray)\n",
    "    idle_signal = QtCore.pyqtSignal()\n",
    "    stage_signal = QtCore.pyqtSignal(str)\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"数字人问答演示\")\n",
    "        self.resize(960, 520)\n",
    "        self.init_ui()\n",
    "        self.init_resources()\n",
    "        self.append_history_signal.connect(self.append_history)\n",
    "        self.show_frame_signal.connect(self.show_video_frame)\n",
    "        self.idle_signal.connect(self.show_idle)\n",
    "        self.stage_signal.connect(self.show_stage)\n",
    "        self.show_idle()\n",
    "        self.show_stage(\"系统待命...\")\n",
    "\n",
    "    def init_ui(self):\n",
    "        self.input_box = QtWidgets.QLineEdit(self)\n",
    "        self.input_box.setPlaceholderText(\"请输入你的问题...\")\n",
    "        self.send_btn = QtWidgets.QPushButton(\"发送\", self)\n",
    "        self.send_btn.clicked.connect(self.on_submit)\n",
    "        self.chat_history = QtWidgets.QTextEdit(self)\n",
    "        self.chat_history.setReadOnly(True)\n",
    "        self.chat_history.setVerticalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOn)\n",
    "        self.face_label = QtWidgets.QLabel(self)\n",
    "        self.face_label.setFixedSize(336, 448)\n",
    "        self.stage_label = QtWidgets.QTextEdit(self)\n",
    "        self.stage_label.setReadOnly(True)\n",
    "        self.stage_label.setAlignment(QtCore.Qt.AlignLeft)\n",
    "        self.stage_label.setStyleSheet(\"color:blue; font-size:14px;\")\n",
    "        self.stage_label.setVerticalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOn)\n",
    "        left_panel = QtWidgets.QVBoxLayout()\n",
    "        left_panel.addWidget(self.chat_history)\n",
    "        left_panel.addWidget(self.stage_label)\n",
    "        input_layout = QtWidgets.QHBoxLayout()\n",
    "        input_layout.addWidget(self.input_box)\n",
    "        input_layout.addWidget(self.send_btn)\n",
    "        left_panel.addLayout(input_layout)\n",
    "        main_layout = QtWidgets.QHBoxLayout(self)\n",
    "        main_layout.addLayout(left_panel, 2)\n",
    "        main_layout.addWidget(self.face_label, 1)\n",
    "        self.setLayout(main_layout)\n",
    "\n",
    "    def init_resources(self):\n",
    "        self.bot = ChatBot(\n",
    "            api_key=API_KEY,\n",
    "            base_url=BASE_URL,\n",
    "            log_dir=\"logs\",\n",
    "            default_background=\"你是一个知识渊博的助手，能够简洁地回答问题。\",\n",
    "            default_prefix=\"请简洁地回答下述问题：\"\n",
    "        )\n",
    "        self.model = load_model(WAV2LIP_MODEL_PATH, DEVICE)\n",
    "        self.face_img, self.face_coords, self.orig_image = preprocess_image(FACE_IMAGE_PATH, device=DEVICE)\n",
    "        self.idle_img = cv2.imread(IDLE_IMAGE_PATH)\n",
    "        self.lip_player = LipSyncPlayer(self.model, DEVICE, self.orig_image, self.face_coords, fps=25)\n",
    "\n",
    "    def show_idle(self):\n",
    "        img = cv2.cvtColor(self.idle_img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (336, 448))\n",
    "        qimg = QtGui.QImage(img.data, img.shape[1], img.shape[0], QtGui.QImage.Format_RGB888)\n",
    "        pix = QtGui.QPixmap.fromImage(qimg)\n",
    "        self.face_label.setPixmap(pix)\n",
    "\n",
    "    @QtCore.pyqtSlot(np.ndarray)\n",
    "    def show_video_frame(self, frame):\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (336, 448))\n",
    "        qimg = QtGui.QImage(img.data, img.shape[1], img.shape[0], QtGui.QImage.Format_RGB888)\n",
    "        pix = QtGui.QPixmap.fromImage(qimg)\n",
    "        self.face_label.setPixmap(pix)\n",
    "\n",
    "    @QtCore.pyqtSlot(str, str)\n",
    "    def append_history(self, speaker, text):\n",
    "        self.chat_history.append(f\"<b>{speaker}：</b>{text}\")\n",
    "\n",
    "    @QtCore.pyqtSlot(str)\n",
    "    def show_stage(self, text):\n",
    "        self.stage_label.append(text)\n",
    "        self.stage_label.verticalScrollBar().setValue(self.stage_label.verticalScrollBar().maximum())\n",
    "\n",
    "    def on_submit(self):\n",
    "        question = self.input_box.text().strip()\n",
    "        if not question:\n",
    "            return\n",
    "        self.input_box.setText(\"\")\n",
    "        self.append_history(\"用户\", question)\n",
    "        self.show_idle()\n",
    "        self.show_stage(\"开始处理...\")\n",
    "        threading.Thread(target=self.process_conversation, args=(question,)).start()\n",
    "\n",
    "    def process_conversation(self, question):\n",
    "        t0 = time.perf_counter()\n",
    "        self.stage_signal.emit(\"等待大模型回复...\")\n",
    "        t1 = time.perf_counter()\n",
    "        answer = self.bot.chat(question)\n",
    "        t2 = time.perf_counter()\n",
    "        self.append_history_signal.emit(\"助手\", answer)\n",
    "        self.stage_signal.emit(f\"大模型回复完成，耗时：{t2-t1:.2f}s\")\n",
    "        self.stage_signal.emit(\"正在合成语音...\")\n",
    "\n",
    "        # TTS生成\n",
    "        if not answer or len(answer.strip()) < 2:\n",
    "            self.stage_signal.emit(\"回答内容过短，跳过语音与口型合成。\")\n",
    "            time.sleep(0.5)\n",
    "            self.idle_signal.emit()\n",
    "            return\n",
    "\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        t3 = time.perf_counter()\n",
    "        try:\n",
    "            audio_path = loop.run_until_complete(generate_speech(answer))\n",
    "        except Exception as e:\n",
    "            self.stage_signal.emit(f\"语音合成失败：{e}\")\n",
    "            self.idle_signal.emit()\n",
    "            return\n",
    "        t4 = time.perf_counter()\n",
    "        import os\n",
    "        if not audio_path or not os.path.exists(audio_path) or os.path.getsize(audio_path) < 800:\n",
    "            self.stage_signal.emit(\"语音文件生成失败或内容太短，跳过口型合成。\")\n",
    "            self.idle_signal.emit()\n",
    "            return\n",
    "        self.stage_signal.emit(f\"语音合成完成，耗时：{t4-t3:.2f}s\")\n",
    "        self.stage_signal.emit(\"正在生成嘴型动画...\")\n",
    "\n",
    "        # Wav2Lip驱动并在Qt界面显示帧\n",
    "        t5 = time.perf_counter()\n",
    "        gen = prepare_audio_batches(audio_path, self.face_img, self.face_coords)\n",
    "        # 修改：推理和播放分开，推理完立即输出推理耗时\n",
    "        infer_time, all_frames = self.lip_player.infer_frames(gen)\n",
    "        self.stage_signal.emit(f\"视频帧推理完成，耗时{infer_time:.2f}s\")\n",
    "        play_time = self.lip_player.play_frames(\n",
    "            audio_path,\n",
    "            all_frames,\n",
    "            lambda frame: self.show_frame_signal.emit(frame)\n",
    "        )\n",
    "        self.stage_signal.emit(f\"嘴型播放完成，耗时{play_time:.2f}s\")\n",
    "        t6 = time.perf_counter()\n",
    "        self.stage_signal.emit(\n",
    "            f\"阶段总结：LLM:{t2-t1:.2f}s，TTS:{t4-t3:.2f}s，\"\n",
    "            f\"视频帧推理:{infer_time:.2f}s，嘴型播放:{play_time:.2f}s，总计:{t6-t0:.2f}s\"\n",
    "        )\n",
    "        self.idle_signal.emit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import os\n",
    "    os.environ[\"QT_FONT_DPI\"] = \"96\"\n",
    "    if sys.platform == \"win32\":\n",
    "        import ctypes\n",
    "        ctypes.windll.shell32.SetCurrentProcessExplicitAppUserModelID(\"digitalhuman.app\")\n",
    "    sys.stdout.reconfigure(encoding='utf-8')\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    win = DigitalHumanUI()\n",
    "    win.show()\n",
    "    sys.exit(app.exec_())"
   ],
   "id": "3a366839247028f",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2323340730.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[1], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    app:\u001B[0m\n\u001B[1;37m        ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "import threading\n",
    "import asyncio\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PyQt5 import QtWidgets, QtCore, QtGui\n",
    "\n",
    "from config import API_KEY, BASE_URL, WAV2LIP_MODEL_PATH, IDLE_VIDEO_PATH, FACE_IMAGE_PATH, DEVICE\n",
    "from llm import ChatBot\n",
    "from tts import generate_speech\n",
    "from face import load_model, preprocess_image, prepare_audio_batches, LipSyncPlayer\n",
    "from asr import run_asr_thread\n",
    "\n",
    "class BubbleTextEdit(QtWidgets.QTextEdit):\n",
    "    \"\"\"带有气泡背景的聊天框\"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.setReadOnly(True)\n",
    "        self.setStyleSheet(\"\"\"\n",
    "            QTextEdit {\n",
    "                background: #f7f9fa;\n",
    "                border-radius: 10px;\n",
    "                padding: 8px;\n",
    "                font-size: 15px;\n",
    "            }\n",
    "        \"\"\")\n",
    "\n",
    "class CardFrame(QtWidgets.QFrame):\n",
    "    \"\"\"圆角卡片样式\"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.setStyleSheet(\"\"\"\n",
    "            QFrame {\n",
    "                background: rgba(255,255,255,0.78);\n",
    "                border-radius: 16px;\n",
    "                border: 1px solid #e7e7e7;\n",
    "            }\n",
    "        \"\"\")\n",
    "\n",
    "class FaceDisplayWidget(QtWidgets.QLabel):\n",
    "    \"\"\"纯圆角卡片，不带高亮光环\"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def setPixmap(self, pixmap):\n",
    "        # 圆角遮罩\n",
    "        mask = QtGui.QPixmap(pixmap.size())\n",
    "        mask.fill(QtCore.Qt.transparent)\n",
    "        painter = QtGui.QPainter(mask)\n",
    "        painter.setRenderHint(QtGui.QPainter.Antialiasing)\n",
    "        radius = 60\n",
    "        painter.setBrush(QtCore.Qt.white)\n",
    "        painter.setPen(QtCore.Qt.NoPen)\n",
    "        painter.drawRoundedRect(0, 0, pixmap.width(), pixmap.height(), radius, radius)\n",
    "        painter.end()\n",
    "        pixmap = pixmap.copy()\n",
    "        pixmap.setMask(mask.createMaskFromColor(QtCore.Qt.transparent))\n",
    "        super().setPixmap(pixmap)\n",
    "\n",
    "class DigitalHumanUI(QtWidgets.QWidget):\n",
    "    append_history_signal = QtCore.pyqtSignal(str, str)\n",
    "    show_frame_signal = QtCore.pyqtSignal(np.ndarray)\n",
    "    idle_signal = QtCore.pyqtSignal()\n",
    "    stage_signal = QtCore.pyqtSignal(str)\n",
    "    asr_text_signal = QtCore.pyqtSignal(str)\n",
    "    asr_status_signal = QtCore.pyqtSignal(bool, bool)  # (is_asr_running, is_wake)\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"数字人问答演示\")\n",
    "        self.setStyleSheet(\"background: #ecf0f4;\")\n",
    "        self.resize(1180, 700)\n",
    "        self.asr_running = False\n",
    "        self.asr_thread = None\n",
    "        self._asr_wake = False\n",
    "        self.busy = False\n",
    "        self.idle_video_thread = None\n",
    "        self.idle_video_running = threading.Event()\n",
    "        self.init_ui()\n",
    "        self.init_resources()\n",
    "        self.append_history_signal.connect(self.append_history)\n",
    "        self.show_frame_signal.connect(self.show_video_frame)\n",
    "        self.idle_signal.connect(self.show_idle)\n",
    "        self.stage_signal.connect(self.show_stage)\n",
    "        self.asr_text_signal.connect(self.on_asr_text)\n",
    "        self.asr_status_signal.connect(self.update_asr_status)\n",
    "        self.show_idle()\n",
    "        self.show_stage(\"系统待命...\")\n",
    "\n",
    "    def init_ui(self):\n",
    "        # 聊天区\n",
    "        self.chat_history = BubbleTextEdit(self)\n",
    "        self.chat_history.setFixedHeight(280)\n",
    "\n",
    "        # 阶段/进度区\n",
    "        self.stage_card = CardFrame(self)\n",
    "        self.stage_label = QtWidgets.QTextEdit(self.stage_card)\n",
    "        self.stage_label.setReadOnly(True)\n",
    "        self.stage_label.setAlignment(QtCore.Qt.AlignLeft)\n",
    "        self.stage_label.setStyleSheet(\"color:#2065d6; font-size:15px;background:transparent;border:none;\")\n",
    "        self.stage_label.setVerticalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOn)\n",
    "        vbox = QtWidgets.QVBoxLayout(self.stage_card)\n",
    "        vbox.addWidget(self.stage_label)\n",
    "        vbox.setContentsMargins(8,8,8,8)\n",
    "\n",
    "        # 状态栏\n",
    "        self.asr_status_label = QtWidgets.QLabel(\"语音识别：关闭 | 唤醒：未唤醒\", self)\n",
    "        self.asr_status_label.setStyleSheet(\"color:green; font-size:14px;\")\n",
    "        self.asr_status_label.setFixedHeight(24)\n",
    "\n",
    "        # 输入区（底部悬浮）\n",
    "        self.input_box = QtWidgets.QLineEdit(self)\n",
    "        self.input_box.setPlaceholderText(\"请输入你的问题或说话（支持语音唤醒）...\")\n",
    "        self.input_box.setStyleSheet(\"font-size:15px; border-radius:7px; padding:6px;background:#fff;\")\n",
    "        self.send_btn = QtWidgets.QPushButton(\"发送\", self)\n",
    "        self.send_btn.setStyleSheet(\"font-size:15px; padding:6px 18px; background:#2065d6; color:#fff; border-radius:7px;\")\n",
    "        self.send_btn.clicked.connect(self.on_submit)\n",
    "        self.asr_btn = QtWidgets.QPushButton(\"🎤\", self)\n",
    "        self.asr_btn.setStyleSheet(\"font-size:19px; padding:6px 15px; background:#fff; color:#2065d6; border-radius:50%;\")\n",
    "        self.asr_btn.setCheckable(True)\n",
    "        self.asr_btn.clicked.connect(self.on_toggle_asr)\n",
    "\n",
    "        left_layout = QtWidgets.QVBoxLayout()\n",
    "        left_layout.addWidget(self.chat_history)\n",
    "        left_layout.addWidget(self.stage_card)\n",
    "        left_layout.addWidget(self.asr_status_label)\n",
    "\n",
    "        left_layout.setStretch(0, 3)\n",
    "        left_layout.setStretch(1, 2)\n",
    "        left_layout.setStretch(2, 0)\n",
    "\n",
    "        # 输入区\n",
    "        input_layout = QtWidgets.QHBoxLayout()\n",
    "        input_layout.addWidget(self.input_box, 3)\n",
    "        input_layout.addWidget(self.send_btn, 1)\n",
    "        input_layout.addWidget(self.asr_btn, 0)\n",
    "        input_layout.setSpacing(12)\n",
    "        left_layout.addLayout(input_layout)\n",
    "\n",
    "        # 人像视频区（右侧卡片，无呼吸光环）\n",
    "        self.face_card = CardFrame(self)\n",
    "        self.face_card.setFixedSize(410, 570)\n",
    "        self.face_card.setStyleSheet(\"background:rgba(255,255,255,0.85);border-radius:30px;\")\n",
    "        face_vbox = QtWidgets.QVBoxLayout(self.face_card)\n",
    "        face_vbox.setContentsMargins(0,0,0,0)\n",
    "        face_vbox.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.face_label = FaceDisplayWidget(self.face_card)\n",
    "        self.face_label.setFixedSize(370, 520)\n",
    "        face_vbox.addWidget(self.face_label)\n",
    "\n",
    "        # 主布局\n",
    "        main_layout = QtWidgets.QHBoxLayout(self)\n",
    "        main_layout.addLayout(left_layout, 3)\n",
    "        main_layout.addWidget(self.face_card, 2)\n",
    "        main_layout.setSpacing(34)\n",
    "        self.setLayout(main_layout)\n",
    "\n",
    "    def init_resources(self):\n",
    "        self.bot = ChatBot(\n",
    "            api_key=API_KEY,\n",
    "            base_url=BASE_URL,\n",
    "            log_dir=\"logs\",\n",
    "            default_background=\"你是一个知识渊博的助手，能够简洁地回答问题。\",\n",
    "            default_prefix=\"请简洁地回答下述问题：\"\n",
    "        )\n",
    "        self.model = load_model(WAV2LIP_MODEL_PATH, DEVICE)\n",
    "        self.face_img, self.face_coords, self.orig_image = preprocess_image(FACE_IMAGE_PATH, device=DEVICE)\n",
    "        self.idle_video_path = IDLE_VIDEO_PATH  # 例如 'idle.mp4'\n",
    "        self.lip_player = LipSyncPlayer(self.model, DEVICE, self.orig_image, self.face_coords, fps=25)\n",
    "\n",
    "    def show_idle(self):\n",
    "        self.idle_video_running.set()\n",
    "        if self.idle_video_thread is None or not self.idle_video_thread.is_alive():\n",
    "            self.idle_video_thread = threading.Thread(target=self.play_idle_video, daemon=True)\n",
    "            self.idle_video_thread.start()\n",
    "\n",
    "    def play_idle_video(self):\n",
    "        while self.idle_video_running.is_set():\n",
    "            cap = cv2.VideoCapture(self.idle_video_path)\n",
    "            if not cap.isOpened():\n",
    "                print(f\"无法打开idle视频：{self.idle_video_path}\")\n",
    "                return\n",
    "            while self.idle_video_running.is_set():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                    continue\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = cv2.resize(frame, (360, 480))\n",
    "                pix = QtGui.QPixmap.fromImage(QtGui.QImage(frame.data, frame.shape[1], frame.shape[0], QtGui.QImage.Format_RGB888))\n",
    "                self.face_label.setPixmap(pix)\n",
    "                time.sleep(1.0 / 25)\n",
    "            cap.release()\n",
    "\n",
    "    def stop_idle_video(self):\n",
    "        self.idle_video_running.clear()\n",
    "        if self.idle_video_thread is not None:\n",
    "            self.idle_video_thread.join(timeout=0.2)\n",
    "\n",
    "    @QtCore.pyqtSlot(np.ndarray)\n",
    "    def show_video_frame(self, frame):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (360, 480))\n",
    "        pix = QtGui.QPixmap.fromImage(QtGui.QImage(frame.data, frame.shape[1], frame.shape[0], QtGui.QImage.Format_RGB888))\n",
    "        self.face_label.setPixmap(pix)\n",
    "\n",
    "    @QtCore.pyqtSlot(str, str)\n",
    "    def append_history(self, speaker, text):\n",
    "        if speaker == \"用户\":\n",
    "            self.chat_history.append(f\"<div style='text-align:right; margin:10px;'><span style='background:#2065d6;color:white;border-radius:12px;padding:8px 12px;display:inline-block;'>{text}</span></div>\")\n",
    "        else:\n",
    "            self.chat_history.append(f\"<div style='text-align:left; margin:10px;'><span style='background:#fff;color:#222;border-radius:12px;padding:8px 12px;display:inline-block;border:1px solid #e7e7e7;'>{text}</span></div>\")\n",
    "\n",
    "    @QtCore.pyqtSlot(str)\n",
    "    def show_stage(self, text):\n",
    "        self.stage_label.append(text)\n",
    "        self.stage_label.verticalScrollBar().setValue(self.stage_label.verticalScrollBar().maximum())\n",
    "\n",
    "    @QtCore.pyqtSlot(str)\n",
    "    def on_asr_text(self, text):\n",
    "        if self.busy:\n",
    "            self.stage_signal.emit(\"正在播报回答，请稍后再提问。\")\n",
    "            return\n",
    "        text = text.strip()\n",
    "        if text:\n",
    "            self.input_box.setText(text)\n",
    "            self.on_submit()\n",
    "\n",
    "    @QtCore.pyqtSlot(bool, bool)\n",
    "    def update_asr_status(self, running, wake):\n",
    "        self.asr_running = running\n",
    "        self._asr_wake = wake\n",
    "        s = f\"语音识别：{'开启' if running else '关闭'} | 唤醒：{'已唤醒' if wake else '未唤醒'}\"\n",
    "        color = \"blue\" if running else \"gray\"\n",
    "        wcolor = \"red\" if wake else \"green\"\n",
    "        self.asr_status_label.setText(s)\n",
    "        self.asr_status_label.setStyleSheet(f\"color:{wcolor if wake else color}; font-size:14px;\")\n",
    "        if not running:\n",
    "            self.asr_btn.setChecked(False)\n",
    "            self.asr_btn.setText(\"🎤\")\n",
    "        else:\n",
    "            self.asr_btn.setChecked(True)\n",
    "            self.asr_btn.setText(\"⏹\")\n",
    "\n",
    "    def on_toggle_asr(self):\n",
    "        if self.asr_running:\n",
    "            self._stop_asr()\n",
    "        else:\n",
    "            self._start_asr()\n",
    "\n",
    "    def _start_asr(self):\n",
    "        if self.asr_running:\n",
    "            return\n",
    "        self.asr_running = True\n",
    "        self.asr_btn.setText(\"⏹\")\n",
    "        self.asr_status_signal.emit(True, False)\n",
    "        self.asr_thread = threading.Thread(target=self.start_asr, daemon=True)\n",
    "        self.asr_thread.start()\n",
    "\n",
    "    def _stop_asr(self):\n",
    "        if not self.asr_running:\n",
    "            return\n",
    "        self.asr_running = False\n",
    "        self.asr_btn.setText(\"🎤\")\n",
    "        self.asr_status_signal.emit(False, False)\n",
    "\n",
    "    def start_asr(self):\n",
    "        def asr_callback(text, wake_state):\n",
    "            self.asr_status_signal.emit(True, wake_state)\n",
    "            if text and wake_state and not self.busy:\n",
    "                self.asr_text_signal.emit(text)\n",
    "        try:\n",
    "            run_asr_thread(asr_callback, lambda: self.asr_running)\n",
    "        except Exception as e:\n",
    "            self.asr_status_signal.emit(False, False)\n",
    "\n",
    "    def on_submit(self):\n",
    "        if self.busy:\n",
    "            self.stage_signal.emit(\"正在播报上一个回答，请稍后...\")\n",
    "            return\n",
    "        question = self.input_box.text().strip()\n",
    "        if not question:\n",
    "            return\n",
    "        self.input_box.setText(\"\")\n",
    "        self.append_history(\"用户\", question)\n",
    "        self.stop_idle_video()\n",
    "        self.show_stage(\"开始处理...\")\n",
    "        self.busy = True\n",
    "        threading.Thread(target=self.process_conversation, args=(question,)).start()\n",
    "\n",
    "    def process_conversation(self, question):\n",
    "        t0 = time.perf_counter()\n",
    "        self.stage_signal.emit(\"等待大模型回复...\")\n",
    "        t1 = time.perf_counter()\n",
    "        answer = self.bot.chat(question)\n",
    "        t2 = time.perf_counter()\n",
    "        self.append_history_signal.emit(\"助手\", answer)\n",
    "        self.stage_signal.emit(f\"大模型回复完成，耗时：{t2-t1:.2f}s\")\n",
    "        self.stage_signal.emit(\"正在合成语音...\")\n",
    "\n",
    "        if not answer or len(answer.strip()) < 2:\n",
    "            self.stage_signal.emit(\"回答内容过短，跳过语音与口型合成。\")\n",
    "            time.sleep(0.5)\n",
    "            self.idle_signal.emit()\n",
    "            self.busy = False\n",
    "            return\n",
    "\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        t3 = time.perf_counter()\n",
    "        try:\n",
    "            audio_path = loop.run_until_complete(generate_speech(answer))\n",
    "        except Exception as e:\n",
    "            self.stage_signal.emit(f\"语音合成失败：{e}\")\n",
    "            self.idle_signal.emit()\n",
    "            self.busy = False\n",
    "            return\n",
    "        t4 = time.perf_counter()\n",
    "        import os\n",
    "        if not audio_path or not os.path.exists(audio_path) or os.path.getsize(audio_path) < 800:\n",
    "            self.stage_signal.emit(\"语音文件生成失败或内容太短，跳过口型合成。\")\n",
    "            self.idle_signal.emit()\n",
    "            self.busy = False\n",
    "            return\n",
    "        self.stage_signal.emit(f\"语音合成完成，耗时：{t4-t3:.2f}s\")\n",
    "        self.stage_signal.emit(\"正在生成嘴型动画...\")\n",
    "\n",
    "        t5 = time.perf_counter()\n",
    "        gen = prepare_audio_batches(audio_path, self.face_img, self.face_coords)\n",
    "        infer_time, all_frames = self.lip_player.infer_frames(gen)\n",
    "        self.stage_signal.emit(f\"视频帧推理完成，耗时{infer_time:.2f}s\")\n",
    "        play_time = self.lip_player.play_frames(\n",
    "            audio_path,\n",
    "            all_frames,\n",
    "            lambda frame: self.show_frame_signal.emit(frame)\n",
    "        )\n",
    "        self.stage_signal.emit(f\"嘴型播放完成，耗时{play_time:.2f}s\")\n",
    "        t6 = time.perf_counter()\n",
    "        self.stage_signal.emit(\n",
    "            f\"阶段总结：LLM:{t2-t1:.2f}s，TTS:{t4-t3:.2f}s，\"\n",
    "            f\"视频帧推理:{infer_time:.2f}s，嘴型播放:{play_time:.2f}s，总计:{t6-t0:.2f}s\"\n",
    "        )\n",
    "        self.idle_signal.emit()\n",
    "        self.busy = False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import os\n",
    "    os.environ[\"QT_FONT_DPI\"] = \"96\"\n",
    "    if sys.platform == \"win32\":\n",
    "        import ctypes\n",
    "        ctypes.windll.shell32.SetCurrentProcessExplicitAppUserModelID(\"digitalhuman.app\")\n",
    "    sys.stdout.reconfigure(encoding='utf-8')\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    win = DigitalHumanUI()\n",
    "    win.show()\n",
    "    sys.exit(app.exec_())"
   ],
   "id": "3c657f0b446ddb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "import threading\n",
    "import asyncio\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PyQt5 import QtWidgets, QtCore, QtGui, QtMultimedia\n",
    "\n",
    "from config import API_KEY, BASE_URL, WAV2LIP_MODEL_PATH, IDLE_VIDEO_PATH, FACE_IMAGE_PATH, DEVICE\n",
    "from llm import ChatBot\n",
    "from tts import generate_speech\n",
    "from face import load_model, preprocess_image, prepare_audio_batches, LipSyncPlayer\n",
    "from asr import run_asr_thread\n",
    "\n",
    "class BubbleTextEdit(QtWidgets.QTextEdit):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.setReadOnly(True)\n",
    "        self.setStyleSheet(\"\"\"\n",
    "            QTextEdit {\n",
    "                background: #181a1b;\n",
    "                border-radius: 12px;\n",
    "                padding: 8px;\n",
    "                font-size: 16px;\n",
    "                color: #e6e6e6;\n",
    "                border: 1px solid #232323;\n",
    "            }\n",
    "        \"\"\")\n",
    "\n",
    "    def append_bubble(self, text, speaker):\n",
    "        if speaker == \"用户\":\n",
    "            self.append(\n",
    "                f\"<div style='text-align:right; margin:10px;'><span style='background:#2e2f31;color:#4faaff;border-radius:14px;padding:10px 16px;display:inline-block;'>{text}</span></div>\"\n",
    "            )\n",
    "        else:\n",
    "            self.append(\n",
    "                f\"<div style='text-align:left; margin:10px;'><span style='background:#2e2f31;color:#f7f7f7;border-radius:14px;padding:10px 16px;display:inline-block;'>{text}</span></div>\"\n",
    "            )\n",
    "\n",
    "class CardFrame(QtWidgets.QFrame):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.setStyleSheet(\"\"\"\n",
    "            QFrame {\n",
    "                background: rgba(34,34,34,0.92);\n",
    "                border-radius: 22px;\n",
    "                border: 1.5px solid #232323;\n",
    "            }\n",
    "        \"\"\")\n",
    "\n",
    "class FaceDisplayWidget(QtWidgets.QLabel):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.setStyleSheet(\"background:transparent;\")\n",
    "        self.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.setScaledContents(True)\n",
    "\n",
    "class AudioPlayer(QtCore.QObject):\n",
    "    finished = QtCore.pyqtSignal()\n",
    "    def __init__(self, parent=None):\n",
    "        super().__init__(parent)\n",
    "        self.player = QtMultimedia.QMediaPlayer()\n",
    "        self.player.setVolume(100)\n",
    "        self.player.mediaStatusChanged.connect(self.handle_status)\n",
    "\n",
    "    def play(self, audio_path):\n",
    "        if self.player.state() == QtMultimedia.QMediaPlayer.PlayingState:\n",
    "            self.player.stop()\n",
    "        url = QtCore.QUrl.fromLocalFile(os.path.abspath(audio_path))\n",
    "        self.player.setMedia(QtMultimedia.QMediaContent(url))\n",
    "        self.player.play()\n",
    "\n",
    "    def handle_status(self, status):\n",
    "        if status in (QtMultimedia.QMediaPlayer.EndOfMedia, QtMultimedia.QMediaPlayer.InvalidMedia):\n",
    "            self.finished.emit()\n",
    "\n",
    "class DigitalHumanUI(QtWidgets.QWidget):\n",
    "    append_history_signal = QtCore.pyqtSignal(str, str)\n",
    "    show_frame_signal = QtCore.pyqtSignal(QtGui.QPixmap)\n",
    "    idle_signal = QtCore.pyqtSignal()\n",
    "    stage_signal = QtCore.pyqtSignal(str)\n",
    "    asr_text_signal = QtCore.pyqtSignal(str)\n",
    "    asr_status_signal = QtCore.pyqtSignal(bool, bool)\n",
    "    play_video_frames_signal = QtCore.pyqtSignal(list, str, float)\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"数字人问答演示\")\n",
    "        self.setStyleSheet(\"QWidget { background: #000; }\")\n",
    "        self.resize(1400, 900)\n",
    "        self.asr_running = False\n",
    "        self.asr_thread = None\n",
    "        self._asr_wake = False\n",
    "        self.busy = False\n",
    "        self.idle_video_thread = None\n",
    "        self.idle_video_running = threading.Event()\n",
    "        self._last_pixmap = None\n",
    "        self._last_face_size = (0, 0)\n",
    "        self.audio_player = AudioPlayer()\n",
    "        self.sync_timer = QtCore.QTimer(self)\n",
    "        self.sync_timer.timeout.connect(self._sync_frame_with_audio)\n",
    "        self.video_frames = []\n",
    "        self.video_frame_count = 0\n",
    "        self.target_fps = 25\n",
    "        self.audio_total_ms = 0\n",
    "        self.init_ui()\n",
    "        self.init_resources()\n",
    "        self.append_history_signal.connect(self.append_history)\n",
    "        self.show_frame_signal.connect(self._show_pixmap_mainthread)\n",
    "        self.idle_signal.connect(self.show_idle)\n",
    "        self.stage_signal.connect(self.show_stage)\n",
    "        self.asr_text_signal.connect(self.on_asr_text)\n",
    "        self.asr_status_signal.connect(self.update_asr_status)\n",
    "        self.play_video_frames_signal.connect(self.play_video_frames)\n",
    "        self.show_idle()\n",
    "        self.show_stage(\"系统待命...\")\n",
    "\n",
    "    def init_ui(self):\n",
    "        self.outer_layout = QtWidgets.QVBoxLayout(self)\n",
    "        self.outer_layout.setContentsMargins(0, 0, 0, 0)\n",
    "        self.outer_layout.setSpacing(0)\n",
    "        self.top_panel = QtWidgets.QWidget(self)\n",
    "        self.top_layout = QtWidgets.QHBoxLayout(self.top_panel)\n",
    "        self.top_layout.setContentsMargins(0, 0, 0, 0)\n",
    "        self.top_layout.setSpacing(0)\n",
    "\n",
    "        self.left_panel = QtWidgets.QWidget(self.top_panel)\n",
    "        self.left_layout = QtWidgets.QVBoxLayout(self.left_panel)\n",
    "        self.left_layout.setContentsMargins(24, 24, 12, 24)\n",
    "        self.left_layout.setSpacing(18)\n",
    "        self.chat_history = BubbleTextEdit(parent=self.left_panel)\n",
    "        self.left_layout.addWidget(self.chat_history)\n",
    "        self.left_panel.setStyleSheet(\"background:transparent;\")\n",
    "        self.top_layout.addWidget(self.left_panel)\n",
    "\n",
    "        self.center_panel = QtWidgets.QWidget(self.top_panel)\n",
    "        self.center_panel.setStyleSheet(\"background:transparent;\")\n",
    "        self.face_label = FaceDisplayWidget(self.center_panel)\n",
    "        self.center_layout = QtWidgets.QVBoxLayout(self.center_panel)\n",
    "        self.center_layout.setContentsMargins(0, 0, 0, 0)\n",
    "        self.center_layout.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.center_layout.addStretch()\n",
    "        self.center_layout.addWidget(self.face_label, alignment=QtCore.Qt.AlignHCenter | QtCore.Qt.AlignVCenter)\n",
    "        self.center_layout.addStretch()\n",
    "        self.top_layout.addWidget(self.center_panel)\n",
    "\n",
    "        self.right_panel = QtWidgets.QWidget(self.top_panel)\n",
    "        self.right_layout = QtWidgets.QVBoxLayout(self.right_panel)\n",
    "        self.right_layout.setContentsMargins(12, 24, 24, 24)\n",
    "        self.right_layout.setSpacing(18)\n",
    "        self.stage_card = CardFrame(self.right_panel)\n",
    "        self.stage_label = QtWidgets.QTextEdit(self.stage_card)\n",
    "        self.stage_label.setReadOnly(True)\n",
    "        self.stage_label.setAlignment(QtCore.Qt.AlignLeft)\n",
    "        self.stage_label.setStyleSheet(\"color:#4faaff; font-size:16px;background:transparent;border:none;\")\n",
    "        self.stage_label.setVerticalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOn)\n",
    "        vbox = QtWidgets.QVBoxLayout(self.stage_card)\n",
    "        vbox.addWidget(self.stage_label)\n",
    "        vbox.setContentsMargins(10, 10, 10, 10)\n",
    "        self.right_layout.addWidget(self.stage_card)\n",
    "        self.right_panel.setStyleSheet(\"background:transparent;\")\n",
    "        self.top_layout.addWidget(self.right_panel)\n",
    "\n",
    "        self.outer_layout.addWidget(self.top_panel, stretch=10)\n",
    "\n",
    "        self.input_panel = QtWidgets.QWidget(self)\n",
    "        input_layout = QtWidgets.QHBoxLayout(self.input_panel)\n",
    "        input_layout.setContentsMargins(48, 0, 48, 18)\n",
    "        input_layout.setSpacing(16)\n",
    "        self.input_box = QtWidgets.QLineEdit(self.input_panel)\n",
    "        self.input_box.setPlaceholderText(\"请输入你的问题或说话（支持语音唤醒）...\")\n",
    "        self.input_box.setStyleSheet(\"\"\"\n",
    "            font-size:17px; border-radius:12px; padding:10px; background:#181a1b;\n",
    "            border:2px solid #232323; color:#e6e6e6;\n",
    "        \"\"\")\n",
    "        self.send_btn = QtWidgets.QPushButton(\"发送\", self.input_panel)\n",
    "        self.send_btn.setStyleSheet(\"\"\"\n",
    "            font-size:17px; padding:10px 28px; background:#4faaff; color:#15181a; border-radius:10px;\n",
    "            font-weight:bold;\n",
    "        \"\"\")\n",
    "        self.send_btn.clicked.connect(self.on_submit)\n",
    "        self.asr_btn = QtWidgets.QPushButton(\"🎤\", self.input_panel)\n",
    "        self.asr_btn.setStyleSheet(\"\"\"\n",
    "            font-size:24px; padding:10px 16px; background:#232323; color:#4faaff; border-radius:50%;\n",
    "            border:2px solid #232323;\n",
    "        \"\"\")\n",
    "        self.asr_btn.setCheckable(True)\n",
    "        self.asr_btn.clicked.connect(self.on_toggle_asr)\n",
    "\n",
    "        input_layout.addWidget(self.input_box, 10)\n",
    "        input_layout.addWidget(self.send_btn, 2)\n",
    "        input_layout.addWidget(self.asr_btn, 1)\n",
    "        self.input_panel.setStyleSheet(\"background:transparent;\")\n",
    "        self.outer_layout.addWidget(self.input_panel, stretch=0)\n",
    "\n",
    "        self.asr_status_label = QtWidgets.QLabel(\"语音识别：关闭 | 唤醒：未唤醒\", self)\n",
    "        self.asr_status_label.setStyleSheet(\"color:#4faaff; font-size:15px; font-weight:bold; background:transparent;\")\n",
    "        self.asr_status_label.setAlignment(QtCore.Qt.AlignRight)\n",
    "        self.asr_status_label.setFixedHeight(24)\n",
    "        self.outer_layout.addWidget(self.asr_status_label, alignment=QtCore.Qt.AlignRight)\n",
    "\n",
    "        self.top_layout.setStretch(0, 1)\n",
    "        self.top_layout.setStretch(1, 1)\n",
    "        self.top_layout.setStretch(2, 1)\n",
    "        self.outer_layout.setStretch(0, 15)\n",
    "        self.outer_layout.setStretch(1, 0)\n",
    "        self.outer_layout.setStretch(2, 0)\n",
    "        self.resizeEvent = self.on_resize\n",
    "\n",
    "    def update_center_panel_geometry(self):\n",
    "        w = self.center_panel.width()\n",
    "        h = self.center_panel.height()\n",
    "        self.face_label.setMinimumSize(w, h)\n",
    "        self.face_label.setMaximumSize(w, h)\n",
    "        self._last_face_size = (w, h)\n",
    "        if self._last_pixmap is not None:\n",
    "            self._show_pixmap_mainthread(self._last_pixmap)\n",
    "\n",
    "    def on_resize(self, event):\n",
    "        self.update_center_panel_geometry()\n",
    "        event.accept()\n",
    "\n",
    "    def init_resources(self):\n",
    "        self.bot = ChatBot(\n",
    "            api_key=API_KEY,\n",
    "            base_url=BASE_URL,\n",
    "            log_dir=\"logs\",\n",
    "            default_background=\"你是一个知识渊博的助手，能够简洁地回答问题。\",\n",
    "            default_prefix=\"请简洁地回答下述问题：\"\n",
    "        )\n",
    "        self.model = load_model(WAV2LIP_MODEL_PATH, DEVICE)\n",
    "        self.face_img, self.face_coords, self.orig_image = preprocess_image(FACE_IMAGE_PATH, device=DEVICE)\n",
    "        self.idle_video_path = IDLE_VIDEO_PATH\n",
    "        self.lip_player = LipSyncPlayer(self.model, DEVICE, self.orig_image, self.face_coords, fps=25)\n",
    "\n",
    "    def show_idle(self):\n",
    "        self.stop_sync()\n",
    "        self.idle_video_running.set()\n",
    "        if self.idle_video_thread is None or not self.idle_video_thread.is_alive():\n",
    "            self.idle_video_thread = threading.Thread(target=self.play_idle_video, daemon=True)\n",
    "            self.idle_video_thread.start()\n",
    "\n",
    "    def play_idle_video(self):\n",
    "        while self.idle_video_running.is_set():\n",
    "            cap = cv2.VideoCapture(self.idle_video_path)\n",
    "            if not cap.isOpened():\n",
    "                print(f\"无法打开idle视频：{self.idle_video_path}\")\n",
    "                return\n",
    "            while self.idle_video_running.is_set():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                    continue\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                w, h = self._last_face_size\n",
    "                if w < 10 or h < 10:\n",
    "                    w, h = 300, 400\n",
    "                frame = cv2.resize(frame, (w, h))\n",
    "                qtimg = QtGui.QImage(frame.data, frame.shape[1], frame.shape[0], QtGui.QImage.Format_RGB888)\n",
    "                pix = QtGui.QPixmap.fromImage(qtimg)\n",
    "                self._last_pixmap = pix\n",
    "                self.show_frame_signal.emit(pix)\n",
    "                time.sleep(1.0 / 25)\n",
    "            cap.release()\n",
    "\n",
    "    def stop_idle_video(self):\n",
    "        self.idle_video_running.clear()\n",
    "\n",
    "    def stop_sync(self):\n",
    "        if self.sync_timer.isActive():\n",
    "            self.sync_timer.stop()\n",
    "        self.video_frames = []\n",
    "        self.video_frame_count = 0\n",
    "        self.audio_total_ms = 0\n",
    "\n",
    "    @QtCore.pyqtSlot(QtGui.QPixmap)\n",
    "    def _show_pixmap_mainthread(self, pix):\n",
    "        w, h = self._last_face_size\n",
    "        scaled = pix.scaled(w, h, QtCore.Qt.IgnoreAspectRatio, QtCore.Qt.SmoothTransformation)\n",
    "        self.face_label.setPixmap(scaled)\n",
    "        self._last_pixmap = pix\n",
    "\n",
    "    @QtCore.pyqtSlot(str, str)\n",
    "    def append_history(self, speaker, text):\n",
    "        self.chat_history.append_bubble(text, speaker)\n",
    "\n",
    "    @QtCore.pyqtSlot(str)\n",
    "    def show_stage(self, text):\n",
    "        self.stage_label.append(f\"<div style='color:#4faaff'>{text}</div>\")\n",
    "        self.stage_label.verticalScrollBar().setValue(self.stage_label.verticalScrollBar().maximum())\n",
    "\n",
    "    @QtCore.pyqtSlot(np.ndarray)\n",
    "    def show_video_frame(self, frame):\n",
    "        w, h = self._last_face_size\n",
    "        if w < 10 or h < 10:\n",
    "            w, h = 300, 400\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (w, h))\n",
    "        qtimg = QtGui.QImage(frame.data, frame.shape[1], frame.shape[0], QtGui.QImage.Format_RGB888)\n",
    "        pix = QtGui.QPixmap.fromImage(qtimg)\n",
    "        self._last_pixmap = pix\n",
    "        self.show_frame_signal.emit(pix)\n",
    "\n",
    "    @QtCore.pyqtSlot(list, str, float)\n",
    "    def play_video_frames(self, frames, audio_path, audio_duration):\n",
    "        self.stop_idle_video()  # 只在此处暂停idle\n",
    "        self.stop_sync()\n",
    "        self.video_frames = frames\n",
    "        self.video_frame_count = len(frames)\n",
    "        self.target_fps = 25\n",
    "        self.audio_total_ms = int(audio_duration * 1000)\n",
    "        self.audio_player.play(audio_path)\n",
    "        self.sync_timer.start(20)\n",
    "\n",
    "    def _sync_frame_with_audio(self):\n",
    "        ms = self.audio_player.player.position()\n",
    "        if ms <= 0:\n",
    "            return\n",
    "        idx = int(ms * self.target_fps / 1000)\n",
    "        idx = min(idx, self.video_frame_count - 1)\n",
    "        if 0 <= idx < self.video_frame_count:\n",
    "            frame = self.video_frames[idx]\n",
    "            self.show_video_frame(frame)\n",
    "        if ms >= self.audio_total_ms - 20 or idx >= self.video_frame_count - 1:\n",
    "            self.sync_timer.stop()\n",
    "            self.idle_signal.emit()\n",
    "\n",
    "    @QtCore.pyqtSlot(str)\n",
    "    def on_asr_text(self, text):\n",
    "        if self.busy:\n",
    "            self.stage_signal.emit(\"正在播报回答，请稍后再提问。\")\n",
    "            return\n",
    "        text = text.strip()\n",
    "        if text:\n",
    "            self.input_box.setText(text)\n",
    "            self.on_submit()\n",
    "\n",
    "    @QtCore.pyqtSlot(bool, bool)\n",
    "    def update_asr_status(self, running, wake):\n",
    "        self.asr_running = running\n",
    "        self._asr_wake = wake\n",
    "        s = f\"语音识别：{'开启' if running else '关闭'} | 唤醒：{'已唤醒' if wake else '未唤醒'}\"\n",
    "        color = \"#4faaff\" if running else \"#555\"\n",
    "        wcolor = \"#ff5050\" if wake else \"#4faaff\"\n",
    "        self.asr_status_label.setText(s)\n",
    "        self.asr_status_label.setStyleSheet(f\"color:{wcolor if wake else color}; font-size:15px; font-weight:bold; background:transparent;\")\n",
    "        if not running:\n",
    "            self.asr_btn.setChecked(False)\n",
    "            self.asr_btn.setText(\"🎤\")\n",
    "        else:\n",
    "            self.asr_btn.setChecked(True)\n",
    "            self.asr_btn.setText(\"⏹\")\n",
    "\n",
    "    def on_toggle_asr(self):\n",
    "        if self.asr_running:\n",
    "            self._stop_asr()\n",
    "        else:\n",
    "            self._start_asr()\n",
    "\n",
    "    def _start_asr(self):\n",
    "        if self.asr_running:\n",
    "            return\n",
    "        self.asr_running = True\n",
    "        self.asr_btn.setText(\"⏹\")\n",
    "        self.asr_status_signal.emit(True, False)\n",
    "        self.asr_thread = threading.Thread(target=self.start_asr, daemon=True)\n",
    "        self.asr_thread.start()\n",
    "\n",
    "    def _stop_asr(self):\n",
    "        if not self.asr_running:\n",
    "            return\n",
    "        self.asr_running = False\n",
    "        self.asr_btn.setText(\"🎤\")\n",
    "        self.asr_status_signal.emit(False, False)\n",
    "\n",
    "    def start_asr(self):\n",
    "        def asr_callback(text, wake_state):\n",
    "            self.asr_status_signal.emit(True, wake_state)\n",
    "            if text and wake_state and not self.busy:\n",
    "                self.asr_text_signal.emit(text)\n",
    "        try:\n",
    "            run_asr_thread(asr_callback, lambda: self.asr_running)\n",
    "        except Exception as e:\n",
    "            self.asr_status_signal.emit(False, False)\n",
    "\n",
    "    def on_submit(self):\n",
    "        if self.busy:\n",
    "            self.stage_signal.emit(\"正在播报上一个回答，请稍后...\")\n",
    "            return\n",
    "        question = self.input_box.text().strip()\n",
    "        if not question:\n",
    "            return\n",
    "        self.input_box.setText(\"\")\n",
    "        self.append_history(\"用户\", question)\n",
    "        # self.stop_idle_video()  # 不要在这里暂停idle\n",
    "        self.show_stage(\"开始处理...\")\n",
    "        self.busy = True\n",
    "        threading.Thread(target=self.process_conversation, args=(question,)).start()\n",
    "\n",
    "    def process_conversation(self, question):\n",
    "        t0 = time.perf_counter()\n",
    "        self.stage_signal.emit(\"等待大模型回复...\")\n",
    "        t1 = time.perf_counter()\n",
    "        answer = self.bot.chat(question)\n",
    "        t2 = time.perf_counter()\n",
    "        self.append_history_signal.emit(\"助手\", answer)\n",
    "        self.stage_signal.emit(f\"大模型回复完成，耗时：{t2-t1:.2f}s\")\n",
    "        self.stage_signal.emit(\"正在合成语音...\")\n",
    "\n",
    "        if not answer or len(answer.strip()) < 2:\n",
    "            self.stage_signal.emit(\"回答内容过短，跳过语音与口型合成。\")\n",
    "            time.sleep(0.5)\n",
    "            self.idle_signal.emit()\n",
    "            self.busy = False\n",
    "            return\n",
    "\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        t3 = time.perf_counter()\n",
    "        try:\n",
    "            audio_path = loop.run_until_complete(generate_speech(answer))\n",
    "        except Exception as e:\n",
    "            self.stage_signal.emit(f\"语音合成失败：{e}\")\n",
    "            self.idle_signal.emit()\n",
    "            self.busy = False\n",
    "            return\n",
    "        t4 = time.perf_counter()\n",
    "        if not audio_path or not os.path.exists(audio_path) or os.path.getsize(audio_path) < 800:\n",
    "            self.stage_signal.emit(\"语音文件生成失败或内容太短，跳过口型合成。\")\n",
    "            self.idle_signal.emit()\n",
    "            self.busy = False\n",
    "            return\n",
    "        import soundfile as sf\n",
    "        audio_info = sf.info(audio_path)\n",
    "        audio_duration = float(audio_info.duration)\n",
    "        self.stage_signal.emit(f\"语音合成完成，耗时：{t4-t3:.2f}s\")\n",
    "        self.stage_signal.emit(\"正在生成嘴型动画...\")\n",
    "\n",
    "        t5 = time.perf_counter()\n",
    "        gen = prepare_audio_batches(audio_path, self.face_img, self.face_coords)\n",
    "        infer_time, all_frames = self.lip_player.infer_frames(gen)\n",
    "        self.stage_signal.emit(f\"视频帧推理完成，耗时{infer_time:.2f}s\")\n",
    "        self.stage_signal.emit(\"正在播放语音与动画...\")\n",
    "\n",
    "        self.play_video_frames_signal.emit(all_frames, audio_path, audio_duration)\n",
    "\n",
    "        t6 = time.perf_counter()\n",
    "        self.busy = False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.environ[\"QT_FONT_DPI\"] = \"96\"\n",
    "    if sys.platform == \"win32\":\n",
    "        import ctypes\n",
    "        ctypes.windll.shell32.SetCurrentProcessExplicitAppUserModelID(\"digitalhuman.app\")\n",
    "    sys.stdout.reconfigure(encoding='utf-8')\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    win = DigitalHumanUI()\n",
    "    win.show()\n",
    "    sys.exit(app.exec_())"
   ],
   "id": "6069e6e3fd720f60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c6b155b4efb148e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnb,wameni\n",
   "id": "6b3f8d7787796434"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "import threading\n",
    "import asyncio\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PyQt5 import QtWidgets, QtCore, QtGui, QtMultimedia\n",
    "\n",
    "from config import API_KEY, BASE_URL, WAV2LIP_MODEL_PATH, IDLE_VIDEO_PATH, FACE_IMAGE_PATH, DEVICE\n",
    "from llm import ChatBot\n",
    "from tts import generate_speech\n",
    "from face import load_model, preprocess_image, prepare_audio_batches, LipSyncPlayer\n",
    "from asr import run_asr_thread\n",
    "\n",
    "class BubbleTextEdit(QtWidgets.QTextEdit):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.setReadOnly(True)\n",
    "        self.setStyleSheet(\"\"\"\n",
    "            QTextEdit {\n",
    "                background: #181a1b;\n",
    "                border-radius: 12px;\n",
    "                padding: 8px;\n",
    "                font-size: 16px;\n",
    "                color: #e6e6e6;\n",
    "                border: 1px solid #232323;\n",
    "            }\n",
    "        \"\"\")\n",
    "\n",
    "    def append_bubble(self, text, speaker):\n",
    "        if speaker == \"用户\":\n",
    "            self.append(\n",
    "                f\"<div style='text-align:right; margin:10px;'><span style='background:#2e2f31;color:#4faaff;border-radius:14px;padding:10px 16px;display:inline-block;'>{text}</span></div>\"\n",
    "            )\n",
    "        else:\n",
    "            self.append(\n",
    "                f\"<div style='text-align:left; margin:10px;'><span style='background:#2e2f31;color:#f7f7f7;border-radius:14px;padding:10px 16px;display:inline-block;'>{text}</span></div>\"\n",
    "            )\n",
    "\n",
    "class CardFrame(QtWidgets.QFrame):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.setStyleSheet(\"\"\"\n",
    "            QFrame {\n",
    "                background: rgba(34,34,34,0.92);\n",
    "                border-radius: 22px;\n",
    "                border: 1.5px solid #232323;\n",
    "            }\n",
    "        \"\"\")\n",
    "\n",
    "class FaceDisplayWidget(QtWidgets.QLabel):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.setStyleSheet(\"background:transparent;\")\n",
    "        self.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.setScaledContents(True)\n",
    "\n",
    "class AudioPlayer(QtCore.QObject):\n",
    "    finished = QtCore.pyqtSignal()\n",
    "    def __init__(self, parent=None):\n",
    "        super().__init__(parent)\n",
    "        self.player = QtMultimedia.QMediaPlayer()\n",
    "        self.player.setVolume(100)\n",
    "        self.player.mediaStatusChanged.connect(self.handle_status)\n",
    "\n",
    "    def play(self, audio_path):\n",
    "        if self.player.state() == QtMultimedia.QMediaPlayer.PlayingState:\n",
    "            self.player.stop()\n",
    "        url = QtCore.QUrl.fromLocalFile(os.path.abspath(audio_path))\n",
    "        self.player.setMedia(QtMultimedia.QMediaContent(url))\n",
    "        self.player.play()\n",
    "\n",
    "    def handle_status(self, status):\n",
    "        if status in (QtMultimedia.QMediaPlayer.EndOfMedia, QtMultimedia.QMediaPlayer.InvalidMedia):\n",
    "            self.finished.emit()\n",
    "\n",
    "class DigitalHumanUI(QtWidgets.QWidget):\n",
    "    append_history_signal = QtCore.pyqtSignal(str, str)\n",
    "    show_frame_signal = QtCore.pyqtSignal(QtGui.QPixmap)\n",
    "    idle_signal = QtCore.pyqtSignal()\n",
    "    stage_signal = QtCore.pyqtSignal(str)\n",
    "    asr_text_signal = QtCore.pyqtSignal(str)\n",
    "    asr_status_signal = QtCore.pyqtSignal(bool, bool)\n",
    "    play_video_frames_signal = QtCore.pyqtSignal(list, str, float)\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"数字人问答演示\")\n",
    "        self.setStyleSheet(\"QWidget { background: #000; }\")\n",
    "        self.resize(1400, 900)\n",
    "        self.asr_running = False\n",
    "        self.asr_thread = None\n",
    "        self._asr_wake = False\n",
    "        self.busy = False\n",
    "        self.idle_video_thread = None\n",
    "        self.idle_video_running = threading.Event()\n",
    "        self._last_pixmap = None\n",
    "        self._last_face_size = (0, 0)\n",
    "        self.audio_player = AudioPlayer()\n",
    "        self.sync_timer = QtCore.QTimer(self)\n",
    "        self.sync_timer.timeout.connect(self._sync_frame_with_audio)\n",
    "        self.video_frames = []\n",
    "        self.video_frame_count = 0\n",
    "        self.target_fps = 25\n",
    "        self.audio_total_ms = 0\n",
    "        self.init_ui()\n",
    "        self.init_resources()\n",
    "        self.append_history_signal.connect(self.append_history)\n",
    "        self.show_frame_signal.connect(self._show_pixmap_mainthread)\n",
    "        self.idle_signal.connect(self.show_idle)\n",
    "        self.stage_signal.connect(self.show_stage)\n",
    "        self.asr_text_signal.connect(self.on_asr_text)\n",
    "        self.asr_status_signal.connect(self.update_asr_status)\n",
    "        self.play_video_frames_signal.connect(self.play_video_frames)\n",
    "        self.show_idle()\n",
    "        self.show_stage(\"系统待命...\")\n",
    "\n",
    "    def init_ui(self):\n",
    "        self.outer_layout = QtWidgets.QVBoxLayout(self)\n",
    "        self.outer_layout.setContentsMargins(0, 0, 0, 0)\n",
    "        self.outer_layout.setSpacing(0)\n",
    "        self.top_panel = QtWidgets.QWidget(self)\n",
    "        self.top_layout = QtWidgets.QHBoxLayout(self.top_panel)\n",
    "        self.top_layout.setContentsMargins(0, 0, 0, 0)\n",
    "        self.top_layout.setSpacing(0)\n",
    "\n",
    "        self.left_panel = QtWidgets.QWidget(self.top_panel)\n",
    "        self.left_layout = QtWidgets.QVBoxLayout(self.left_panel)\n",
    "        self.left_layout.setContentsMargins(24, 24, 12, 24)\n",
    "        self.left_layout.setSpacing(18)\n",
    "        self.chat_history = BubbleTextEdit(parent=self.left_panel)\n",
    "        self.left_layout.addWidget(self.chat_history)\n",
    "        self.left_panel.setStyleSheet(\"background:transparent;\")\n",
    "        self.top_layout.addWidget(self.left_panel)\n",
    "\n",
    "        self.center_panel = QtWidgets.QWidget(self.top_panel)\n",
    "        self.center_panel.setStyleSheet(\"background:transparent;\")\n",
    "        self.face_label = FaceDisplayWidget(self.center_panel)\n",
    "        self.center_layout = QtWidgets.QVBoxLayout(self.center_panel)\n",
    "        self.center_layout.setContentsMargins(0, 0, 0, 0)\n",
    "        self.center_layout.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.center_layout.addStretch()\n",
    "        self.center_layout.addWidget(self.face_label, alignment=QtCore.Qt.AlignHCenter | QtCore.Qt.AlignVCenter)\n",
    "        self.center_layout.addStretch()\n",
    "        self.top_layout.addWidget(self.center_panel)\n",
    "\n",
    "        self.right_panel = QtWidgets.QWidget(self.top_panel)\n",
    "        self.right_layout = QtWidgets.QVBoxLayout(self.right_panel)\n",
    "        self.right_layout.setContentsMargins(12, 24, 24, 24)\n",
    "        self.right_layout.setSpacing(18)\n",
    "        self.stage_card = CardFrame(self.right_panel)\n",
    "        self.stage_label = QtWidgets.QTextEdit(self.stage_card)\n",
    "        self.stage_label.setReadOnly(True)\n",
    "        self.stage_label.setAlignment(QtCore.Qt.AlignLeft)\n",
    "        self.stage_label.setStyleSheet(\"color:#4faaff; font-size:16px;background:transparent;border:none;\")\n",
    "        self.stage_label.setVerticalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOn)\n",
    "        vbox = QtWidgets.QVBoxLayout(self.stage_card)\n",
    "        vbox.addWidget(self.stage_label)\n",
    "        vbox.setContentsMargins(10, 10, 10, 10)\n",
    "        self.right_layout.addWidget(self.stage_card)\n",
    "        self.right_panel.setStyleSheet(\"background:transparent;\")\n",
    "        self.top_layout.addWidget(self.right_panel)\n",
    "\n",
    "        self.outer_layout.addWidget(self.top_panel, stretch=10)\n",
    "\n",
    "        self.input_panel = QtWidgets.QWidget(self)\n",
    "        input_layout = QtWidgets.QHBoxLayout(self.input_panel)\n",
    "        input_layout.setContentsMargins(48, 0, 48, 18)\n",
    "        input_layout.setSpacing(16)\n",
    "        self.input_box = QtWidgets.QLineEdit(self.input_panel)\n",
    "        self.input_box.setPlaceholderText(\"请输入你的问题或说话（支持语音唤醒）...\")\n",
    "        self.input_box.setStyleSheet(\"\"\"\n",
    "            font-size:17px; border-radius:12px; padding:10px; background:#181a1b;\n",
    "            border:2px solid #232323; color:#e6e6e6;\n",
    "        \"\"\")\n",
    "        self.send_btn = QtWidgets.QPushButton(\"发送\", self.input_panel)\n",
    "        self.send_btn.setStyleSheet(\"\"\"\n",
    "            font-size:17px; padding:10px 28px; background:#4faaff; color:#15181a; border-radius:10px;\n",
    "            font-weight:bold;\n",
    "        \"\"\")\n",
    "        self.send_btn.clicked.connect(self.on_submit)\n",
    "        self.asr_btn = QtWidgets.QPushButton(\"🎤\", self.input_panel)\n",
    "        self.asr_btn.setStyleSheet(\"\"\"\n",
    "            font-size:24px; padding:10px 16px; background:#232323; color:#4faaff; border-radius:50%;\n",
    "            border:2px solid #232323;\n",
    "        \"\"\")\n",
    "        self.asr_btn.setCheckable(True)\n",
    "        self.asr_btn.clicked.connect(self.on_toggle_asr)\n",
    "\n",
    "        input_layout.addWidget(self.input_box, 10)\n",
    "        input_layout.addWidget(self.send_btn, 2)\n",
    "        input_layout.addWidget(self.asr_btn, 1)\n",
    "        self.input_panel.setStyleSheet(\"background:transparent;\")\n",
    "        self.outer_layout.addWidget(self.input_panel, stretch=0)\n",
    "\n",
    "        self.asr_status_label = QtWidgets.QLabel(\"语音识别：关闭 | 唤醒：未唤醒\", self)\n",
    "        self.asr_status_label.setStyleSheet(\"color:#4faaff; font-size:15px; font-weight:bold; background:transparent;\")\n",
    "        self.asr_status_label.setAlignment(QtCore.Qt.AlignRight)\n",
    "        self.asr_status_label.setFixedHeight(24)\n",
    "        self.outer_layout.addWidget(self.asr_status_label, alignment=QtCore.Qt.AlignRight)\n",
    "\n",
    "        self.top_layout.setStretch(0, 1)\n",
    "        self.top_layout.setStretch(1, 1)\n",
    "        self.top_layout.setStretch(2, 1)\n",
    "        self.outer_layout.setStretch(0, 15)\n",
    "        self.outer_layout.setStretch(1, 0)\n",
    "        self.outer_layout.setStretch(2, 0)\n",
    "        self.resizeEvent = self.on_resize\n",
    "\n",
    "    def update_center_panel_geometry(self):\n",
    "        w = self.center_panel.width()\n",
    "        h = self.center_panel.height()\n",
    "        self.face_label.setMinimumSize(w, h)\n",
    "        self.face_label.setMaximumSize(w, h)\n",
    "        self._last_face_size = (w, h)\n",
    "        if self._last_pixmap is not None:\n",
    "            self._show_pixmap_mainthread(self._last_pixmap)\n",
    "\n",
    "    def on_resize(self, event):\n",
    "        self.update_center_panel_geometry()\n",
    "        event.accept()\n",
    "\n",
    "    def init_resources(self):\n",
    "        self.bot = ChatBot(\n",
    "            api_key=API_KEY,\n",
    "            base_url=BASE_URL,\n",
    "            log_dir=\"logs\",\n",
    "            default_background=\"你是一个知识渊博的助手，能够简洁地回答问题。\",\n",
    "            default_prefix=\"请简洁地回答下述问题：\"\n",
    "        )\n",
    "        self.model = load_model(WAV2LIP_MODEL_PATH, DEVICE)\n",
    "        self.face_img, self.face_coords, self.orig_image = preprocess_image(FACE_IMAGE_PATH, device=DEVICE)\n",
    "        self.idle_video_path = IDLE_VIDEO_PATH\n",
    "        self.lip_player = LipSyncPlayer(self.model, DEVICE, self.orig_image, self.face_coords, fps=25)\n",
    "\n",
    "    def show_idle(self):\n",
    "        self.stop_sync()\n",
    "        self.idle_video_running.set()\n",
    "        if self.idle_video_thread is None or not self.idle_video_thread.is_alive():\n",
    "            self.idle_video_thread = threading.Thread(target=self.play_idle_video, daemon=True)\n",
    "            self.idle_video_thread.start()\n",
    "\n",
    "    def play_idle_video(self):\n",
    "        while self.idle_video_running.is_set():\n",
    "            cap = cv2.VideoCapture(self.idle_video_path)\n",
    "            if not cap.isOpened():\n",
    "                print(f\"无法打开idle视频：{self.idle_video_path}\")\n",
    "                return\n",
    "            while self.idle_video_running.is_set():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                    continue\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                w, h = self._last_face_size\n",
    "                if w < 10 or h < 10:\n",
    "                    w, h = 300, 400\n",
    "                frame = cv2.resize(frame, (w, h))\n",
    "                qtimg = QtGui.QImage(frame.data, frame.shape[1], frame.shape[0], frame.strides[0], QtGui.QImage.Format_RGB888)\n",
    "                pix = QtGui.QPixmap.fromImage(qtimg)\n",
    "                self._last_pixmap = pix\n",
    "                self.show_frame_signal.emit(pix)\n",
    "                time.sleep(1.0 / 25)\n",
    "            cap.release()\n",
    "\n",
    "    def stop_idle_video(self):\n",
    "        self.idle_video_running.clear()\n",
    "\n",
    "    def stop_sync(self):\n",
    "        if self.sync_timer.isActive():\n",
    "            self.sync_timer.stop()\n",
    "        self.video_frames = []\n",
    "        self.video_frame_count = 0\n",
    "        self.audio_total_ms = 0\n",
    "\n",
    "    @QtCore.pyqtSlot(QtGui.QPixmap)\n",
    "    def _show_pixmap_mainthread(self, pix):\n",
    "        w, h = self._last_face_size\n",
    "        scaled = pix.scaled(w, h, QtCore.Qt.IgnoreAspectRatio, QtCore.Qt.SmoothTransformation)\n",
    "        self.face_label.setPixmap(scaled)\n",
    "        self._last_pixmap = pix\n",
    "\n",
    "    @QtCore.pyqtSlot(str, str)\n",
    "    def append_history(self, speaker, text):\n",
    "        self.chat_history.append_bubble(text, speaker)\n",
    "\n",
    "    @QtCore.pyqtSlot(str)\n",
    "    def show_stage(self, text):\n",
    "        self.stage_label.append(f\"<div style='color:#4faaff'>{text}</div>\")\n",
    "        self.stage_label.verticalScrollBar().setValue(self.stage_label.verticalScrollBar().maximum())\n",
    "\n",
    "    @QtCore.pyqtSlot(np.ndarray)\n",
    "    def show_video_frame(self, frame):\n",
    "        w, h = self._last_face_size\n",
    "        # 确保frame为RGB\n",
    "        if len(frame.shape) == 2 or frame.shape[2] == 1:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)\n",
    "        elif frame.shape[2] == 3:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (w, h))\n",
    "        qtimg = QtGui.QImage(frame.data, frame.shape[1], frame.shape[0], frame.strides[0], QtGui.QImage.Format_RGB888)\n",
    "        pix = QtGui.QPixmap.fromImage(qtimg)\n",
    "        self.face_label.setPixmap(pix)\n",
    "        self._last_pixmap = pix\n",
    "\n",
    "    @QtCore.pyqtSlot(list, str, float)\n",
    "    def play_video_frames(self, frames, audio_path, audio_duration):\n",
    "        self.stop_idle_video()  # 只在此处暂停idle\n",
    "        self.stop_sync()\n",
    "        self.video_frames = frames\n",
    "        self.video_frame_count = len(frames)\n",
    "        self.target_fps = 25\n",
    "        self.audio_total_ms = int(audio_duration * 1000)\n",
    "        self.audio_player.play(audio_path)\n",
    "        self.sync_timer.start(20)\n",
    "\n",
    "    def _sync_frame_with_audio(self):\n",
    "        ms = self.audio_player.player.position()\n",
    "        if ms <= 0:\n",
    "            return\n",
    "        idx = int(ms * self.target_fps / 1000)\n",
    "        idx = min(idx, self.video_frame_count - 1)\n",
    "        if 0 <= idx < self.video_frame_count:\n",
    "            frame = self.video_frames[idx]\n",
    "            self.show_video_frame(frame)\n",
    "        if ms >= self.audio_total_ms - 20 or idx >= self.video_frame_count - 1:\n",
    "            self.sync_timer.stop()\n",
    "            self.idle_signal.emit()\n",
    "\n",
    "    # ----------- 语音识别部分（参考修正版） -----------\n",
    "    @QtCore.pyqtSlot(str)\n",
    "    def on_asr_text(self, text):\n",
    "        if self.busy:\n",
    "            self.stage_signal.emit(\"正在播报回答，请稍后再提问。\")\n",
    "            return\n",
    "        text = text.strip()\n",
    "        if text:\n",
    "            self.input_box.setText(text)\n",
    "            self.on_submit()\n",
    "\n",
    "    @QtCore.pyqtSlot(bool, bool)\n",
    "    def update_asr_status(self, running, wake):\n",
    "        self.asr_running = running\n",
    "        self._asr_wake = wake\n",
    "        s = f\"语音识别：{'开启' if running else '关闭'} | 唤醒：{'已唤醒' if wake else '未唤醒'}\"\n",
    "        color = \"#4faaff\" if running else \"#555\"\n",
    "        wcolor = \"#ff5050\" if wake else \"#4faaff\"\n",
    "        self.asr_status_label.setText(s)\n",
    "        self.asr_status_label.setStyleSheet(f\"color:{wcolor if wake else color}; font-size:15px; font-weight:bold; background:transparent;\")\n",
    "        if not running:\n",
    "            self.asr_btn.setChecked(False)\n",
    "            self.asr_btn.setText(\"🎤\")\n",
    "        else:\n",
    "            self.asr_btn.setChecked(True)\n",
    "            self.asr_btn.setText(\"⏹\")\n",
    "\n",
    "    def on_toggle_asr(self):\n",
    "        if self.asr_running:\n",
    "            self._stop_asr()\n",
    "        else:\n",
    "            self._start_asr()\n",
    "\n",
    "    def _start_asr(self):\n",
    "        if self.asr_running:\n",
    "            return\n",
    "        self.asr_running = True\n",
    "        self.asr_btn.setText(\"⏹\")\n",
    "        self.asr_status_signal.emit(True, False)\n",
    "        self.asr_thread = threading.Thread(target=self.start_asr, daemon=True)\n",
    "        self.asr_thread.start()\n",
    "\n",
    "    def _stop_asr(self):\n",
    "        if not self.asr_running:\n",
    "            return\n",
    "        self.asr_running = False\n",
    "        self.asr_btn.setText(\"🎤\")\n",
    "        self.asr_status_signal.emit(False, False)\n",
    "\n",
    "    def start_asr(self):\n",
    "        def asr_callback(text, wake_state):\n",
    "            self.asr_status_signal.emit(True, wake_state)\n",
    "            if text and wake_state and not self.busy:\n",
    "                self.asr_text_signal.emit(text)\n",
    "        try:\n",
    "            run_asr_thread(asr_callback, lambda: self.asr_running)\n",
    "        except Exception as e:\n",
    "            self.asr_status_signal.emit(False, False)\n",
    "    # ----------- 语音识别部分 END -----------\n",
    "\n",
    "    def on_submit(self):\n",
    "        if self.busy:\n",
    "            self.stage_signal.emit(\"正在播报上一个回答，请稍后...\")\n",
    "            return\n",
    "        question = self.input_box.text().strip()\n",
    "        if not question:\n",
    "            return\n",
    "        self.input_box.setText(\"\")\n",
    "        self.append_history(\"用户\", question)\n",
    "        self.show_stage(\"开始处理...\")\n",
    "        self.busy = True\n",
    "        threading.Thread(target=self.process_conversation, args=(question,)).start()\n",
    "\n",
    "    def process_conversation(self, question):\n",
    "        t0 = time.perf_counter()\n",
    "        self.stage_signal.emit(\"等待大模型回复...\")\n",
    "        t1 = time.perf_counter()\n",
    "        answer = self.bot.chat(question)\n",
    "        t2 = time.perf_counter()\n",
    "        self.append_history_signal.emit(\"助手\", answer)\n",
    "        self.stage_signal.emit(f\"大模型回复完成，耗时：{t2-t1:.2f}s\")\n",
    "        self.stage_signal.emit(\"正在合成语音...\")\n",
    "\n",
    "        if not answer or len(answer.strip()) < 2:\n",
    "            self.stage_signal.emit(\"回答内容过短，跳过语音与口型合成。\")\n",
    "            time.sleep(0.5)\n",
    "            self.idle_signal.emit()\n",
    "            self.busy = False\n",
    "            return\n",
    "\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        t3 = time.perf_counter()\n",
    "        try:\n",
    "            audio_path = loop.run_until_complete(generate_speech(answer))\n",
    "        except Exception as e:\n",
    "            self.stage_signal.emit(f\"语音合成失败：{e}\")\n",
    "            self.idle_signal.emit()\n",
    "            self.busy = False\n",
    "            return\n",
    "        t4 = time.perf_counter()\n",
    "        if not audio_path or not os.path.exists(audio_path) or os.path.getsize(audio_path) < 800:\n",
    "            self.stage_signal.emit(\"语音文件生成失败或内容太短，跳过口型合成。\")\n",
    "            self.idle_signal.emit()\n",
    "            self.busy = False\n",
    "            return\n",
    "        import soundfile as sf\n",
    "        audio_info = sf.info(audio_path)\n",
    "        audio_duration = float(audio_info.duration)\n",
    "        self.stage_signal.emit(f\"语音合成完成，耗时：{t4-t3:.2f}s\")\n",
    "        self.stage_signal.emit(\"正在生成嘴型动画...\")\n",
    "\n",
    "        t5 = time.perf_counter()\n",
    "        gen = prepare_audio_batches(audio_path, self.face_img, self.face_coords)\n",
    "        infer_time, all_frames = self.lip_player.infer_frames(gen)\n",
    "        self.stage_signal.emit(f\"视频帧推理完成，耗时{infer_time:.2f}s\")\n",
    "        self.stage_signal.emit(\"正在播放语音与动画...\")\n",
    "\n",
    "        self.play_video_frames_signal.emit(all_frames, audio_path, audio_duration)\n",
    "\n",
    "        t6 = time.perf_counter()\n",
    "        self.busy = False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.environ[\"QT_FONT_DPI\"] = \"96\"\n",
    "    if sys.platform == \"win32\":\n",
    "        import ctypes\n",
    "        ctypes.windll.shell32.SetCurrentProcessExplicitAppUserModelID(\"digitalhuman.app\")\n",
    "    sys.stdout.reconfigure(encoding='utf-8')\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    win = DigitalHumanUI()\n",
    "    win.show()\n",
    "    sys.exit(app.exec_())"
   ],
   "id": "e874212aa65eee42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "import threading\n",
    "import asyncio\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PyQt5 import QtWidgets, QtCore, QtGui, QtMultimedia\n",
    "\n",
    "from config import (\n",
    "    API_KEY, BASE_URL, WAV2LIP_MODEL_PATH, IDLE_VIDEO_PATH, FACE_IMAGE_PATH, DEVICE,\n",
    "    CHAT_FONT_SIZE,  # 左侧聊天区字体大小\n",
    "    STAGE_FONT_SIZE  # 右侧右栏状态区字体大小\n",
    ")\n",
    "from llm import ChatBot\n",
    "from tts import generate_speech\n",
    "from face import load_model, preprocess_image, prepare_audio_batches, LipSyncPlayer\n",
    "from asr import run_asr_thread\n",
    "\n",
    "class BubbleTextEdit(QtWidgets.QTextEdit):\n",
    "    def __init__(self, *args, font_size=16, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.setReadOnly(True)\n",
    "        self.setFont(QtGui.QFont(\"微软雅黑\", font_size))\n",
    "        # 优雅白色背景，滚动条也更清新\n",
    "        self.setStyleSheet(f\"\"\"\n",
    "            QTextEdit {{\n",
    "                background: #ffffff;\n",
    "                border-radius: 18px;\n",
    "                padding: 12px 10px 12px 10px;\n",
    "                font-size: {font_size}px;\n",
    "                color: #222;\n",
    "                border: 1.5px solid #e2e2e2;\n",
    "            }}\n",
    "            QScrollBar:vertical {{\n",
    "                background: #f5f6fa;\n",
    "                width: 10px;\n",
    "                margin: 2px 0 2px 0;\n",
    "                border-radius: 4px;\n",
    "            }}\n",
    "            QScrollBar::handle:vertical {{\n",
    "                background: #e2e2e2;\n",
    "                border-radius: 5px;\n",
    "                min-height: 20px;\n",
    "            }}\n",
    "        \"\"\")\n",
    "\n",
    "    def append_bubble(self, text, speaker=\"用户\"):\n",
    "        # 更高级的气泡，带渐变、投影、圆角、淡色边框\n",
    "        if speaker == \"用户\":\n",
    "            self.append(\n",
    "                \"<div style='margin:12px 0; text-align:right;'>\"\n",
    "                \"<span style=\\\"\"\n",
    "                \"background: linear-gradient(135deg, #7ed6ff 0%, #81ecec 100%);\"\n",
    "                \"color:#2176ae;\"\n",
    "                \"border-radius:20px 4px 20px 20px;\"\n",
    "                \"border: 1.5px solid #b6eaff;\"\n",
    "                \"box-shadow: 0 4px 18px rgba(126,214,255,0.11);\"\n",
    "                \"padding:14px 26px;\"\n",
    "                \"font-weight:500;\"\n",
    "                \"display:inline-block;\"\n",
    "                \"max-width:67%;\"\n",
    "                \"line-height:1.8;\"\n",
    "                \"word-break:break-all;\"\n",
    "                \"transition: background 0.2s;\"\n",
    "                \"\\\">\"\n",
    "                f\"{text}\"\n",
    "                \"</span>\"\n",
    "                \"</div>\")\n",
    "        else:\n",
    "            self.append(\n",
    "                \"<div style='margin:12px 0; text-align:left;'>\"\n",
    "                \"<span style=\\\"\"\n",
    "                \"background: linear-gradient(135deg, #f5f6fa 0%, #e9e9e9 100%);\"\n",
    "                \"color:#222;\"\n",
    "                \"border-radius:4px 20px 20px 20px;\"\n",
    "                \"border: 1.5px solid #e2e2e2;\"\n",
    "                \"box-shadow: 0 4px 18px rgba(225,225,225,0.10);\"\n",
    "                \"padding:14px 26px;\"\n",
    "                \"font-weight:500;\"\n",
    "                \"display:inline-block;\"\n",
    "                \"max-width:67%;\"\n",
    "                \"line-height:1.8;\"\n",
    "                \"word-break:break-all;\"\n",
    "                \"transition: background 0.2s;\"\n",
    "                \"\\\">\"\n",
    "                f\"{text}\"\n",
    "                \"</span>\"\n",
    "                \"</div>\")\n",
    "\n",
    "class BubbleStageEdit(QtWidgets.QTextEdit):\n",
    "    \"\"\"右侧状态区的气泡文本框\"\"\"\n",
    "    def __init__(self, *args, font_size=16, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.setReadOnly(True)\n",
    "        self.setFont(QtGui.QFont(\"微软雅黑\", font_size))\n",
    "        self.setStyleSheet(f\"\"\"\n",
    "            QTextEdit {{\n",
    "                background: #ffffff;\n",
    "                border-radius: 18px;\n",
    "                padding: 12px 10px 12px 10px;\n",
    "                font-size: {font_size}px;\n",
    "                color: #2176ae;\n",
    "                border: 1.5px solid #e2e2e2;\n",
    "            }}\n",
    "            QScrollBar:vertical {{\n",
    "                background: #f5f6fa;\n",
    "                width: 10px;\n",
    "                margin: 2px 0 2px 0;\n",
    "                border-radius: 4px;\n",
    "            }}\n",
    "            QScrollBar::handle:vertical {{\n",
    "                background: #e2e2e2;\n",
    "                border-radius: 5px;\n",
    "                min-height: 20px;\n",
    "            }}\n",
    "        \"\"\")\n",
    "\n",
    "    def append_bubble(self, text, speaker=\"助手\"):\n",
    "        # 右侧气泡更精致，带蓝色微渐变和浅灰\n",
    "        if speaker == \"助手\":\n",
    "            self.append(\n",
    "                \"<div style='margin:12px 0; text-align:left;'>\"\n",
    "                \"<span style=\\\"\"\n",
    "                \"background: linear-gradient(135deg, #eaf6ff 0%, #d0e2ff 100%);\"\n",
    "                \"color:#2176ae;\"\n",
    "                \"border-radius:4px 20px 20px 20px;\"\n",
    "                \"border: 1.5px solid #b1d2fa;\"\n",
    "                \"box-shadow: 0 4px 18px rgba(161,206,255,0.13);\"\n",
    "                \"padding:14px 26px;\"\n",
    "                \"font-weight:500;\"\n",
    "                \"display:inline-block;\"\n",
    "                \"max-width:75%;\"\n",
    "                \"line-height:1.8;\"\n",
    "                \"word-break:break-all;\"\n",
    "                \"transition: background 0.2s;\"\n",
    "                \"\\\">\"\n",
    "                f\"{text}\"\n",
    "                \"</span>\"\n",
    "                \"</div>\")\n",
    "        else:\n",
    "            self.append(\n",
    "                \"<div style='margin:12px 0; text-align:right;'>\"\n",
    "                \"<span style=\\\"\"\n",
    "                \"background: linear-gradient(135deg, #f5f6fa 0%, #e9e9e9 100%);\"\n",
    "                \"color:#222;\"\n",
    "                \"border-radius:20px 4px 20px 20px;\"\n",
    "                \"border: 1.5px solid #e2e2e2;\"\n",
    "                \"box-shadow: 0 4px 18px rgba(225,225,225,0.10);\"\n",
    "                \"padding:14px 26px;\"\n",
    "                \"font-weight:500;\"\n",
    "                \"display:inline-block;\"\n",
    "                \"max-width:75%;\"\n",
    "                \"line-height:1.8;\"\n",
    "                \"word-break:break-all;\"\n",
    "                \"transition: background 0.2s;\"\n",
    "                \"\\\">\"\n",
    "                f\"{text}\"\n",
    "                \"</span>\"\n",
    "                \"</div>\")\n",
    "\n",
    "class CardFrame(QtWidgets.QFrame):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.setStyleSheet(\"\"\"\n",
    "            QFrame {\n",
    "                background: rgba(34,34,34,0.92);\n",
    "                border-radius: 22px;\n",
    "                border: 1.5px solid #232323;\n",
    "            }\n",
    "        \"\"\")\n",
    "\n",
    "class FaceDisplayWidget(QtWidgets.QLabel):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.setStyleSheet(\"background:transparent;\")\n",
    "        self.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.setScaledContents(True)\n",
    "\n",
    "class AudioPlayer(QtCore.QObject):\n",
    "    finished = QtCore.pyqtSignal()\n",
    "    def __init__(self, parent=None):\n",
    "        super().__init__(parent)\n",
    "        self.player = QtMultimedia.QMediaPlayer()\n",
    "        self.player.setVolume(100)\n",
    "        self.player.mediaStatusChanged.connect(self.handle_status)\n",
    "\n",
    "    def play(self, audio_path):\n",
    "        if self.player.state() == QtMultimedia.QMediaPlayer.PlayingState:\n",
    "            self.player.stop()\n",
    "        url = QtCore.QUrl.fromLocalFile(os.path.abspath(audio_path))\n",
    "        self.player.setMedia(QtMultimedia.QMediaContent(url))\n",
    "        self.player.play()\n",
    "\n",
    "    def handle_status(self, status):\n",
    "        if status in (QtMultimedia.QMediaPlayer.EndOfMedia, QtMultimedia.QMediaPlayer.InvalidMedia):\n",
    "            self.finished.emit()\n",
    "\n",
    "class DigitalHumanUI(QtWidgets.QWidget):\n",
    "    append_history_signal = QtCore.pyqtSignal(str, str)\n",
    "    show_frame_signal = QtCore.pyqtSignal(QtGui.QPixmap)\n",
    "    idle_signal = QtCore.pyqtSignal()\n",
    "    stage_signal = QtCore.pyqtSignal(str)\n",
    "    asr_text_signal = QtCore.pyqtSignal(str)\n",
    "    asr_status_signal = QtCore.pyqtSignal(bool, bool)\n",
    "    play_video_frames_signal = QtCore.pyqtSignal(list, str, float)\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"数字人问答演示\")\n",
    "        self.setStyleSheet(\"QWidget { background: #000; }\")\n",
    "        self.resize(1400, 900)\n",
    "        self.asr_running = False\n",
    "        self.asr_thread = None\n",
    "        self._asr_wake = False\n",
    "        self.busy = False\n",
    "        self.idle_video_thread = None\n",
    "        self.idle_video_running = threading.Event()\n",
    "        self._last_pixmap = None\n",
    "        self._last_face_size = (0, 0)\n",
    "        self.audio_player = AudioPlayer()\n",
    "        self.sync_timer = QtCore.QTimer(self)\n",
    "        self.sync_timer.timeout.connect(self._sync_frame_with_audio)\n",
    "        self.video_frames = []\n",
    "        self.video_frame_count = 0\n",
    "        self.target_fps = 25\n",
    "        self.audio_total_ms = 0\n",
    "        self.init_ui()\n",
    "        self.init_resources()\n",
    "        self.append_history_signal.connect(self.append_history)\n",
    "        self.show_frame_signal.connect(self._show_pixmap_mainthread)\n",
    "        self.idle_signal.connect(self.show_idle)\n",
    "        self.stage_signal.connect(self.show_stage)\n",
    "        self.asr_text_signal.connect(self.on_asr_text)\n",
    "        self.asr_status_signal.connect(self.update_asr_status)\n",
    "        self.play_video_frames_signal.connect(self.play_video_frames)\n",
    "        self.show_idle()\n",
    "        self.show_stage(\"系统待命...\")\n",
    "\n",
    "    def init_ui(self):\n",
    "        self.outer_layout = QtWidgets.QVBoxLayout(self)\n",
    "        self.outer_layout.setContentsMargins(0, 0, 0, 0)\n",
    "        self.outer_layout.setSpacing(0)\n",
    "        self.top_panel = QtWidgets.QWidget(self)\n",
    "        self.top_layout = QtWidgets.QHBoxLayout(self.top_panel)\n",
    "        self.top_layout.setContentsMargins(0, 0, 0, 0)\n",
    "        self.top_layout.setSpacing(0)\n",
    "\n",
    "        self.left_panel = QtWidgets.QWidget(self.top_panel)\n",
    "        self.left_layout = QtWidgets.QVBoxLayout(self.left_panel)\n",
    "        self.left_layout.setContentsMargins(24, 24, 12, 24)\n",
    "        self.left_layout.setSpacing(18)\n",
    "        self.chat_history = BubbleTextEdit(parent=self.left_panel, font_size=CHAT_FONT_SIZE)\n",
    "        self.left_layout.addWidget(self.chat_history)\n",
    "        self.left_panel.setStyleSheet(\"background:transparent;\")\n",
    "        self.top_layout.addWidget(self.left_panel)\n",
    "\n",
    "        self.center_panel = QtWidgets.QWidget(self.top_panel)\n",
    "        self.center_panel.setStyleSheet(\"background:transparent;\")\n",
    "        self.face_label = FaceDisplayWidget(self.center_panel)\n",
    "        self.center_layout = QtWidgets.QVBoxLayout(self.center_panel)\n",
    "        self.center_layout.setContentsMargins(0, 0, 0, 0)\n",
    "        self.center_layout.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        self.center_layout.addStretch()\n",
    "        self.center_layout.addWidget(self.face_label, alignment=QtCore.Qt.AlignHCenter | QtCore.Qt.AlignVCenter)\n",
    "        self.center_layout.addStretch()\n",
    "        self.top_layout.addWidget(self.center_panel)\n",
    "\n",
    "        self.right_panel = QtWidgets.QWidget(self.top_panel)\n",
    "        self.right_layout = QtWidgets.QVBoxLayout(self.right_panel)\n",
    "        self.right_layout.setContentsMargins(12, 24, 24, 24)\n",
    "        self.right_layout.setSpacing(18)\n",
    "        self.stage_card = CardFrame(self.right_panel)\n",
    "        # 右侧用气泡文本\n",
    "        self.stage_label = BubbleStageEdit(self.stage_card, font_size=STAGE_FONT_SIZE)\n",
    "        self.stage_label.setVerticalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOn)\n",
    "        vbox = QtWidgets.QVBoxLayout(self.stage_card)\n",
    "        vbox.addWidget(self.stage_label)\n",
    "        vbox.setContentsMargins(10, 10, 10, 10)\n",
    "        self.right_layout.addWidget(self.stage_card)\n",
    "        self.right_panel.setStyleSheet(\"background:transparent;\")\n",
    "        self.top_layout.addWidget(self.right_panel)\n",
    "\n",
    "        self.outer_layout.addWidget(self.top_panel, stretch=10)\n",
    "\n",
    "        self.input_panel = QtWidgets.QWidget(self)\n",
    "        input_layout = QtWidgets.QHBoxLayout(self.input_panel)\n",
    "        input_layout.setContentsMargins(48, 0, 48, 18)\n",
    "        input_layout.setSpacing(16)\n",
    "        self.input_box = QtWidgets.QLineEdit(self.input_panel)\n",
    "        self.input_box.setPlaceholderText(\"请输入你的问题或说话（支持语音唤醒）...\")\n",
    "        self.input_box.setStyleSheet(\"\"\"\n",
    "            font-size:17px; border-radius:12px; padding:10px; background:#181a1b;\n",
    "            border:2px solid #232323; color:#e6e6e6;\n",
    "        \"\"\")\n",
    "        self.send_btn = QtWidgets.QPushButton(\"发送\", self.input_panel)\n",
    "        self.send_btn.setStyleSheet(\"\"\"\n",
    "            font-size:17px; padding:10px 28px; background:#4faaff; color:#15181a; border-radius:10px;\n",
    "            font-weight:bold;\n",
    "        \"\"\")\n",
    "        self.send_btn.clicked.connect(self.on_submit)\n",
    "        self.asr_btn = QtWidgets.QPushButton(\"🎤\", self.input_panel)\n",
    "        self.asr_btn.setStyleSheet(\"\"\"\n",
    "            font-size:24px; padding:10px 16px; background:#232323; color:#4faaff; border-radius:50%;\n",
    "            border:2px solid #232323;\n",
    "        \"\"\")\n",
    "        self.asr_btn.setCheckable(True)\n",
    "        self.asr_btn.clicked.connect(self.on_toggle_asr)\n",
    "\n",
    "        input_layout.addWidget(self.input_box, 10)\n",
    "        input_layout.addWidget(self.send_btn, 2)\n",
    "        input_layout.addWidget(self.asr_btn, 1)\n",
    "        self.input_panel.setStyleSheet(\"background:transparent;\")\n",
    "        self.outer_layout.addWidget(self.input_panel, stretch=0)\n",
    "\n",
    "        self.asr_status_label = QtWidgets.QLabel(\"语音识别：关闭 | 唤醒：未唤醒\", self)\n",
    "        self.asr_status_label.setStyleSheet(\"color:#4faaff; font-size:15px; font-weight:bold; background:transparent;\")\n",
    "        self.asr_status_label.setAlignment(QtCore.Qt.AlignRight)\n",
    "        self.asr_status_label.setFixedHeight(24)\n",
    "        self.outer_layout.addWidget(self.asr_status_label, alignment=QtCore.Qt.AlignRight)\n",
    "\n",
    "        self.top_layout.setStretch(0, 1)\n",
    "        self.top_layout.setStretch(1, 1)\n",
    "        self.top_layout.setStretch(2, 1)\n",
    "        self.outer_layout.setStretch(0, 15)\n",
    "        self.outer_layout.setStretch(1, 0)\n",
    "        self.outer_layout.setStretch(2, 0)\n",
    "        self.resizeEvent = self.on_resize\n",
    "\n",
    "    def update_center_panel_geometry(self):\n",
    "        w = self.center_panel.width()\n",
    "        h = self.center_panel.height()\n",
    "        self.face_label.setMinimumSize(w, h)\n",
    "        self.face_label.setMaximumSize(w, h)\n",
    "        self._last_face_size = (w, h)\n",
    "        if self._last_pixmap is not None:\n",
    "            self._show_pixmap_mainthread(self._last_pixmap)\n",
    "\n",
    "    def on_resize(self, event):\n",
    "        self.update_center_panel_geometry()\n",
    "        event.accept()\n",
    "\n",
    "    def init_resources(self):\n",
    "        self.bot = ChatBot(\n",
    "            api_key=API_KEY,\n",
    "            base_url=BASE_URL,\n",
    "            log_dir=\"logs\",\n",
    "            default_background=\"你是一个知识渊博的助手，能够简洁地回答问题。\",\n",
    "            default_prefix=\"请简洁地回答下述问题：\"\n",
    "        )\n",
    "        self.model = load_model(WAV2LIP_MODEL_PATH, DEVICE)\n",
    "        self.face_img, self.face_coords, self.orig_image = preprocess_image(FACE_IMAGE_PATH, device=DEVICE)\n",
    "        self.idle_video_path = IDLE_VIDEO_PATH\n",
    "        self.lip_player = LipSyncPlayer(self.model, DEVICE, self.orig_image, self.face_coords, fps=25)\n",
    "\n",
    "    def show_idle(self):\n",
    "        self.stop_sync()\n",
    "        self.idle_video_running.set()\n",
    "        if self.idle_video_thread is None or not self.idle_video_thread.is_alive():\n",
    "            self.idle_video_thread = threading.Thread(target=self.play_idle_video, daemon=True)\n",
    "            self.idle_video_thread.start()\n",
    "\n",
    "    def play_idle_video(self):\n",
    "        while self.idle_video_running.is_set():\n",
    "            cap = cv2.VideoCapture(self.idle_video_path)\n",
    "            if not cap.isOpened():\n",
    "                print(f\"无法打开idle视频：{self.idle_video_path}\")\n",
    "                return\n",
    "            while self.idle_video_running.is_set():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                    continue\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                w, h = self._last_face_size\n",
    "                if w < 10 or h < 10:\n",
    "                    w, h = 300, 400\n",
    "                frame = cv2.resize(frame, (w, h))\n",
    "                qtimg = QtGui.QImage(frame.data, frame.shape[1], frame.shape[0], frame.strides[0], QtGui.QImage.Format_RGB888)\n",
    "                pix = QtGui.QPixmap.fromImage(qtimg)\n",
    "                self._last_pixmap = pix\n",
    "                self.show_frame_signal.emit(pix)\n",
    "                time.sleep(1.0 / 25)\n",
    "            cap.release()\n",
    "\n",
    "    def stop_idle_video(self):\n",
    "        self.idle_video_running.clear()\n",
    "\n",
    "    def stop_sync(self):\n",
    "        if self.sync_timer.isActive():\n",
    "            self.sync_timer.stop()\n",
    "        self.video_frames = []\n",
    "        self.video_frame_count = 0\n",
    "        self.audio_total_ms = 0\n",
    "\n",
    "    @QtCore.pyqtSlot(QtGui.QPixmap)\n",
    "    def _show_pixmap_mainthread(self, pix):\n",
    "        w, h = self._last_face_size\n",
    "        scaled = pix.scaled(w, h, QtCore.Qt.IgnoreAspectRatio, QtCore.Qt.SmoothTransformation)\n",
    "        self.face_label.setPixmap(scaled)\n",
    "        self._last_pixmap = pix\n",
    "\n",
    "    @QtCore.pyqtSlot(str, str)\n",
    "    def append_history(self, speaker, text):\n",
    "        self.chat_history.append_bubble(text, speaker)\n",
    "\n",
    "    @QtCore.pyqtSlot(str)\n",
    "    def show_stage(self, text):\n",
    "        self.stage_label.append_bubble(text, \"助手\")\n",
    "        self.stage_label.verticalScrollBar().setValue(self.stage_label.verticalScrollBar().maximum())\n",
    "\n",
    "    @QtCore.pyqtSlot(np.ndarray)\n",
    "    def show_video_frame(self, frame):\n",
    "        w, h = self._last_face_size\n",
    "        # 确保frame为RGB\n",
    "        if len(frame.shape) == 2 or frame.shape[2] == 1:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)\n",
    "        elif frame.shape[2] == 3:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, (w, h))\n",
    "        qtimg = QtGui.QImage(frame.data, frame.shape[1], frame.shape[0], frame.strides[0], QtGui.QImage.Format_RGB888)\n",
    "        pix = QtGui.QPixmap.fromImage(qtimg)\n",
    "        self.face_label.setPixmap(pix)\n",
    "        self._last_pixmap = pix\n",
    "\n",
    "    @QtCore.pyqtSlot(list, str, float)\n",
    "    def play_video_frames(self, frames, audio_path, audio_duration):\n",
    "        self.stop_idle_video()  # 只在此处暂停idle\n",
    "        self.stop_sync()\n",
    "        self.video_frames = frames\n",
    "        self.video_frame_count = len(frames)\n",
    "        self.target_fps = 25\n",
    "        self.audio_total_ms = int(audio_duration * 1000)\n",
    "        self.audio_player.play(audio_path)\n",
    "        self.sync_timer.start(20)\n",
    "\n",
    "    def _sync_frame_with_audio(self):\n",
    "        ms = self.audio_player.player.position()\n",
    "        if ms <= 0:\n",
    "            return\n",
    "        idx = int(ms * self.target_fps / 1000)\n",
    "        idx = min(idx, self.video_frame_count - 1)\n",
    "        if 0 <= idx < self.video_frame_count:\n",
    "            frame = self.video_frames[idx]\n",
    "            self.show_video_frame(frame)\n",
    "        if ms >= self.audio_total_ms - 20 or idx >= self.video_frame_count - 1:\n",
    "            self.sync_timer.stop()\n",
    "            self.idle_signal.emit()\n",
    "\n",
    "    # ----------- 语音识别部分（参考修正版） -----------\n",
    "    @QtCore.pyqtSlot(str)\n",
    "    def on_asr_text(self, text):\n",
    "        if self.busy:\n",
    "            self.stage_signal.emit(\"正在播报回答，请稍后再提问。\")\n",
    "            return\n",
    "        text = text.strip()\n",
    "        if text:\n",
    "            self.input_box.setText(text)\n",
    "            self.on_submit()\n",
    "\n",
    "    @QtCore.pyqtSlot(bool, bool)\n",
    "    def update_asr_status(self, running, wake):\n",
    "        self.asr_running = running\n",
    "        self._asr_wake = wake\n",
    "        s = f\"语音识别：{'开启' if running else '关闭'} | 唤醒：{'已唤醒' if wake else '未唤醒'}\"\n",
    "        color = \"#4faaff\" if running else \"#555\"\n",
    "        wcolor = \"#ff5050\" if wake else \"#4faaff\"\n",
    "        self.asr_status_label.setText(s)\n",
    "        self.asr_status_label.setStyleSheet(f\"color:{wcolor if wake else color}; font-size:15px; font-weight:bold; background:transparent;\")\n",
    "        if not running:\n",
    "            self.asr_btn.setChecked(False)\n",
    "            self.asr_btn.setText(\"🎤\")\n",
    "        else:\n",
    "            self.asr_btn.setChecked(True)\n",
    "            self.asr_btn.setText(\"⏹\")\n",
    "\n",
    "    def on_toggle_asr(self):\n",
    "        if self.asr_running:\n",
    "            self._stop_asr()\n",
    "        else:\n",
    "            self._start_asr()\n",
    "\n",
    "    def _start_asr(self):\n",
    "        if self.asr_running:\n",
    "            return\n",
    "        self.asr_running = True\n",
    "        self.asr_btn.setText(\"⏹\")\n",
    "        self.asr_status_signal.emit(True, False)\n",
    "        self.asr_thread = threading.Thread(target=self.start_asr, daemon=True)\n",
    "        self.asr_thread.start()\n",
    "\n",
    "    def _stop_asr(self):\n",
    "        if not self.asr_running:\n",
    "            return\n",
    "        self.asr_running = False\n",
    "        self.asr_btn.setText(\"🎤\")\n",
    "        self.asr_status_signal.emit(False, False)\n",
    "\n",
    "    def start_asr(self):\n",
    "        def asr_callback(text, wake_state):\n",
    "            self.asr_status_signal.emit(True, wake_state)\n",
    "            if text and wake_state and not self.busy:\n",
    "                self.asr_text_signal.emit(text)\n",
    "        try:\n",
    "            run_asr_thread(asr_callback, lambda: self.asr_running)\n",
    "        except Exception as e:\n",
    "            self.asr_status_signal.emit(False, False)\n",
    "    # ----------- 语音识别部分 END -----------\n",
    "\n",
    "    def on_submit(self):\n",
    "        if self.busy:\n",
    "            self.stage_signal.emit(\"正在播报上一个回答，请稍后...\")\n",
    "            return\n",
    "        question = self.input_box.text().strip()\n",
    "        if not question:\n",
    "            return\n",
    "        self.input_box.setText(\"\")\n",
    "        self.append_history(\"用户\", question)\n",
    "        self.show_stage(\"开始处理...\")\n",
    "        self.busy = True\n",
    "        threading.Thread(target=self.process_conversation, args=(question,)).start()\n",
    "\n",
    "    def process_conversation(self, question):\n",
    "        t0 = time.perf_counter()\n",
    "        self.stage_signal.emit(\"等待大模型回复...\")\n",
    "        t1 = time.perf_counter()\n",
    "        answer = self.bot.chat(question)\n",
    "        t2 = time.perf_counter()\n",
    "        self.append_history_signal.emit(\"助手\", answer)\n",
    "        self.stage_signal.emit(f\"大模型回复完成，耗时：{t2-t1:.2f}s\")\n",
    "        self.stage_signal.emit(\"正在合成语音...\")\n",
    "\n",
    "        if not answer or len(answer.strip()) < 2:\n",
    "            self.stage_signal.emit(\"回答内容过短，跳过语音与口型合成。\")\n",
    "            time.sleep(0.5)\n",
    "            self.idle_signal.emit()\n",
    "            self.busy = False\n",
    "            return\n",
    "\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        t3 = time.perf_counter()\n",
    "        try:\n",
    "            audio_path = loop.run_until_complete(generate_speech(answer))\n",
    "        except Exception as e:\n",
    "            self.stage_signal.emit(f\"语音合成失败：{e}\")\n",
    "            self.idle_signal.emit()\n",
    "            self.busy = False\n",
    "            return\n",
    "        t4 = time.perf_counter()\n",
    "        if not audio_path or not os.path.exists(audio_path) or os.path.getsize(audio_path) < 800:\n",
    "            self.stage_signal.emit(\"语音文件生成失败或内容太短，跳过口型合成。\")\n",
    "            self.idle_signal.emit()\n",
    "            self.busy = False\n",
    "            return\n",
    "        import soundfile as sf\n",
    "        audio_info = sf.info(audio_path)\n",
    "        audio_duration = float(audio_info.duration)\n",
    "        self.stage_signal.emit(f\"语音合成完成，耗时：{t4-t3:.2f}s\")\n",
    "        self.stage_signal.emit(\"正在生成嘴型动画...\")\n",
    "\n",
    "        t5 = time.perf_counter()\n",
    "        gen = prepare_audio_batches(audio_path, self.face_img, self.face_coords)\n",
    "        infer_time, all_frames = self.lip_player.infer_frames(gen)\n",
    "        self.stage_signal.emit(f\"视频帧推理完成，耗时{infer_time:.2f}s\")\n",
    "        self.stage_signal.emit(\"正在播放语音与动画...\")\n",
    "\n",
    "        self.play_video_frames_signal.emit(all_frames, audio_path, audio_duration)\n",
    "\n",
    "        t6 = time.perf_counter()\n",
    "        self.busy = False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.environ[\"QT_FONT_DPI\"] = \"96\"\n",
    "    if sys.platform == \"win32\":\n",
    "        import ctypes\n",
    "        ctypes.windll.shell32.SetCurrentProcessExplicitAppUserModelID(\"digitalhuman.app\")\n",
    "    sys.stdout.reconfigure(encoding='utf-8')\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    win = DigitalHumanUI()\n",
    "    win.show()\n",
    "    sys.exit(app.exec_())"
   ],
   "id": "fbb3cbcce38b7a2a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
